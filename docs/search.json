[
  {
    "objectID": "INT3_Importe_R.html",
    "href": "INT3_Importe_R.html",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "",
    "text": "Ce document montre les solutions techniques pour importer, explorer, manipuler, visualiser (simplement) et exporter des données géographiques avec R :"
  },
  {
    "objectID": "INT3_Importe_R.html#import-.csv",
    "href": "INT3_Importe_R.html#import-.csv",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Import .csv",
    "text": "Import .csv\nImport des données des délégations au format csv. On lui donne le nom de del_df.\n\ndel_df &lt;- read.csv(\"data/data_intro/tun/data/don_del.csv\", sep = \";\", dec = \",\")\n\nAvec R, il est très important de maîtriser la nature des objets importés ou transformés, et les convertir le cas échéant. La fonction class() nous permet de constater qu’il s’agit d’un data.frame. La fonction str() permet de détailler son contenu.\n\nclass(del_df)\n\n[1] \"data.frame\"\n\nstr(del_df)\n\n'data.frame':   264 obs. of  30 variables:\n $ del_code    : chr  \"TN.AN.AR\" \"TN.AN.ET\" \"TN.AN.KA\" \"TN.AN.LS\" ...\n $ del_nom_fr  : chr  \"Ariana Ville\" \"Cité Ettathamen\" \"kalaât El Andalous\" \"Soukra\" ...\n $ del_nom_ar  : chr  \"أريانة المدينة\" \"حي التضامن\" \"قلعة الاندلس\" \"سكرة\" ...\n $ gou_code    : chr  \"AN\" \"AN\" \"AN\" \"AN\" ...\n $ gou_nom     : chr  \"Ariana\" \"Ariana\" \"Ariana\" \"Ariana\" ...\n $ gou_cap     : int  1 0 0 0 0 0 0 1 0 0 ...\n $ gou_cap_dist: num  1 8.8 19.8 6.7 8 8.8 15 1 9.5 7.4 ...\n $ reg_code    : chr  \"NE\" \"NE\" \"NE\" \"NE\" ...\n $ reg_nom     : chr  \"Nord-est\" \"Nord-est\" \"Nord-est\" \"Nord-est\" ...\n $ popto_2004  : int  97687 78311 23045 89151 53752 60896 19404 32329 27977 31792 ...\n $ popco_2004  : int  97687 78311 15313 89151 40176 53911 8909 32329 27977 31792 ...\n $ immig_2004  : int  16961 5651 728 19129 7258 14053 1298 3963 5831 5508 ...\n $ emigr_2004  : int  15426 5245 528 2832 985 1443 723 9381 1135 3991 ...\n $ mobil_2004  : int  32387 10896 1256 21961 8243 15496 2021 13344 6966 9499 ...\n $ menag_2004  : int  27468 11950 4709 21590 17119 14276 4215 7941 6498 8462 ...\n $ ordin_2004  : int  9751 430 188 2979 685 2327 181 834 1176 1963 ...\n $ porta_2004  : int  22524 4505 1865 13321 7087 9022 1775 4908 4178 6397 ...\n $ telef_2004  : int  18596 3824 829 9262 7019 6339 1176 4002 2755 4747 ...\n $ popto_2014  : int  114486 84312 26796 129693 89884 106414 24503 31128 40101 34962 ...\n $ popco_2014  : int  114486 84312 18211 129693 58641 94961 11351 31128 40101 34962 ...\n $ immig_2014  : int  15637 5028 1104 20786 14400 20128 1997 2392 5855 3957 ...\n $ emigr_2014  : int  20448 6752 752 5528 1828 2521 822 8495 1883 3803 ...\n $ mobil2014   : int  36085 11780 1856 26314 16228 22649 2819 10887 7738 7760 ...\n $ menag_2014  : int  32498 22087 6554 33981 22781 27574 5922 8506 10066 9996 ...\n $ ordin_2014  : int  25474 6836 1701 18191 8326 14284 1723 4339 5494 6471 ...\n $ porta_2014  : int  32308 21715 6305 33683 22531 27338 5811 8363 9970 9901 ...\n $ telef_2014  : int  19942 3496 428 9831 4249 7505 637 2918 3110 4901 ...\n $ popto_2010  : num  109500 82922 24367 107829 69247 ...\n $ surfa_2010  : num  18.61 3.38 188.21 27.89 22.91 ...\n $ idr_2011    : num  0.638 0.386 0.383 0.557 0.466 0.531 0.358 0.489 0.51 0.523 ...\n\n\nOn visualise les premières lignes avec la fonction head().\n\nhead(del_df, 5)\n\n  del_code         del_nom_fr     del_nom_ar gou_code gou_nom gou_cap\n1 TN.AN.AR       Ariana Ville أريانة المدينة       AN  Ariana       1\n2 TN.AN.ET    Cité Ettathamen     حي التضامن       AN  Ariana       0\n3 TN.AN.KA kalaât El Andalous   قلعة الاندلس       AN  Ariana       0\n4 TN.AN.LS             Soukra           سكرة       AN  Ariana       0\n5 TN.AN.MN             Mnihla       المنيهلة       AN  Ariana       0\n  gou_cap_dist reg_code  reg_nom popto_2004 popco_2004 immig_2004 emigr_2004\n1          1.0       NE Nord-est      97687      97687      16961      15426\n2          8.8       NE Nord-est      78311      78311       5651       5245\n3         19.8       NE Nord-est      23045      15313        728        528\n4          6.7       NE Nord-est      89151      89151      19129       2832\n5          8.0       NE Nord-est      53752      40176       7258        985\n  mobil_2004 menag_2004 ordin_2004 porta_2004 telef_2004 popto_2014 popco_2014\n1      32387      27468       9751      22524      18596     114486     114486\n2      10896      11950        430       4505       3824      84312      84312\n3       1256       4709        188       1865        829      26796      18211\n4      21961      21590       2979      13321       9262     129693     129693\n5       8243      17119        685       7087       7019      89884      58641\n  immig_2014 emigr_2014 mobil2014 menag_2014 ordin_2014 porta_2014 telef_2014\n1      15637      20448     36085      32498      25474      32308      19942\n2       5028       6752     11780      22087       6836      21715       3496\n3       1104        752      1856       6554       1701       6305        428\n4      20786       5528     26314      33981      18191      33683       9831\n5      14400       1828     16228      22781       8326      22531       4249\n  popto_2010 surfa_2010 idr_2011\n1     109500     18.612    0.638\n2      82922      3.376    0.386\n3      24367    188.206    0.383\n4     107829     27.895    0.557\n5      69247     22.907    0.466"
  },
  {
    "objectID": "INT3_Importe_R.html#import-excel",
    "href": "INT3_Importe_R.html#import-excel",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Import Excel",
    "text": "Import Excel\nLa package readxl permet l’import de fichiers Excel. La fonction read_excel a plusieurs arguments utiles pour spécifier en entrée le format des colonnes (texte, numérique), ne pas considérer les n premières lignes du fichier, etc.\nNous importons ici un fichier Excel dérivé du World Population Prospects des Nations Unies, qui met à disposition toute sorte d’indicateurs démographiques (population, natalité, mortalité). On dispose ici des dénombrements de population par tranche d’âge quinquennale de 1950 à 2021 (feuille estimates).\n\nlibrary(readxl)\n\nworld &lt;- read_excel(\"data/data_intro/world/data/unpp_POP_5y.xlsx\", \n                 sheet = \"Estimates\",\n                 skip = 16,\n                 col_types = c(rep(\"text\", 10), rep(\"numeric\", 22)))"
  },
  {
    "objectID": "INT3_Importe_R.html#manipulation-de-data.frame",
    "href": "INT3_Importe_R.html#manipulation-de-data.frame",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Manipulation de data.frame",
    "text": "Manipulation de data.frame\nDans les faits ces fichiers nécessitent généralement d’être reformatés et réorganisés pour pouvoir être interprétés dans un logiciel quel qu’il soit… Commençons par comprendre la structure des données : noms de colonnes, années disponibles etc.\n\n# Conversion en data.frame\nworld &lt;- data.frame(world)\n\n# Nom des colonnes\ncolnames(world)\n\n [1] \"Index\"                               \n [2] \"Variant\"                             \n [3] \"Region..subregion..country.or.area..\"\n [4] \"Notes\"                               \n [5] \"Location.code\"                       \n [6] \"ISO3.Alpha.code\"                     \n [7] \"ISO2.Alpha.code\"                     \n [8] \"SDMX.code..\"                         \n [9] \"Type\"                                \n[10] \"Parent.code\"                         \n[11] \"Year\"                                \n[12] \"X0.4\"                                \n[13] \"X5.9\"                                \n[14] \"X10.14\"                              \n[15] \"X15.19\"                              \n[16] \"X20.24\"                              \n[17] \"X25.29\"                              \n[18] \"X30.34\"                              \n[19] \"X35.39\"                              \n[20] \"X40.44\"                              \n[21] \"X45.49\"                              \n[22] \"X50.54\"                              \n[23] \"X55.59\"                              \n[24] \"X60.64\"                              \n[25] \"X65.69\"                              \n[26] \"X70.74\"                              \n[27] \"X75.79\"                              \n[28] \"X80.84\"                              \n[29] \"X85.89\"                              \n[30] \"X90.94\"                              \n[31] \"X95.99\"                              \n[32] \"X100.\"                               \n\n# Années disponibles\nunique(world$Year)\n\n [1] 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964\n[16] 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979\n[31] 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994\n[46] 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009\n[61] 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021   NA\n\n\nOn peut alors filtrer les dimensions du tableau, calculer des indicateurs, etc. qui pourront être utilisés pour des statistiques de base, des graphiques voire de futures représentations cartographiques.\n\n# Somme de plusieurs colonnes\nworld$POP_TOT &lt;- rowSums(world[,c(12:32)]) # Population totale\n\n# Renommer une colonne\nnames(world)[3] &lt;- \"Name\"\n\n# Créer des indicateurs\n# Part des jeunes\nworld$YOUNG_RT &lt;- (world$X0.4 + world$X5.9 + world$X10.14) / world$POP_TOT * 100 \n# Part des personnes âgées\nworld$OLD_RT &lt;- (world$X65.69 + world$X70.74 + world$X75.79 + world$X80.84 +\n                   world$X85.89 + world$X90.94 + world$X95.99) / world$POP_TOT * 100 \n\n# Sélection d'une ligne\nworld_2021 &lt;- world[world$Year == 2021,] # Année de référence\n\n# Sélectionner plusieurs lignes\nafr &lt;- c(\"910\", \"911\", \"912\", \"913\", \"914\")\nafr_2021 &lt;- world_2021[world_2021$Parent.code %in% afr,] # Pays africains\n\n# Ordonner selon les valeurs d'une colonne\nafr_2021 &lt;- afr_2021[order(afr_2021$YOUNG_RT, decreasing = TRUE),]\n\nIl existe de nombreuses fonctions pour l’analyse statistique avec R. La plus basique étant probablement summary().\n\n# Résumé stat\nsummary(afr_2021)\n\n    Index             Variant              Name              Notes          \n Length:58          Length:58          Length:58          Length:58         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Location.code      ISO3.Alpha.code    ISO2.Alpha.code    SDMX.code..       \n Length:58          Length:58          Length:58          Length:58         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n     Type           Parent.code             Year           X0.4         \n Length:58          Length:58          Min.   :2021   Min.   :    0.22  \n Class :character   Class :character   1st Qu.:2021   1st Qu.:  299.04  \n Mode  :character   Mode  :character   Median :2021   Median : 1971.23  \n                                       Mean   :2021   Mean   : 3576.71  \n                                       3rd Qu.:2021   3rd Qu.: 4280.10  \n                                       Max.   :2021   Max.   :34830.80  \n      X5.9               X10.14             X15.19              X20.24         \n Min.   :    0.275   Min.   :    0.26   Min.   :    0.197   Min.   :    0.166  \n 1st Qu.:  287.524   1st Qu.:  260.32   1st Qu.:  231.017   1st Qu.:  218.739  \n Median : 1799.815   Median : 1596.25   Median : 1340.744   Median : 1073.518  \n Mean   : 3237.939   Mean   : 2880.72   Mean   : 2481.160   Mean   : 2123.874  \n 3rd Qu.: 3812.367   3rd Qu.: 3456.02   3rd Qu.: 3054.270   3rd Qu.: 2727.918  \n Max.   :30567.689   Max.   :26974.49   Max.   :22929.125   Max.   :18806.200  \n     X25.29              X30.34              X35.39              X40.44        \n Min.   :    0.252   Min.   :    0.244   Min.   :    0.287   Min.   :   0.267  \n 1st Qu.:  201.104   1st Qu.:  188.732   1st Qu.:  152.122   1st Qu.: 122.764  \n Median :  960.347   Median :  880.112   Median :  738.572   Median : 573.226  \n Mean   : 1858.879   Mean   : 1643.911   Mean   : 1421.126   Mean   :1171.518  \n 3rd Qu.: 2325.300   3rd Qu.: 1923.398   3rd Qu.: 1581.452   3rd Qu.:1374.119  \n Max.   :15675.790   Max.   :13171.290   Max.   :11591.915   Max.   :9893.223  \n     X45.49             X50.54             X55.59             X60.64        \n Min.   :   0.358   Min.   :   0.486   Min.   :   0.452   Min.   :   0.496  \n 1st Qu.:  99.267   1st Qu.:  84.229   1st Qu.:  67.378   1st Qu.:  54.439  \n Median : 469.567   Median : 374.635   Median : 291.823   Median : 233.514  \n Mean   : 938.585   Mean   : 770.335   Mean   : 616.303   Mean   : 473.997  \n 3rd Qu.:1124.716   3rd Qu.: 851.100   3rd Qu.: 667.341   3rd Qu.: 534.762  \n Max.   :7846.818   Max.   :6096.186   Max.   :4876.240   Max.   :3778.750  \n     X65.69             X70.74              X75.79              X80.84       \n Min.   :   0.399   Min.   :   0.4345   Min.   :   0.3185   Min.   :  0.167  \n 1st Qu.:  40.704   1st Qu.:  26.6259   1st Qu.:  16.2689   1st Qu.:  9.041  \n Median : 156.874   Median :  94.0440   Median :  58.9380   Median : 29.567  \n Mean   : 349.206   Mean   : 235.3130   Mean   : 140.6908   Mean   : 70.866  \n 3rd Qu.: 377.993   3rd Qu.: 237.7533   3rd Qu.: 132.5434   3rd Qu.: 68.634  \n Max.   :2757.823   Max.   :1819.8435   Max.   :1102.5085   Max.   :494.341  \n     X85.89            X90.94           X95.99            X100.         \n Min.   :  0.079   Min.   : 0.038   Min.   : 0.0075   Min.   :0.000000  \n 1st Qu.:  4.053   1st Qu.: 0.968   1st Qu.: 0.0685   1st Qu.:0.004375  \n Median :  9.991   Median : 2.052   Median : 0.3372   Median :0.031750  \n Mean   : 28.099   Mean   : 7.973   Mean   : 1.4798   Mean   :0.219655  \n 3rd Qu.: 27.383   3rd Qu.: 7.602   3rd Qu.: 1.2139   3rd Qu.:0.152125  \n Max.   :178.652   Max.   :81.603   Max.   :22.9160   Max.   :3.797500  \n    POP_TOT            YOUNG_RT         OLD_RT      \n Min.   :     5.4   Min.   :13.97   Min.   : 1.677  \n 1st Qu.:  2388.4   1st Qu.:34.33   1st Qu.: 2.696  \n Median : 12774.0   Median :40.41   Median : 3.152  \n Mean   : 24028.9   Mean   :38.12   Mean   : 4.298  \n 3rd Qu.: 28556.3   3rd Qu.:43.45   3rd Qu.: 4.161  \n Max.   :213401.3   Max.   :48.90   Max.   :26.714  \n\n\n\n\n\n\n\n\nL’intérêt de la programmation pour manipuler des données\n\n\n\n\n\nLes fournisseurs de données institutionnels distribuent parfois des tableaux de données peu adaptés à l’intégration dans un logiciel quel qu’il soit. La mise en forme des données dans un langage de programmation permet :\n\nd’éviter d’avoir à manipuler ces fichiers manuellement, source d’erreurs.\nd’avoir un façon générique et rapide d’importer un grand nombre de tableaux de données.\n\nVoici le fichier d’origineproduit par l’Institut National de la Statistique tunisien (INS) qui présente le nombre de chômeurs par sexe et niveau d’instruction par gouvernorat tunisien (INS) :\n\n\n\nUn court bloc de code permet de réorganiser le fichier comme désiré, et pourrait être utilement étendu aux autres fichiers distribués par l’INS.\n\n# Import\ninput_gouv &lt;- read_excel(\"data/data_intro/tun/data/chomage.xls\", # Chemin du fichier\n                         sheet = \"Sheet1\", # Nom de la feuille Excel\n                         skip = 3, # Retirer les trois premières lignes\n                         col_types = c(rep(\"text\", 3), rep(\"numeric\", 6))) # Format des colonnes \n\n# Table de passage Recensement / codes internationaux\ngouv &lt;- read.csv(\"data/data_intro/tun/data/code_tun.csv\")\n\n# Reformatage\ninput_gouv &lt;- data.frame(input_gouv)\ninput_gouv[,1:2] &lt;- NULL # Retirer les deux premières colonnes\n\n# Noms de colonnes\ncols &lt;- c(\"CHOM_INS_NON_\", \"CHOM_INS_PRI_\", \"CHOM_INS_SEC_\", \"CHOM_INS_SUP_\",\n          \"CHOM_INS_UNK_\", \"CHOM_INS_TOT_\") \ncolnames(input_gouv)[1] &lt;- \"id_TUN\"\n\n# Chômeurs\n# Hommes\ntmp1 &lt;- input_gouv[c(1:25),]\nnames(tmp1)[2:length(tmp1)] &lt;- paste0(cols, \"M\")\ngouv &lt;- merge(gouv, tmp1, by = \"id_TUN\", all.x = TRUE)\n\n# Femmes\ntmp2 &lt;- input_gouv[c(26:50),]\nnames(tmp2)[2:length(tmp2)] &lt;- paste0(cols, \"F\")\ngouv &lt;- merge(gouv, tmp2, by = \"id_TUN\", all.x = TRUE)\n\nUne fois mis en forme, on peut réaliser un graphique sans avoir modifié le fichier initial provenant de l’INS.\n\n# 2 graphiques par ligne\npar(mfrow = c(1,2), mar = c(2,2,2,2))\n\n# Boxplot hommes\nboxplot(gouv$CHOM_INS_NON_M, # Chômeurs hommes par niveau d'instruction\n        gouv$CHOM_INS_PRI_M, \n        gouv$CHOM_INS_SEC_M,\n        gouv$CHOM_INS_SUP_M, \n        ylim = c(0, 12000), # Bornes min/max de l'axe des ordonnées\n        main = \"Hommes\", # Titre plot\n        names = c(\"Rien\", \"Primaire\", \"Secondaire\", \"Tertiaire\"), # Labels (X)\n        ylab = \"Nombre de chômeurs, 2014\", # Label (Y)\n        col = \"#adcaf7\", # Couleur des box-plots\n        cex.axis = .6, # Taille des labels des axes (réduit de 70 %)\n        cex.title = .6) # Taille du label du titre (réduit de 70 %)\n\n# Boxplot femmes\nboxplot(gouv$CHOM_INS_NON_F, \n        gouv$CHOM_INS_PRI_F, \n        gouv$CHOM_INS_SEC_F,\n        gouv$CHOM_INS_SUP_F,\n        ylim = c(0, 12000),\n        main = \"Femmes\",\n        names = c(\"Rien\", \"Primaire\", \"Secondaire\", \"Tertiaire\"), \n        col = \"#ed9fb0\", \n        cex.axis = .6, \n        cex.title = .6)\n\n\n\n\nNombre de chômeurs dans les gouvernorats tunisiens par niveau d’éducation"
  },
  {
    "objectID": "INT3_Importe_R.html#export",
    "href": "INT3_Importe_R.html#export",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Export",
    "text": "Export\nwrite.csv() exporte un data.frame selon un chemin spécifié.\n\nwrite.csv(x = gouv, # Objet à exporter\n          file = \"data/tun/data/gouv_chom.csv\", # Chemin de fichier \n          row.names = FALSE) # Pour retirer les numéros de ligne"
  },
  {
    "objectID": "INT3_Importe_R.html#graphiques-de-base",
    "href": "INT3_Importe_R.html#graphiques-de-base",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Graphiques de base",
    "text": "Graphiques de base\nLes possibilités offertes en terme de représentations graphiques sont nombreuses avec R ! En une ligne de code on peut créer des représentations graphiques variées.\nOn s’intéresse ici à la part des jeunes (0-14 ans, YOUNG_RT) et à la part des personnes âgées (65 ans et plus, OLD_RT) des pays africains dans la population totale en 2021.\n\npar(mar = c(2,2,2,2), mfrow = c(2, 3))\n\nbarplot(afr_2021$YOUNG_RT, main = \"Diagramme en barre\")\nboxplot(afr_2021$YOUNG_RT, main = \"Boîtes à moustache\")\nhist(afr_2021$YOUNG_RT, main = \"Histogrammes\")\nhist(afr_2021$YOUNG_RT, freq = FALSE, main = \"Histogrammes et densité\")\nlines(density(afr_2021$YOUNG_RT), col = \"blue\")\nstripchart(afr_2021$YOUNG_RT, method = \"jitter\", pch = 16,\n           main = \"Diagrammes de dispersion\")\nplot(data = afr_2021, YOUNG_RT ~ OLD_RT, main = \"Nuages de points\")\n\n\n\n\nCes graphiques sont paramétrables avec une série d’arguments graphiques.\n\npar(mar = c(4,4,0,4))\n\n# Line plot\ntun &lt;- world[world$Name == \"Tunisia\",]\nalg &lt;- world[world$Name == \"Algeria\",]\nmar &lt;- world[world$Name == \"Morocco\",]\n\nplot(alg$Year, # Abscisses \n     alg$YOUNG_RT, # Ordonnées\n     type = \"l\", # Type lignes\n     ylim = c(20, 50), # Bornes min/max des ordonnées\n     cex = .6, # Taille des points\n     col = \"blue\", # Couleur de la ligne\n     cex.lab = 0.7, # Réduit les labels d'un facteur de 0.7\n     cex.axis = 0.6, # Réduit les labels des graduations d'un facteur de 0.6 \n     xlab = \"Années\", # Label abscisses \n     ylab = \"Part des jeunes (%) dans la population totale\") # Label ordonnées\n\nlines(mar$Year, \n      mar$YOUNG_RT, # Rajouter une ligne (Maroc)\n      col = \"darkgreen\", \n      type = \"l\",\n      cex = .6)\n\nlines(tun$Year,  # Et Tunisie\n      tun$YOUNG_RT, \n      type = \"l\", \n      cex = .6,\n      col = \"red\")\n\n# Organisation de la légende\nlegend(x = \"topright\",\n       legend = c(\"Algérie\", \"Maroc\", \"Tunisie\"),\n       col = c(\"blue\", \"darkgreen\", \"red\"), lty = 1,\n       cex = .8)"
  },
  {
    "objectID": "INT3_Importe_R.html#graphiques-interactifs",
    "href": "INT3_Importe_R.html#graphiques-interactifs",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Graphiques interactifs",
    "text": "Graphiques interactifs\nLe package plotly (Sievert et al. 2024) permet d’associer aux graphiques une dimension interactive. Pour utiliser les fonctions de ce package, il faut bien avoir en tête le format de données attendu (format long).\n\nlibrary(plotly)\n\n# Importer jeu de données d'exemple de gapminder\ngap &lt;- read.csv(\"data/data_intro/world/data/gapminder.csv\")\n\nhead(gap)\n\n      country continent year lifeExp      pop gdpPercap\n1 Afghanistan      Asia 1952  28.801  8425333  779.4453\n2 Afghanistan      Asia 1957  30.332  9240934  820.8530\n3 Afghanistan      Asia 1962  31.997 10267083  853.1007\n4 Afghanistan      Asia 1967  34.020 11537966  836.1971\n5 Afghanistan      Asia 1972  36.088 13079460  739.9811\n6 Afghanistan      Asia 1977  38.438 14880372  786.1134\n\n# Paramétrage des cercles proportionnels\narea_max &lt;- 2000 # Diamètre maximal\narea_min &lt;- area_max/(max(gap$pop)/min(gap$pop)) # Diamètre minimal\n\n# Créer un graphique de type \"Multiple Trace Animations\"\nfig &lt;- gap %&gt;%\n  plot_ly(\n    x = ~gdpPercap, # Variable X\n    y = ~lifeExp,   # Variable Y\n    size = ~pop,    # Taille des cercles \n    color = ~continent,  # Couleur des cercles \n    frame = ~year, # Animation temporelle \n    sizes = c(area_min, area_max), # Gestion taille cercles\n    marker = list(opacity = 0.5, sizemode = 'area'), # Taille et opacité\n    text = ~country,  #  Nom du champ qui s'affichera interactivement\n    hoverinfo = \"text\", \n    type = 'scatter', # Type de graphique\n    mode = 'markers' # Mode de représentation des figurés\n  )\n\n# Paramétrer l'échelle, les labels, etc.\nfig &lt;- fig %&gt;% layout(\n    xaxis = list(type = \"log\", title = \"PIB par habitant\"),\n    yaxis = list(title = \"Espérance de vie\")\n  )\n\nfig\n\n\n\n\n\n\n\n\n\n\n\nPour aller plus loin\n\n\n\n\n\nr-graph-gallery présente les possibilités graphiques les plus courantes, en langage de base R. L’exploration de la syntaxe ggplotet son package de référence ggplot2 peut être utile pour la recherche de représentations graphiques avancées. Cette syntaxe est un peu différente du langage de base R et repose sur les principes de la “grammaire des graphiques”. Plusieurs manuels très bien construits permettent de rentrer dans l’univers de la visualisation de données avec ggplot2, comme Modern Data Visualization with R (Kabacoff 2023)\n\n\n\nTransition Plot réalisé avec les packages ggplot2 et ggallivial (R. Ysebaert, 2024)"
  },
  {
    "objectID": "INT3_Importe_R.html#import",
    "href": "INT3_Importe_R.html#import",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Import",
    "text": "Import\nLe geopackage est un format de données ouvert qui permet de stocker plusieurs couches géographiques dans un même fichier. La fonction st_layers() permet d’avoir un aperçu des couches présentes dans un geopackage.\n\nlibrary(sf)\n\nst_layers(\"data/data_intro/tun/geom/tun_admin.gpkg\")\n\nDriver: GPKG \nAvailable layers:\n   layer_name geometry_type features fields                      crs_name\n1  delegation Multi Polygon      266     11 ETRS89-extended / LAEA Europe\n2 gouvernorat Multi Polygon       24      4 ETRS89-extended / LAEA Europe\n3      region Multi Polygon        6      2 ETRS89-extended / LAEA Europe\n\n\nImporter des couches géographiques avec st_read().\n\ndel &lt;- st_read(\"data/data_intro/tun/geom/tun_admin.gpkg\", layer = \"delegation\", quiet = TRUE)\ngouv &lt;- st_read(\"data/data_intro/tun/geom/tun_admin.gpkg\", layer = \"gouvernorat\", quiet = TRUE)\nreg &lt;- st_read(\"data/data_intro/tun/geom/tun_admin.gpkg\", layer = \"region\", quiet = TRUE)\n\nIl s’agit bien d’objets sf.\n\nclass(del)\n\n[1] \"sf\"         \"data.frame\"\n\n\nLa fonction st_read() peut aussi être employée pour des formats de fichiers .geojson, .shapefiles, etc.\n\nreg &lt;- st_read(\"data/data_intro/tun/geom/map_reg.geojson\", quiet = TRUE) \n\nLes objets sf sont des data.frame dont l’une des colonnes contient des géométries. Cette colonne est de la classe sfc (simple feature column) et chaque individu de la colonne est un sfg (simple feature geometry).\n\nhead(del)\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 4184398 ymin: 1282883 xmax: 4380989 ymax: 1539573\nProjected CRS: ETRS89-extended / LAEA Europe\n  del_code   del_nom_fr del_code_riate del_code_ins     del_nom_ar gou_code\n1 TN.SF.AG       Agareb         TS2146        TN347          عقارب    TN.SF\n2 TN.JE.AD   Ain Drahem         TS1224        TN225      عين دراهم    TN.JE\n3 TN.SS.AK       Akouda         TS2115        TN316          اكودة    TN.SS\n4 TN.KR.AL         Alaa         TS2216        TN417         العلاء    TN.KR\n5 TN.BJ.AM       Amdoun         TS1212        TN213          عمدون    TN.BJ\n6 TN.AN.AR Ariana Ville         TS1120        TN121 أريانة المدينة    TN.AN\n   gou_nom gou_cap gou_cap_dist reg_code      reg_nom\n1     Sfax       0         30.1       CE   Centre-est\n2 Jendouba       0         38.5       NO   Nord-ouest\n3   Sousse       0         14.3       CE   Centre-est\n4 Kairouan       0         48.6       CO Centre-ouest\n5     Beja       0         18.9       NO   Nord-ouest\n6   Ariana       1          1.0       NE     Nord-est\n                            geom\n1 MULTIPOLYGON (((4375308 130...\n2 MULTIPOLYGON (((4224769 152...\n3 MULTIPOLYGON (((4373533 142...\n4 MULTIPOLYGON (((4306097 141...\n5 MULTIPOLYGON (((4243838 153...\n6 MULTIPOLYGON (((4338370 153..."
  },
  {
    "objectID": "INT3_Importe_R.html#affichage",
    "href": "INT3_Importe_R.html#affichage",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Affichage",
    "text": "Affichage\nAperçu des variables avec plot() :\n\nplot(del)\n\n\n\n\nAfficher juste les géométries:\n\n# 3 cartes par ligne\npar(mfrow = c(1,3), mar = c(2,2,2,2))\n\n# Délégations\nplot(del$geom, # Géométries uniquement\n     col = \"peachpuff\", # Couleur du fond\n     border = \"white\", # Couleur de bordure\n     main = \"Délégations\") # Titre\n\n# Gouvernorats\nplot(gouv$geom, \n     col = \"peachpuff\", \n     border = \"white\",\n     main = \"Gouvernorats\")\n\n# \"Régions\"\nplot(reg$geom, \n     col = \"peachpuff\",\n     border = \"white\",\n     main = \"Régions\")"
  },
  {
    "objectID": "INT3_Importe_R.html#manipulations-de-base",
    "href": "INT3_Importe_R.html#manipulations-de-base",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Manipulations de base",
    "text": "Manipulations de base\n\nJointures attributaires\nNous pouvons joindre un data.frame à un objet sf en utilisant la fonction merge() et en s’appuyant sur des identifiants communs aux deux objets.\nAttention à l’ordre des arguments, l’objet retourné sera du même type que x. Il n’est pas possible de faire une jointure attributaire en utilisant deux objets sf.\n\ndel &lt;-  merge(\n  x = del[,\"del_code\"],  # L'objet sf (seulement le champ del_code)\n  y = del_df,          # le data.frame\n  by.x = \"del_code\",  # identifiant dans x\n  by.y = \"del_code\",  # identifiant dans y\n  all.x = TRUE         # conserver toutes les lignes\n)\n\nhead(del)\n\nSimple feature collection with 6 features and 30 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 4321914 ymin: 1528813 xmax: 4346090 ymax: 1562156\nProjected CRS: ETRS89-extended / LAEA Europe\n  del_code         del_nom_fr     del_nom_ar gou_code gou_nom gou_cap\n1 TN.AN.AR       Ariana Ville أريانة المدينة       AN  Ariana       1\n2 TN.AN.ET    Cité Ettathamen     حي التضامن       AN  Ariana       0\n3 TN.AN.KA kalaât El Andalous   قلعة الاندلس       AN  Ariana       0\n4 TN.AN.LS             Soukra           سكرة       AN  Ariana       0\n5 TN.AN.MN             Mnihla       المنيهلة       AN  Ariana       0\n6 TN.AN.RA             Raoued           رواد       AN  Ariana       0\n  gou_cap_dist reg_code  reg_nom popto_2004 popco_2004 immig_2004 emigr_2004\n1          1.0       NE Nord-est      97687      97687      16961      15426\n2          8.8       NE Nord-est      78311      78311       5651       5245\n3         19.8       NE Nord-est      23045      15313        728        528\n4          6.7       NE Nord-est      89151      89151      19129       2832\n5          8.0       NE Nord-est      53752      40176       7258        985\n6          8.8       NE Nord-est      60896      53911      14053       1443\n  mobil_2004 menag_2004 ordin_2004 porta_2004 telef_2004 popto_2014 popco_2014\n1      32387      27468       9751      22524      18596     114486     114486\n2      10896      11950        430       4505       3824      84312      84312\n3       1256       4709        188       1865        829      26796      18211\n4      21961      21590       2979      13321       9262     129693     129693\n5       8243      17119        685       7087       7019      89884      58641\n6      15496      14276       2327       9022       6339     106414      94961\n  immig_2014 emigr_2014 mobil2014 menag_2014 ordin_2014 porta_2014 telef_2014\n1      15637      20448     36085      32498      25474      32308      19942\n2       5028       6752     11780      22087       6836      21715       3496\n3       1104        752      1856       6554       1701       6305        428\n4      20786       5528     26314      33981      18191      33683       9831\n5      14400       1828     16228      22781       8326      22531       4249\n6      20128       2521     22649      27574      14284      27338       7505\n  popto_2010 surfa_2010 idr_2011                           geom\n1     109500     18.612    0.638 MULTIPOLYGON (((4338370 153...\n2      82922      3.376    0.386 MULTIPOLYGON (((4330561 153...\n3      24367    188.206    0.383 MULTIPOLYGON (((4333853 156...\n4     107829     27.895    0.557 MULTIPOLYGON (((4342368 153...\n5      69247     22.907    0.466 MULTIPOLYGON (((4332840 153...\n6      77419     57.080    0.531 MULTIPOLYGON (((4338691 154...\n\nplot(del[,\"idr_2011\"])\n\n\n\n\n\n\nSélectionner des lignes, des colonnes\nLes objets sf sont des data.frame, on peut donc sélectionner leur lignes et leur colonnes de la même manière.\n\n# Sélection de lignes\nsou &lt;- del[del$gou_nom == \"Sousse\",]\n\n# Sélection de colonnes\nsou &lt;- sou[,\"idr_2011\"]\n\n# Ne conserver que les lignes avec une valeur\nsou &lt;- sou[!is.na(sou$idr_2011),]\n\nplot(sou[,\"idr_2011\"])"
  },
  {
    "objectID": "INT3_Importe_R.html#export-1",
    "href": "INT3_Importe_R.html#export-1",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Export",
    "text": "Export\n\nst_write(\"data/data_intro/tun/geom/sousse_deleg.geojson\")"
  },
  {
    "objectID": "INT3_Importe_R.html#import-1",
    "href": "INT3_Importe_R.html#import-1",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Import",
    "text": "Import\nLa fonction rast() permet de créer et/ou d’importer des données raster. Nous importons ici un jeu de données au format .tif créé et distribué par WorldPop qui porte sur une estimation de la population tunisienne dans une résolution d’1 km (aussi accessible à 100 mètres).\n\nlibrary(terra)\npop &lt;- rast(\"data/data_intro/tun/geom/pop.tif\")\n\nCe sont des objets de type SpatRaster.\n\npop\n\nclass       : SpatRaster \ndimensions  : 879, 488, 1  (nrow, ncol, nlyr)\nresolution  : 0.008333333, 0.008333333  (x, y)\nextent      : 7.532083, 11.59875, 30.24125, 37.56625  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : pop.tif \nname        :      pop \nmin value   :     0.00 \nmax value   : 23068.07 \n\n\nLa fonction summary() est toujours utile pour un résumé statistique des cellules. Vu le nombre important de cellules, ce résumé est effectué sur un échantillon.\n\nsummary(pop)\n\n      pop          \n Min.   :    0.00  \n 1st Qu.:    0.95  \n Median :    9.16  \n Mean   :   53.95  \n 3rd Qu.:   25.72  \n Max.   :18878.24  \n NA's   :49070"
  },
  {
    "objectID": "INT3_Importe_R.html#affichage-1",
    "href": "INT3_Importe_R.html#affichage-1",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Affichage",
    "text": "Affichage\nPar défaut et comme montré précédemment, la fonction plot() renvoie une légende continue sur les représentations cartographiques. On peut choisir de discrétiser cette information pour représenter des classes de valeur associée à une palette de couleurs personnalisée.\n\npar(mfrow = c(1,2))\n\n# Graphique en échelle continue\nplot(pop)\n\n# Avec discrétisation et paramétrage des couleurs\ncuts &lt;- c(0, 5, 25, 50, 250, 500, 2000, 18879)\ncols &lt;- colorRampPalette(c(\"yellow\", \"darkgoldenrod1\", \"brown2\"))\nplot(pop, breaks = cuts, col = cols(7))"
  },
  {
    "objectID": "INT3_Importe_R.html#manipulation-de-base",
    "href": "INT3_Importe_R.html#manipulation-de-base",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Manipulation de base",
    "text": "Manipulation de base\nLe découpage d’un raster en fonction de l’étendue d’un autre objet, SpatVector ou SpatRaster, est réalisable avec la fonction crop(). Les deux couches de données doivent être dans la même projection.\n\n# Transformer en WGS 84\nsou &lt;- st_transform(sou, 4326)\n\n# Crop avec la délégation de Sousse\npop_sou &lt;- crop(pop, sou)\n\n# Plot\nplot(pop_sou, breaks = cuts, col = cols(8))\nplot(sou$geom, col = NA, add = TRUE)"
  },
  {
    "objectID": "INT3_Importe_R.html#export-2",
    "href": "INT3_Importe_R.html#export-2",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Export",
    "text": "Export\nLa fonction writeRaster() permet d’enregistrer un objet SpatRaster.\n\nwriteRaster(x = pop_sou, filename = \"data/data_intro/tun/geom/pop_sou.tif\")"
  },
  {
    "objectID": "INT3_Importe_R.html#geodata",
    "href": "INT3_Importe_R.html#geodata",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "geodata",
    "text": "geodata\nCe package facilite l’accès à des données géographique de référence sur le climat, la couverture du sol, les limites administratives et plusieurs autres jeux de données de référence au niveau mondial.\n\n\n\n\n\n\nLes couches géographiques inclues dans le package geodata\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nbio_oracle\nMarine data from Bio-Oracle\n\n\ncmip6_world, cmip6_tile\nDownscaled and calibrated CMIP6 projected future climate data\n\n\ncountry_codes\nCountry codes\n\n\ncrop_calendar_sacks\nCrop calendar data by Sacks et al\n\n\ncrop_monfreda\nCrop area and yield data for 175 crops by Monfreda et al.\n\n\ncrop_spam\nMapSPAM crop data (area, yield, value)\n\n\ncropland\nCropland density for the world derived from different sources (ESA, GLAD, QED)\n\n\nelevation_3s, elevation_30s, elevation_global\nElevation data\n\n\ngadm, world\nAdministrative boundaries for any country, or the entire world from GADM\n\n\nlandcover\nLandcover data derived from ESA WorldCover\n\n\nfootprint\nHuman footprint data from the Last of the Wild project\n\n\nosm\nOpenStreetMap data by country (places and roads)\n\n\npopulation\nPopulation density Gridded Population of the World\n\n\nsoil_af\nChemical and physical soil properties data for Africa for different soil depths\n\n\nsoil_af_elements\nConnect to or download chemical soil element concentration (for the 0-30 cm topsoil) data for Africa\n\n\nsoil_af_water\nPhysical soil properties data for Africa for water balance computation\n\n\nsoil_af_isda\nSoil data for Africa derived from the iDSA data set\n\n\nsoil_world_vsi\nVirtually connect to the global SoilGrids data\n\n\nsoil_world\nGlobal soils data from SoilGrids\n\n\nsp_occurrence\nSpecies occurrence records from the Global Biodiversity Information Facility\n\n\ntravel_time\nTravel time to and from cities and ports by Nelson et al.\n\n\nworldclim_global, worldclim_country, worldclim_tile\nWorldClim glocal climate data\n\n\n\n\n\n\nExtraction des couches géographiques d’altitude et de température en Tunisie.\n\nlibrary(geodata)\nelev &lt;- elevation_30s(country = \"TUN\", path = tempdir())\ntemp &lt;- worldclim_country(country = \"Tunisia\", \n                          res = 10, \n                          var = \"tavg\",\n                          path = tempdir())\n\nCe sont des objets de type SpatRaster.\n\nclass(temp)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\nclass(elev)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\n\n# Les afficher\npar(mfrow = c(1,2))\n\n# Altitude\ncols &lt;- colorRampPalette(c(\"#31ad37\", \"#f5f752\", \"#fca330\", \"#9c5903\"))\nplot(elev, main = \"Altitude\", col = cols(50))\n     \n# Température\ncols &lt;- colorRampPalette(c(\"#4575b4\", \"#91bfdb\", \"#e0f3f8\", \n                           \"#fee090\", \"#fc8d59\", \"#d73027\"))\nplot(temp$TUN_wc2.1_30s_tavg_5, main = \"Températures, Mai (1970-2000)\",\n     col = cols(50))"
  },
  {
    "objectID": "INT3_Importe_R.html#natural-earth-et-banque-mondiale.",
    "href": "INT3_Importe_R.html#natural-earth-et-banque-mondiale.",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Natural Earth et Banque Mondiale.",
    "text": "Natural Earth et Banque Mondiale.\n\n\n\n\n\n\nObjectif\n\n\n\nNous cherchons ici à créer une carte de la part de la couverture forestière en Afrique en utilisant les données de la banque mondiale et le fond de carte Natural Earth. Rien besoin de télécharger, mais il faut une connexion internet.\n\n\nPlusieurs fonds de carte des pays du Monde à différents niveaux de généralisation cartographique sont disponibles avec la package rnaturalearth. Nous sélectionnons uniquement les pays africains.\n\nlibrary(rnaturalearth)\n\n# Import des pays\ncountry &lt;- ne_countries(type = \"countries\", # pays\n                        scale = \"small\",  # niveau de généralisation\n                        returnclass = \"sf\") # objet retourné\n\n# Conversion en projection Mercator\ncountry &lt;- st_transform(country, crs = \"EPSG:3857\")\n\n# Si on s'intéresse à l'Afrique (modèle carto)\nafr &lt;- country[country$continent == \"Africa\",]\n\nLe package wbstatspermet d’interroger l’API de la base de données de la Banque Mondiale. On peut faire une recherche pour trouver le nom des tables qui répondent à une requête par mots-clés avec la fonction wb_search().\n\nlibrary(wbstats)\n\nwb_search(\"Forest.area\")\n\n# A tibble: 6 × 3\n  indicator_id                   indicator                        indicator_desc\n  &lt;chr&gt;                          &lt;chr&gt;                            &lt;chr&gt;         \n1 AG.LND.FRST.HA                 Forest area (hectares)           Forest area i…\n2 AG.LND.FRST.K2                 Forest area (sq. km)             Forest area i…\n3 AG.LND.FRST.ZS                 Forest area (% of land area)     Forest area i…\n4 ER.FST.DFST.ZG                 Annual deforestation (% of chan… Average annua…\n5 IN.ENV.COASTALZONE.FOREST.AREA Forest (Non- tidal)/ Plantation… &lt;NA&gt;          \n6 IN.ENV.FOREST.AREA             Forest Cover  ('000 hectares)    &lt;NA&gt;          \n\n\n\n\n\n\n\n\nAvertissement\n\n\n\nChaque package reposant sur une API a son fonctionnement propre. Il est donc conseillé de consulter attentivement la documentation associée à ces packages (souvent précise) pour apprendre à les utiliser. Par ailleurs les validité des extractions réalisées est dépendante des fournisseurs de données. Si le contenu de la base de donnée évolue (organisation, nom des indicateurs, etc.), le code R sur lequel repose l’extraction des données peut ne plus s’exécuter correctement avec le temps. Pour éviter ce type de désagrément, il peut être utile de sauvegarder le résultat de l’export des données.\n\n\nLa fonction wb_data() extrait la table de la banque Mondiale qui nous intéresse.\n\n# Sélection des indicateurs\nwb &lt;- wb_data(\"AG.LND.FRST.ZS\", return_wide = FALSE)\nhead(wb)\n\n# A tibble: 6 × 11\n  indicator_id   indicator      iso2c iso3c country  date value unit  obs_status\n  &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     \n1 AG.LND.FRST.ZS Forest area (… AF    AFG   Afghan…  2023 NA    &lt;NA&gt;  &lt;NA&gt;      \n2 AG.LND.FRST.ZS Forest area (… AF    AFG   Afghan…  2022  1.85 &lt;NA&gt;  &lt;NA&gt;      \n3 AG.LND.FRST.ZS Forest area (… AF    AFG   Afghan…  2021  1.85 &lt;NA&gt;  &lt;NA&gt;      \n4 AG.LND.FRST.ZS Forest area (… AF    AFG   Afghan…  2020  1.85 &lt;NA&gt;  &lt;NA&gt;      \n5 AG.LND.FRST.ZS Forest area (… AF    AFG   Afghan…  2019  1.85 &lt;NA&gt;  &lt;NA&gt;      \n6 AG.LND.FRST.ZS Forest area (… AF    AFG   Afghan…  2018  1.85 &lt;NA&gt;  &lt;NA&gt;      \n# ℹ 2 more variables: footnote &lt;chr&gt;, last_updated &lt;date&gt;\n\n\nLa fonction reshape() est utilisée pour transformer le data.frame dans un format plus conforme à nos habitudes (long vers large) : les pays dans la première colonne, puis la série temporelle disponible en colonnes.\n\n# Ordonner par année\nwb &lt;- wb[order(wb$date),]\n\n# Sélectionner les colonnes d'intérêt\nwb &lt;- data.frame(wb[,c(\"iso3c\", \"date\", \"value\")])\n\n# Reformater au format long\nwb &lt;- reshape(wb, \n              idvar = \"iso3c\", # identifiants\n              timevar = \"date\", # variable contenant les dates \n              direction = \"wide\") # format long\n\n# Résultat pour quelques colonnes\nhead(wb[,c(\"iso3c\", \"value.2020\", \"value.2021\", \"value.2022\", \"value.2023\")])\n\n  iso3c value.2020 value.2021 value.2022 value.2023\n1   AFG   1.852782  1.8527820   1.852782         NA\n2   ALB  28.791971 28.7919708  28.791971         NA\n3   DZA   0.818309  0.8222276   0.826333         NA\n4   ASM  85.650000 85.5000000  85.350000         NA\n5   AND  34.042553 34.0425532  34.042553         NA\n6   AGO  53.426951 52.9817224  52.536497         NA\n\n\nNous cherchons l’année la plus récente pour laquelle nous disposons d’un maximum de valeurs. Cette ligne de code permet de dénombrer le nombre de NA pour chaque colonne du jeu de données. 2021 est l’année la plus récente avec le moins de valeurs manquantes.\n\n# Regarder le nombre de données manquantes\nsapply(wb, function(x) sum(length(which(is.na(x)))))\n\n     iso3c value.1960 value.1961 value.1962 value.1963 value.1964 value.1965 \n         0        217        217        217        217        217        217 \nvalue.1966 value.1967 value.1968 value.1969 value.1970 value.1971 value.1972 \n       217        217        217        217        217        217        217 \nvalue.1973 value.1974 value.1975 value.1976 value.1977 value.1978 value.1979 \n       217        217        217        217        217        217        217 \nvalue.1980 value.1981 value.1982 value.1983 value.1984 value.1985 value.1986 \n       217        217        217        217        217        217        217 \nvalue.1987 value.1988 value.1989 value.1990 value.1991 value.1992 value.1993 \n       217        217        217         39         35         16         12 \nvalue.1994 value.1995 value.1996 value.1997 value.1998 value.1999 value.2000 \n        12         12         12         12         12         12         10 \nvalue.2001 value.2002 value.2003 value.2004 value.2005 value.2006 value.2007 \n        10         10         10         10         10          8          8 \nvalue.2008 value.2009 value.2010 value.2011 value.2012 value.2013 value.2014 \n         8          8          8          5          3          3          3 \nvalue.2015 value.2016 value.2017 value.2018 value.2019 value.2020 value.2021 \n         3          3          3          3          3          3          3 \nvalue.2022 value.2023 \n         7        217 \n\n\nNous réalisons pour une finir une jointure attributaire avec le fond de carte précédemment importé avec rnaturalearth. La cartographie est réalisée avec la fonction mf_map du package mapsf, dont le fonctionnement sera présenté ultérieurement dans la formation.\n\n# Jointure attributaire\nafr &lt;- merge(x = afr[,c(\"adm0_a3\", \"name_fr\")], # fond de carte\n             wb, # jeu de données de la banque mondiale\n             by.x = \"adm0_a3\", # champ de jointure fond de carte\n             by.y = \"iso3c\", # champ de jointure jeu de données\n             all.x = TRUE) # conserver toutes les géométries\n\n# Carte avec la librairie map sf\nlibrary(mapsf)\nmf_map(afr, # objet sf\n       var = \"value.2021\", # variable \n       type = \"choro\", # type choroplèthe\n       breaks = \"quantile\", # méthode de discrétisation\n       nbreaks = 5, # nombre de classes\n       leg_title = \"Part de la surface totale (%)\", # titre de légende\n       leg_adj = c(0, 2)) # ajustement position légende\n\nmf_layout(title = \"Surface forestière 2021\",  # titre de la carte\n          credits = \"Source: Banque Mondiale, 2024\", # sources\n          scale = FALSE) # pas d'échelle"
  },
  {
    "objectID": "INT3_Importe_R.html#extraction-et-mise-en-forme",
    "href": "INT3_Importe_R.html#extraction-et-mise-en-forme",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Extraction et mise en forme",
    "text": "Extraction et mise en forme\nLe package osmextract (Gilardi et Lovelace 2023) permet d’extraire de télécharger des données OSM pour une zone géographique donnée. Cela permet aussi d’éviter de surcharger un serveur Overpass turbo (utilisé par le package osmdata) et ainsi de travailler sur des volumes de données plus importants.\n\nDécoupages administratifs\nLa fonction oe_get() permet de télécharger un extrait de la base de données OSM pour une zone particulière et un type d’objet géographique. L’argument place correspond au nom du fichier *.pbf accessible sur le site Geofabrik. L’argument extra_tag permet de sélectionner les objets de la base OSM correspondant à une clé particulière (se référer à la documentation d’OSM pour choisir les clés).\nOn commence par extraire tous les polygones et les points OSM inclus en Tunisie. L’import d’extra_tags permet d’obtenir des informations supplémentaires qui serviront à filtrer la base de données.\n\nN.B. : L’extraction peut durer quelques minutes, même avec une bonne connexion\n\n\nlibrary(osmextract)\nosm_poly &lt;- oe_get(place = \"Tunisia\",\n                   layer = \"multipolygons\",\n                   extra_tags = c(\"amenity\", \"ref:tn:hasc_2\", \"ref:tn:codegeo\",\n                                  \"name:fr\", \"name:ar\"))\n\nosm_pt &lt;- oe_get(place = \"Tunisia\",\n                 layer = \"points\",\n                 extra_tags = c(\"amenity\", \"name:fr\", \"name:ar\"))\n\nOn peut ensuite filtrer l’extraction en fonction des objets / champs d’intérêt.\n\n# Délégations et secteurs\nadmin &lt;- osm_poly[!is.na(osm_poly$admin_level),] # Retirer pas d'attribut de niveau hiérarchique\ndeleg &lt;- admin[admin$admin_level == 5,] # Délégations\nsect &lt;- admin[admin$admin_level == 6,] # Secteurs\n\n# Ne garder que les champs utiles\ndeleg &lt;- deleg[,c(\"osm_id\", \"ref_tn_codegeo\", \"ref_tn_hasc_2\", \"name_ar\",  \n                  \"name_fr\", \"admin_level\")]\nsect &lt;- sect[,c(\"osm_id\", \"ref_tn_codegeo\", \"name_ar\",  \n                  \"name_fr\", \"admin_level\")]\n\nCe bloc de code, dont on ne détaillera pas le contenu ici, permet d’harmoniser le nom des champs entre les couches géographiques et de disposer des délégations et gouvernorats d’appartenance des couches géographiques des secteurs et délégations.\n\n# Délégation d'appartenance du secteur\nsect_pt &lt;- st_centroid(sect) # Centroide du secteur\nsect_pt &lt;- st_intersection(sect_pt, deleg) # Intersection avec couche délégation\nsect_pt &lt;- st_set_geometry(sect_pt, NULL) # Retirer géométries\nsect &lt;- merge(sect, # Enrichir les secteurs du code d'appartenance de la délégation\n              sect_pt[,c(\"osm_id\", \"ref_tn_hasc_2\")], \n              by = \"osm_id\", \n              all.x = TRUE)\nsect &lt;- sect[!duplicated(sect$osm_id),] # Retirer valeurs dupliquées\n\n# Renommer colonnes\nnames(sect)[2] &lt;- \"id_tn\"\nnames(sect)[6] &lt;- \"id_hasc_deleg\"\nsect$id_hasc_gouv &lt;- substr(sect$id_hasc_deleg, 1, 5) # Gouvernorat d'appartenance\nnames(sect)[2,6] &lt;- (c(\"tn_codegeo\", \"int_codegeo\"))\ndeleg$id_hasc_gouv &lt;- substr(deleg$id_hasc_deleg, 1, 5)\n\n\n\nÉquipements\nLes objets décrits par la clé amenity sont de nature hétérogènes (points, polygones). Ce bloc de code extrait les centroides des polygones et les associent à la couche de points initiale.\nCes couches géographiques sont finalement exportées dans un geopackage tun_osm.gpkg.\n\n# Consolidation des géométries\nsel_poly &lt;- osm_poly[!is.na(osm_poly$amenity),] # Retirer les objets qui n'ont pas de clé amenity\nsel_pt &lt;- osm_pt[!is.na(osm_pt$amenity),]\nsel_poly &lt;- st_make_valid(sel_poly) # Consolider les géométries des polygones\nsel_pt2 &lt;- st_centroid(sel_poly) # extraire le centroide\ncols &lt;- intersect(names(sel_pt), names(sel_pt2)) # Garder les colonnes identiques\nsel_pt &lt;- rbind(sel_pt[,cols, sel_pt2[,cols]]) # Combiner points et polygones\nsel_pt &lt;- sel_pt[,c(\"osm_id\", \"amenity\", \"name_ar\", \"name_fr\")]\n\n# Exporter les couche ainsi créées\nst_write(sel_pt, \"data/tun/geom/tun_osm.gpkg\", layer = \"poi\")\nst_write(deleg, \"data/tun/geom/tun_osm.gpkg\", layer = \"deleg\")\nst_write(sect, \"data/tun/geom/tun_osm.gpkg\", layer = \"sect\")\n\n\n\n\n\n\n\nPour aller plus loin\n\n\n\n\n\nCe document (Giraud 2017) montre comment créer un fond de carte avec des données OSM, extraire des objets d’intérêt (bars et restaurants) avec le package osmdata. Il propose également plusieurs pistes cartographiques pour manipuler et visualiser ces données. Notons simplement que la cartographie utilise les fonctions du package cartography, plus maintenu, et qu’il est conseillé d’utiliser dorénavant le package mapsf.\n\n\n\nCartographic Explorations of the OpenStreetMap Database with R (Giraud, 2017)"
  },
  {
    "objectID": "INT3_Importe_R.html#résultats-de-lextraction",
    "href": "INT3_Importe_R.html#résultats-de-lextraction",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Résultats de l’extraction",
    "text": "Résultats de l’extraction\nDénombrement des 15 objets OSM les plus fréquents décrits par la clé amenity en Tunisie.\n\n# Import des aménités préparées en amont\nosm_pt &lt;- st_read(\"data/data_intro/tun/geom/tun_osm.gpkg\", layer = \"poi\", quiet = TRUE)\n\n# Nombre de points avec le tag \"amenity\". \ntbl &lt;- table(osm_pt$amenity)\ntbl &lt;- tbl[order(tbl, decreasing = TRUE)]\ntbl[1:15]\n\n\n            cafe       restaurant place_of_worship             bank \n            2680             1272             1094              996 \n          school         pharmacy        fast_food             fuel \n             916              700              597              525 \n     post_office           police              bar          parking \n             327              153              135              135 \n         doctors              atm          dentist \n             113              109              109 \n\n# On ne prend ici que les cliniques et hôpitaux\nosm_pt &lt;- osm_pt[osm_pt$amenity %in% c(\"clinic\", \"hospital\"), ]\n\nNombre de délégations, secteurs et cliniques/hôpitaux inclus dans OSM.\n\n# Import des unités territoriales préparées en amont\ndeleg &lt;- st_read(\"data/data_intro/tun/geom/tun_osm.gpkg\", layer = \"deleg\", quiet = TRUE)\nsect &lt;- st_read(\"data/data_intro/tun/geom/tun_osm.gpkg\", layer = \"sect\", quiet = TRUE)\n\n# Nombre d'objets (lignes)\nnrow(deleg)\n\n[1] 266\n\nnrow(sect)\n\n[1] 2104\n\nnrow(osm_pt)\n\n[1] 119\n\n\nLe résultat sous forme d’une carte interactive avec le package leaflet, qui sera présenté ultérieurement dans la formation.\n\n\nCode\n# Choisir la palette\nlibrary(leaflet)\npal &lt;- colorFactor(palette = c(\"red\", \"gold\"),\n                   domain = c(\"clinic\", \"hospital\"))\n\n# Cartographie interactive\nleaflet(osm_pt) |&gt; # Emprise = hôpitaux\n  addProviderTiles(\"OpenStreetMap.HOT\") |&gt; # Type de tuiles chargées\n  addPolygons(data = sect, # Secteurs\n              col = \"white\",\n              fillColor = \"lightgrey\",\n              fillOpacity = 0.7,\n              weight = 1,\n              popup = paste0(\"&lt;b&gt;\", sect$id_tn, \"&lt;br&gt;&lt;/b&gt;\",\n                             sect$name_ar, \"&lt;br&gt;\", sect$name_fr),\n              group = \"Secteurs\")|&gt;\n  addPolygons(data = deleg, # Délégations\n              col = \"darkgrey\",\n              fill = \"lightgrey\",\n              fillOpacity = 0,\n              weight = 1.2,\n              popup = paste0(\"&lt;b&gt;\", deleg$id_tn, \" / \",\n                             deleg$id_hasc_deleg,\"&lt;br&gt;&lt;/b&gt;\",\n                             deleg$name_ar, \"&lt;br&gt;\", deleg$name_fr),\n              group = \"Délégations\") |&gt;\n  addCircleMarkers(radius = 4, # Hôpitaux\n                   stroke = FALSE,\n                   color = ~ pal(amenity),\n                   fillOpacity = 1,\n                   popup = paste0(osm_pt$name_ar, \"&lt;br&gt;\", osm_pt$name_fr),\n                   group = \"Cliniques et hôpitaux\") |&gt;\n  addLegend(pal = pal, # Légende pour différencier cliniques et hôpitaux\n            values = c(\"clinic\", \"hospital\"),\n            opacity = 0.7,\n            title = \"OSM amenity\",\n            position = \"bottomright\") |&gt;\n  addLayersControl(overlayGroups = c(\"Secteurs\", \"Délégations\", \"Cliniques et hôpitaux\"),\n                   options = layersControlOptions(collapsed = FALSE))"
  },
  {
    "objectID": "INT3_Importe_R.html#matrices-de-temps-et-itinéraires",
    "href": "INT3_Importe_R.html#matrices-de-temps-et-itinéraires",
    "title": "GEO UNIV’R Tunisie 2024",
    "section": "Matrices de temps et itinéraires",
    "text": "Matrices de temps et itinéraires\nLe package osrm (Giraud (2022)) sert d’interface entre R et le service de calcul d’itinéraire OSRM (Luxen et Vetter, 2011). Ce package permet de calculer des matrices de temps et de distances, des itinéraires routiers, des isochrones. Le package utilise par défaut le serveur de démo d’OSRM. En cas d’utilisation intensive il est fortement recommandé d’utiliser sa propre instance d’OSRM avec Docker.\nLa fonction osrmTable() permet de calculer des matrices de distances ou de temps par la route. Nous effectuons cette opération à partir des données extraites plus haut :\n\nOrigines : centroides des secteurs de la délégation de Sousse.\nDestinations : hôpitaux et cliniques dans un voisinage géographique de 20 kilomètres autour de la délégation de Sousse.\n\n\n# Origines\nsel &lt;- sect[sect$id_hasc_gouv == \"TN.SS\",] # Secteurs de la délégation de Sousse\nsel &lt;- sel[!is.na(sel$osm_id),] # Géométries vides\nsel &lt;- sel[!duplicated(sel$osm_id),] # Géométries dupliquées\nori &lt;- st_centroid(sel) # Cenroide\n\n# Considérer les cliniques et hôpitaux dans un voisinage de 20 km autour de la délégation\nosm_pt &lt;- st_transform(osm_pt, 2088) # Transformer en coordonnées planaires\nsel &lt;- st_transform(sel, 2088)\ndest &lt;- st_filter(osm_pt, st_buffer(sel, 20000), .predicate = st_intersects) # Dans un rayon de 20 km\ndest &lt;- st_transform(dest, 4326)\n\n# Calcul de temps de trajets avec OSRM (pas grosse requête)\nlibrary(osrm)\ndf &lt;- osrmTable(src = ori, dst = dest, measure = \"duration\")\n\n# Extraire les temps de trajet\ndf &lt;- data.frame(df$durations)\n\n# Formater la table d'une manière arrangeante\ncolnames(df) &lt;- as.character(dest$osm_id)\nrow.names(df) &lt;- as.character(ori$osm_id)\nhead(df)\n\n        2109034339 2981447790 3756156059 4543660394 4967820121 4971604621\n7105249       55.3       68.3       58.5       58.1       80.2       78.3\n7105250       58.2       71.1       61.4       60.9       83.0       81.1\n7105251       56.9       69.8       60.1       59.6       81.8       79.8\n7105252       54.0       66.9       57.2       56.7       78.8       76.9\n7105253       45.1       58.0       48.3       47.8       69.9       68.0\n7105254       58.7       71.6       61.9       61.5       83.6       81.7\n        5516163723 5673214937 5778893454 7919870954 10759343505 11756738948\n7105249       59.5       89.7       24.6       79.2        60.6        60.1\n7105250       62.3       92.5       25.8       82.5        63.4        62.9\n7105251       61.0       91.2       27.4       83.0        62.2        61.6\n7105252       58.1       88.3       33.2       77.0        59.3        58.7\n7105253       49.2       79.4       29.9       68.1        50.4        49.8\n7105254       62.9       93.0       48.4       77.6        64.0        63.4\n\n\nOn peut ensuite extraire le temps de trajet minimal par secteur avec la fonction apply()\n\ntime &lt;- apply(df, 1, min) \ntime &lt;- data.frame(time)\ntime$osm_id &lt;- row.names(time)\nhead(time)\n\n        time  osm_id\n7105249 24.6 7105249\n7105250 25.8 7105250\n7105251 27.4 7105251\n7105252 33.2 7105252\n7105253 29.9 7105253\n7105254 48.4 7105254\n\n\nNous finissons par une jointure attributaire avec la couche géographique des secteurs, ce qui permet de réaliser une représentation cartographique des résultats avec le package mapsf qui sera présenté ultérieurement dans la formation.\n\n\nCode\nsel &lt;- merge(sel, time, by = \"osm_id\", all.x = TRUE)\ndeleg &lt;- st_transform(deleg, 2088)\ndest &lt;- st_transform(dest, 2088)\n\nlibrary(mapsf)\npar(mfrow = c(1,1))\nmf_init(sel)\nmf_map(deleg, col = \"lightgrey\", \n       border = NA,\n       add = TRUE)\nmf_map(sel, \n       type = \"choro\",\n       var = \"time\",\n       nbreaks = 4,\n       border = \"white\", \n       leg_title = \"Minutes en voiture\", \n       add = TRUE)\nmf_map(deleg, col = NA, \n       border = \"black\",\n       add = TRUE)\nmf_map(dest, pch = 21, col = NA, bg = \"red\", add = TRUE)\nmf_scale(size = 10)\nmf_title(\"Délégation de Sousse : Temps de trajet vers l'hôpital ou la clinique la plus proche\")\nmf_credits(paste0(\"Source: © OpenStreetMap et Contributeurs, 2024\\n\",\n                  \"NB/ Toute chose égale par rapport à la complétude d'OSM. Contribuez pour compléter la carte le cas échéant !\"))"
  },
  {
    "objectID": "MOD3_Regression_multiple.html",
    "href": "MOD3_Regression_multiple.html",
    "title": "[MOD3] : Introduction à la régression multiple",
    "section": "",
    "text": "# liste des packages nécessaires\nliste_packages &lt;- c(\"knitr\", \"readxl\", \"corrplot\")\n# liste des éventuels packages à installer (= ceux qui ne sont pas déjà installés)\nnew_packages &lt;- liste_packages[!(liste_packages %in% installed.packages()[,\"Package\"])]\n# s'il y en a, installation \nif(length(new_packages)) install.packages(new_packages)\n# Importantc: définit les options pr défaut\nknitr::opts_chunk$set(echo = TRUE,  # n'affiche pas le code R\n                      warning = FALSE,\n                      message = FALSE)\nlibrary(knitr)  # Pour afficher les tableaux avec kable\nlibrary(readxl) # Pour importer le fichier Excel\nlibrary(corrplot) # Pour visualiser une matrice de corrélation facile à lire"
  },
  {
    "objectID": "MOD3_Regression_multiple.html#importation-des-données",
    "href": "MOD3_Regression_multiple.html#importation-des-données",
    "title": "[MOD3] : Introduction à la régression multiple",
    "section": "Importation des données",
    "text": "Importation des données\n\n# Importe les données\nlibrary(readxl)\ntab_depart &lt;-read_xlsx(path = \"data/TUN-CLIMAT/tun_climat.xlsx\",\n              sheet = \"data\")\nkable(tab_depart, caption = \"Tableau de données\")\n\n\nTableau de données\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode\nnom\nreg_code\nreg_nom\nlat\nlon\nalt\ntmin\ntmax\ntmoy\nprec\nvent\nrosee\n\n\n\n\nBJ\nBeja\nNO\nNord-ouest\n36.73333\n9.183333\n159.00\n11.45894\n24.62033\n18.55692\n590.000\n6.436291\n10.881502\n\n\nBZ\nBizerte\nNE\nNord-est\n37.24545\n9.791453\n6.09\n13.36735\n23.96475\n18.73467\n639.000\n13.080826\n13.507263\n\n\nGB\nGabes\nSE\nSud-est\n33.87692\n10.103333\n7.92\n15.62121\n25.44585\n20.64563\n192.000\n11.564158\n12.396331\n\n\nGF\nGafsa\nSO\nSud-ouest\n34.42202\n8.822503\n323.08\n13.73596\n26.88865\n20.42736\n163.000\n12.759514\n7.894512\n\n\nJE\nJendouba\nNO\nNord-ouest\n36.48333\n8.800000\n144.00\n12.03502\n25.75739\n19.17381\n458.000\n8.187385\n11.549468\n\n\nKR\nKairouan\nCO\nCentre-ouest\n35.66667\n10.100000\n68.00\n15.05704\n27.37991\n20.88537\n303.000\n5.826256\n10.894726\n\n\nKS\nKasserine\nCO\nCentre-ouest\n35.16667\n8.833333\n707.00\n11.47720\n24.13852\n18.46683\n340.000\n12.853035\n8.366253\n\n\nKB\nKebili\nSO\nSud-ouest\n33.70000\n8.966667\n46.00\n15.34825\n28.66706\n22.71979\n89.000\n14.061362\n10.373775\n\n\nKF\nLe Kef\nNO\nNord-ouest\n36.13333\n8.700000\n518.00\n10.30506\n23.19958\n17.24170\n528.000\n8.246948\n8.059934\n\n\nMH\nMahdia\nCE\nCentre-est\n35.50000\n11.066667\n12.00\n16.50674\n23.29379\n20.16491\n290.000\n10.854368\n14.624500\n\n\nME\nMedenine\nSE\nSud-est\n33.35000\n10.483333\n117.00\n16.17117\n27.56439\n22.57362\n159.000\n8.743863\n11.404804\n\n\nMS\nMonastir\nCE\nCentre-est\n35.66667\n10.750000\n2.00\n15.64783\n24.26410\n19.76152\n322.062\n13.888661\n13.587094\n\n\nNB\nNabeul\nNE\nNord-est\n36.46667\n10.700000\n78.00\n15.70167\n23.43309\n19.81197\n450.000\n12.190401\n14.033335\n\n\nSF\nSfax\nCE\nCentre-est\n34.71795\n10.690972\n25.90\n14.88812\n25.24082\n20.05744\n221.000\n11.408961\n12.427977\n\n\nSZ\nSidi Bou Zid\nCO\nCentre-ouest\n35.00000\n9.483333\n355.00\n13.03144\n26.20685\n20.25616\n280.000\n8.283933\n9.461638\n\n\nSL\nSiliana\nNO\nNord-ouest\n36.06667\n9.366667\n445.00\n11.36109\n24.50220\n19.02255\n389.000\n9.242761\n9.455365\n\n\nSS\nSousse\nCE\nCentre-est\n35.70000\n10.600000\n5.00\n15.70000\n24.40000\n19.90000\n310.000\n12.500000\n13.600000\n\n\nTA\nTataouine\nSE\nSud-est\n32.91667\n10.450000\n215.00\n15.90320\n27.20100\n21.41218\n110.000\n10.298155\n9.182343\n\n\nTO\nTozeur\nSO\nSud-ouest\n33.93972\n8.110556\n87.47\n16.83189\n28.64269\n22.63410\n97.000\n14.732460\n8.697420\n\n\nTU\nTunis\nNE\nNord-est\n36.85103\n10.227217\n6.70\n14.26899\n24.61744\n19.14238\n453.000\n13.405618\n12.626422\n\n\nZA\nZaghouan\nNE\nNord-est\n36.43333\n10.083333\n156.00\n12.43361\n25.06573\n18.57657\n501.000\n10.331711\n11.907365"
  },
  {
    "objectID": "MOD3_Regression_multiple.html#sélection-de-variables",
    "href": "MOD3_Regression_multiple.html#sélection-de-variables",
    "title": "[MOD3] : Introduction à la régression multiple",
    "section": "Sélection de variables",
    "text": "Sélection de variables\nPour la suite de l’exercice, nous retenons seulement quelques variables ou colonnes du tableau de départ : des identifiants (code, nom), des variables qu’on va chercher à expliquer (tmoy, tmin, tmax, prec) et des variables a priori explicatives (lat, lon, alt).\n\ndon &lt;- tab_depart[,c(\"code\", \"nom\", \"tmoy\", \"tmin\", \"tmax\", \"prec\", \"lat\", \"lon\", \"alt\")]\ndon_reg &lt;- don[, c(\"tmoy\", \"lat\",\"lon\",\"alt\")]\n\nL’objectif de cet exercice est de chercher à expliquer les variations des températures moyennes des stations par les 3 variables explicatives : don_reg. Mais tout d’abord, commençons par une première étape, l’exploration visuelle des relations entre ces variables.\n\n\n\n\n\n\nQuelles sont -par ex- les fonctions R à utiliser pour étudier une relation ?\n\n\n\n\n\n?plot()\n?cor.test()\n?lm()\nLes ? devant les fonctions permettent d’obtenir de l’aide sous R."
  },
  {
    "objectID": "MOD3_Regression_multiple.html#modele1",
    "href": "MOD3_Regression_multiple.html#modele1",
    "title": "[MOD3] : Introduction à la régression multiple",
    "section": "modele1",
    "text": "modele1\n::: ATTENTION, texte à trou, à vous de le remplir\nRappel : on écrit la variable à expliquer [Y] en fonction [~] de la variable explicative [X], soit lm(Y~X). Choisir ici les variables en question.\n\nmodele1 &lt;- lm(...)\nsummary(modele1)\n\nEst-ce que la relation est significative ? Quel est son sens ? Quelle est son intensité ?\nQue doit-on vérifier au-delà de la p-value et de la significativité pour valider le modèle ?\nQuel est le pouvoir explicatif de cette relation ?\nNotez que le R ajusté est utile lorsque l’on compare plusieurs modèles sur un même jeu de données."
  },
  {
    "objectID": "MOD3_Regression_multiple.html#modele2",
    "href": "MOD3_Regression_multiple.html#modele2",
    "title": "[MOD3] : Introduction à la régression multiple",
    "section": "modele2",
    "text": "modele2\n\ncorrplot(cor(don_reg[,c(\"...\", \"...\")], \n             m1$residuals), \n         addCoef.col = TRUE)\nmodele2 &lt;- lm(m1$residuals ~ don_reg$...)\nsummary(modele2)\n\nSi la nouvelle variable est significative avec ce qui n’a pas été expliqué par le premier modèle (= les résidus), alors on continue."
  },
  {
    "objectID": "MOD3_Regression_multiple.html#modele3",
    "href": "MOD3_Regression_multiple.html#modele3",
    "title": "[MOD3] : Introduction à la régression multiple",
    "section": "modele3",
    "text": "modele3\nIl ne reste plus qu’une variable à tester sur les résidus.\n\nmodele3 &lt;- lm(m2$residuals ~ don_reg$...)\nsummary(m3)\n\nChacune des variables retenues, in fine, explique significativement une partie non expliquée auparavant. Il s’agit à présent de combiner l’ensemble des variables dans un seul modèle de régression multiple."
  },
  {
    "objectID": "MOD3_Regression_multiple.html#comparaison-de-modèles",
    "href": "MOD3_Regression_multiple.html#comparaison-de-modèles",
    "title": "[MOD3] : Introduction à la régression multiple",
    "section": "6. COMPARAISON DE MODÈLES",
    "text": "6. COMPARAISON DE MODÈLES\nPlusieurs critères permettent de comparer plusieurs modèles, les plus connus étant AIC (An Information Criterion d’Akaike) et le BIC (Bayesian Information Criterion), basés sur des compromis : plus les valeurs sont petites, plus le modèle est adapté. Sous R:\n\nAIC(modele)\nBIC(modele)\n\nSi vous hésitez entre 2 modèles (2 combinaisons de variables), vous pouvez tester par une analyse de la variance les 2 modèles. En d’autres termes, vous cherchez à savoir l’influence d’une ou de plusieurs variables dans un modèle, tout en prenant en considération les autres.\n\nanova(mod1,mod2)\n\nSi la significativité est supérieure à 0,05 (ou 0,10), alors vous pouvez conclure que les variables introduites ne contribuent pas significativement."
  },
  {
    "objectID": "SPA2_DistAccess.html#les-données-utilisées-dans-ce-module",
    "href": "SPA2_DistAccess.html#les-données-utilisées-dans-ce-module",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Les données utilisées dans ce module",
    "text": "Les données utilisées dans ce module\n\n\n\n\n\n\nTélécharger les jeux de données\n\n\n\n\nSPA\nSPA2\n\n\n\n\nLes villes tunisiennes et les découpages administratifs tunisiens (cf SPA1)\n\n\n\n\n\n\nCode R si vous devez réimporter ces données\n\n\n\n\n\nLes villes tunisiennes (source : Africapolis)\n\nvil &lt;- st_read(dsn = \"data/SPA/vil.gpkg\", quiet=TRUE)\n\nFond de carte des délégations, gouvernorats et régions (source : INS & Syfacte/Riate)\n\ndel &lt;- st_read(\"data/SPA/tun_admin.gpkg\", layer = \"delegation\", quiet = TRUE)\ndel &lt;- del[!duplicated(del$del_code),]\ngou &lt;- st_read(\"data/SPA/tun_admin.gpkg\", layer = \"gouvernorat\", quiet = TRUE)\nreg &lt;- st_read(\"data/SPA/tun_admin.gpkg\", layer = \"region\", quiet = TRUE)\n\n\n\n\nLes populations des délégations (source : INS), à joindre aux géométries déjà importées\n\npopdel &lt;- read.csv(file = \"data/SPA/don_del.csv\", header = TRUE, sep= \";\", encoding = \"UTF-8\")\n# NB : dans le fichier don_del.csv, correction du code (del_code) de Zarzouna : TN.BZ.JA au lieu de TN.BZ.ZA (dans le fichier del)\n\ndel &lt;-  merge(x = del[,\"del_code\"],  # L'objet sf (seulement le champ del_code)\n              y = popdel,          # le data.frame\n              by.x = \"del_code\",  # identifiant dans x\n              by.y = \"del_code\",  # identifiant dans y\n              all.x = TRUE         # conserver toutes les lignes\n              )\n\ndel &lt;- del[,c(\"del_code\",\"del_nom_fr\",\"del_nom_ar\",\"popto_2014\")]\n\nFond de carte et population 2004 des secteurs (source : INS)\n\nsecteurs &lt;- st_read(\"data/SPA2/secteurs.gpkg\", quiet=TRUE)\n\n\n\nLes universités tunisiennes (source : OSM)\nLe fichier contient les 10 universités extraites de la base OSM (à partir de la catégorie amenity=university), cette liste ayant été vérifiée à partir de Wikipedia (consulté le 3 mai 2024). La localisation d’une université dans chaque ville est associée au point correspondant à une des entrées du site principal (à consolider !).\n\nuniv &lt;- st_read(dsn = \"data/SPA2/univOSM.gpkg\", quiet=TRUE)"
  },
  {
    "objectID": "SPA2_DistAccess.html#pour-commencer-de-tunis-à-ben-guerdane",
    "href": "SPA2_DistAccess.html#pour-commencer-de-tunis-à-ben-guerdane",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Pour commencer, de Tunis à Ben Guerdane…",
    "text": "Pour commencer, de Tunis à Ben Guerdane…\n\nComment mesurer la distance à vol d’oiseau entre ces deux villes ? Quel est l’écart par rapport à la distance routière ?\n\n\n\n\n\n\nDéfinition : qu’est-ce qu’une métrique euclidienne ? rectilinéaire ? comment estimer une distance théorique entre deux lieux ?\n\n\n\n\n\n\n\n\n\n\nDe manière générale, une métrique est une fonction mathématique qui permet d’associer à tout couple de coordonnées (i,j) une mesure de distance Dij.\n\nLa plus connue et la plus fréquemment utilisée est la métrique euclidienne, mais il en existe d’autres (métrique rectilinéaire, orthodromique…) qui peuvent s’avérer plus adaptées selon les contextes et les objectifs de mesure.\n\n\n\n\n\nSource de la figure : Pumain D., Saint-Julien T., 2010, Analyse spatiale : les localisations, Paris : Cursus Armand Colin, p.31.\n\n\n\n\n\n\n\n\n\n\n\n\nD’après le service de calcul d’itinéraire OSRM, l’itinéraire routier le plus court par la route pour aller de l’agglomération de Tunis à celle de Ben Guerdane fait 550 km.\n\nDist_rout(Tunis-BenG) = 550 km\n\nPar comparaison, quelle est la distance à vol d’oiseau entre ces deux villes ? et la distance rectilinéaire ? quel est l’écart entre distance routière et distances estimées ? \\ X_Tunis = 4 342 371 m, Y_Tunis = 1 525 005 m\nX_BenG = 4 434 680 m, Y_BenG = 1 124 046 m\n Dist_eucli(Tunis-BenG) = 411 km\nLa distance euclidienne sous-estime de 34% la distance routière.\nDist_recti(Tunis-BenG) = 493 km\nLa distance rectilinéaire sous-estime de 12% la distance routière.\n\n\n\n\n\n\n\n\n\n\n\n\nCode pour extraire les coordonnées des deux villes, puis calculer la distance à vol d’oiseau et la distance rectilinéaire\n\n\n\n\n\n\n# On extrait les coordonnées projetées (crs=3035) de Tunis et de Ben Guerdanne \n# à l'aide de la fonction st_coordinates() utilisée dans SPA1 pour préparer le calcul du point moyen\ncoords &lt;- data.frame(Xtunis = st_coordinates(vil[vil$Nom==\"Tunis\",])[,1], # pour extraire X\n                     Ytunis = st_coordinates(vil[vil$Nom==\"Tunis\",])[,2], # pour extraire Y\n                     Xbeng = st_coordinates(vil[vil$Nom==\"Ben Guerdane\",])[,1],\n                     Ybeng = st_coordinates(vil[vil$Nom==\"Ben Guerdane\",])[,2],stringsAsFactors = FALSE)\n\n# Distance routière d'après OSRM : fonction osrmTable\ndistrout &lt;- osrmTable(src=vil[vil$Nom==\"Tunis\",],\n                      dst=vil[vil$Nom==\"Ben Guerdane\",],\n                      measure = \"distance\")\ndistrout &lt;- (distrout$distance/1000)\n\n# Calcul de la distance euclidienne (à vol d'oiseau)\ndisteucl &lt;- round((sqrt((coords$Xtunis-coords$Xbeng)^2\n                                   +(coords$Ytunis-coords$Ybeng)^2)/1000),0)\n\n# Calcul de la distance rectilinéaire\ndistrecti &lt;- round((abs(coords$Xtunis-coords$Xbeng)\n                             + abs(coords$Ytunis-coords$Ybeng))/1000,0)\n\n# Ecart distance routière/distance euclidienne\ndiff_routeucli &lt;- round((distrout[1]-disteucl[1])/disteucl*100,1) \n\n# Ecart distance routière/distance rectilinéaire\ndiffrel_routerecti &lt;- round((distrout[1]-distrecti[1])/distrecti*100,1)"
  },
  {
    "objectID": "SPA2_DistAccess.html#construire-une-matrice-des-distances-routières-via-osrm",
    "href": "SPA2_DistAccess.html#construire-une-matrice-des-distances-routières-via-osrm",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Construire une matrice des distances routières via OSRM",
    "text": "Construire une matrice des distances routières via OSRM\nCalcul d’une matrice des distances routières à l’aide de la fonction osrmTable d’OSRM\n\n# Pour avoir les noms des villes comme identifiants de la future matrice, au lieu d'avoir des indices des colonnes et des lignes\nrownames(vil) &lt;- vil$Nom\n# Calcul d'une matrice de distances routières via OSRM\nmatdist_osrm &lt;- osrmTable(loc=vil,\n                          measure=\"distance\")\n# cette matrice n'est pas tout à fait symétrique, même si les différences sont infimes\n\nLe résultat est une liste avec 3 informations : la matrice des distances routières, les coordonnées des sources et celles des destinations.\nTransformation en table de liens, suppression lignes i=j, distance en km (+ arrondi à l’unité)\n\n# suppression des distances sur la diagonale supérieure (en faisant l'hypothèse que Distij~Distji)\nmatdist_osrm$distances[upper.tri(matdist_osrm$distances)] &lt;- NA\n# transformation d'une matrice en tableau XY\ndistrout &lt;-as.data.frame.table(matdist_osrm$distances)\n# ajout des noms de colonnes\nnames(distrout) &lt;- c(\"i\",\"j\",\"distrout\")\n# suppression des valeurs manquantes (l'ancienne partie supérieure de la matrice)\ndistrout &lt;- na.omit(distrout)\n# suppression lignes i=j (distance d'une ville à elle-même)\ndistrout &lt;- distrout[distrout$distrout!=0,]\n# distance en km (+ arrondi à l'unité)\ndistrout$distrout &lt;- round(distrout$distrout/1000,0)\n\n# importation directe du tableau de données, au cas où la connexion à OSRM serait trop longue...\n# distrout &lt;- read.csv2(\"data/SPA2/distrout_vil.csv\")"
  },
  {
    "objectID": "SPA2_DistAccess.html#construire-une-matrice-de-distance-euclidienne-à-vol-doiseau-entre-les-villes",
    "href": "SPA2_DistAccess.html#construire-une-matrice-de-distance-euclidienne-à-vol-doiseau-entre-les-villes",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Construire une matrice de distance euclidienne (à vol d’oiseau) entre les villes",
    "text": "Construire une matrice de distance euclidienne (à vol d’oiseau) entre les villes\nConstruction d’une matrice des distances euclidiennes à l’aide de st_distance() de sf\n\n# calcul de la distance euclidienne entre les villes\nmatdist_eucli &lt;- st_distance(vil) \n\n# n.b.: comme on souhaite avoir une matrice carrée (les lieux en ligne sont identiques aux lieux en colonne), on n'a pas besoin de préciser l'identité des lieux x et y. Sinon on écrirait 'st_distance(x=vil,y=vil)'\n\n# le résultat est une matrice. Par exemple ici si on prend les 5 premières villes :\nmatdist_eucli[1:5,1:5]\n\nUnits: [m]\n         1        2         3        4         5\n1      0.0 358753.3 262753.18 368740.1 207960.29\n2 358753.3      0.0 159515.73 162539.4 169045.97\n3 262753.2 159515.7      0.00 106449.8  63489.65\n4 368740.1 162539.4 106449.83      0.0 167450.28\n5 207960.3 169046.0  63489.65 167450.3      0.00\n\n\nNotez que les distances sont exprimées dans l’unité du système de coordonnées de référence, en l’occurrence ici en mètres.\nComme vu dans LUN3 : amélioration de l’affichage de la matrice\n\n# transformation des distances en km\nmatdist_eucli &lt;- set_units(matdist_eucli, \"km\")\n# et arrondi à l'unité kilométrique\nmatdist_eucli &lt;- round(matdist_eucli, 0)\n# ajout des noms de villes en identifiants \ncolnames(matdist_eucli) &lt;- vil$Nom\nrow.names(matdist_eucli) &lt;- vil$Nom\n# retrait de l'unité de mesure\nmatdist_eucli &lt;- drop_units(matdist_eucli)\n\nmatdist_eucli[1:5,1:5]\n\n              Ras Jebel Redeief Regueb Hamma Hajeb Elayoun\nRas Jebel             0     359    263   369           208\nRedeief             359       0    160   163           169\nRegueb              263     160      0   106            63\nHamma               369     163    106     0           167\nHajeb Elayoun       208     169     63   167             0\n\n\nTransformation en table de liens, suppression lignes i=j, distance en km\n\n# suppression des distances sur la diagonale supérieure \nmatdist_eucli[upper.tri(matdist_eucli)] &lt;- NA\n# transformation d'une matrice en tableau XY\ndisteucli &lt;-as.data.frame.table(matdist_eucli)\n# retrait des valeurs manquantes (celles de la diagonale supérieure) \ndisteucli &lt;- na.omit(disteucli)\n# ajout des noms de colonnes\ncolnames(disteucli) &lt;- c(\"i\",\"j\",\"disteucl\")\n# suppression des distances nulles (i.e. la distance entre une ville et elle-même)\ndisteucli &lt;- disteucli[disteucli$disteucl!=0 ,]"
  },
  {
    "objectID": "SPA2_DistAccess.html#calcul-des-distances-rectilinéaires-entre-les-villes",
    "href": "SPA2_DistAccess.html#calcul-des-distances-rectilinéaires-entre-les-villes",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Calcul des distances rectilinéaires entre les villes",
    "text": "Calcul des distances rectilinéaires entre les villes\nOn souhaite récupérer les distances routières, euclidiennes et rectilinéaires dans un même tableau.\nJointure de la table des distances euclidiennes avec la table des distances routières\n\n# Jointure entre le fichier des distances eucliennes et le fichier des distances routières\ndistvil &lt;- merge(distrout, disteucli, \n           by= c(\"i\",\"j\"))\n\n# Avant de joindre cette table des distances à celle des villes, on récupère les coordonnées des villes (utile pour le futur calcul des distances rectilinéaires)\nvil$X &lt;- st_coordinates(vil)[,1] # pour extraire X\nvil$Y &lt;- st_coordinates(vil)[,2] # pour extraire Y\n\n# Jointure avec la base des villes pour récupérer le nom des villes de destination j et la date à laquelle elles apparaissent dans la base Africapolis\ndistvil &lt;- merge(x = distvil, \n                 y = st_drop_geometry(vil[, c(\"Nom\",\"Apparition1\",\"X\",\"Y\")]), \n           by.x= \"j\", by.y= \"Nom\")\n\nnames(distvil)[5:7] &lt;- c(\"Apparitionj\",\"Xj\",\"Yj\")\n\n# Nouvelle jointure pour récupérer le nom des villes d'origine i et la date à laquelle elles apparaissent dans la base Africapolis\ndistvil &lt;- merge(x = distvil, \n           y = st_drop_geometry(vil[, c(\"Nom\", \"Apparition1\",\"X\",\"Y\")]), \n           by.x= \"i\", by.y= \"Nom\")\nnames(distvil)[8:10] &lt;- c(\"Apparitioni\",\"Xi\",\"Yi\")\n\nAjout à la table des distances des distances rectilinéaires\n\n# Calcul des distances rectilinéaires\ndistvil$distrect &lt;- round((abs(distvil$Xi-distvil$Xj)\n                         +abs(distvil$Yi-distvil$Yj))/1000,0)\n\n# Pour réarranger l'ordre des colonnes\nordre &lt;- c(\"i\",\"j\",\"Xi\",\"Yi\",\"Xj\",\"Yj\",\"distrout\",\"disteucl\",\"distrect\",\"Apparitioni\",\"Apparitionj\")\ndistvil &lt;- data.frame(distvil[,ordre])"
  },
  {
    "objectID": "SPA2_DistAccess.html#comparaison-des-distances-euclidiennes-et-routières",
    "href": "SPA2_DistAccess.html#comparaison-des-distances-euclidiennes-et-routières",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Comparaison des distances euclidiennes et routières",
    "text": "Comparaison des distances euclidiennes et routières\nCalcul des écarts relatifs entre distances routières et euclidiennes\n\ndistvil$diffrel &lt;- round(((distvil$distrout-distvil$disteucl)/\n                            distvil$disteucl)*100,1)\nsummary(distvil$diffrel)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   21.80   28.40   31.04   36.20  214.90 \n\n\nQue vous apprend ce résumé de l’écart relatif entre distances routières et distances euclidiennes ? Quel est l’écart moyen ? A quel itinéraire correspond le plus grand écart ?\nUn modèle pour estimer les distances routières en fonction des distances à vol d’oiseau ?\nComplétez les lignes de ce programme pour construire un modèle de régression linéaire qui estime la distance routière en fonction de la distance euclidienne de la forme Y = a.X + b : distrout = a.disteucl + b\n\n# On crée d'abord un graphique qui représente la distance routière en fonction de la distance euclidenne\n\nplot(... ~ ..., data = ..., pch = 16, cex=0.3, \n   # Ajout d'un titre principal et des libellés des axes\n     main=\"Comparaison des distances entre les villes tunisiennes\", \n     xlab = \"Distance à vol d'oiseau (en km)\", \n     ylab = \"Distance routière (en km)\")\n\n# on construit ensuite un modèle de régression linéaire (linear modeling - lm) de la forme : \n\nmodeleucl &lt;- ...(... ~ ..., data=...)\n# comment faire pour avoir un résumé des résultats de la régression ?\n...(modeleucl) \n# Ajout de la droite de régression entre les 2 distances\nabline(a=modeleucl$coefficients[1], b=modeleucl$coefficients[2], col=\"blue\", lwd=2)\n# La 1ère bissectrice, i.e. l'égalité des distances\nabline(a=0, b=1, col=\"red\", lwd=2)\n\nQue pensez-vous des résultats du modèle qui estime les distances routières en fonction des distances euclidiennes ?\n\n\n\n\n\n\nUne solution possible pour la comparaison des distances euclidiennes/routières\n\n\n\n\n\nQue montrent les écarts relatifs entre distances routières et euclidiennes ?\n\ndistvil$diffrel &lt;- round(((distvil$distrout-distvil$disteucl)/\n                            distvil$disteucl)*100,1)\nsummary(distvil$diffrel)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   21.80   28.40   31.04   36.20  214.90 \n\n\nQue vous apprend ce résumé de l’écart relatif entre distances routières et distances euclidiennes ? Quel est l’écart moyen ? A quel itinéraire correspond le plus grand écart ?\nLa distance euclidienne est toujours inférieure à la distance routière.\nEn moyenne, la distance euclidienne sous-estime la distance routière de 31%.\n3/4 des distances mesurées montrent un écart compris entre 22% et 36% (distances euclidiennes inférieures de 22% à 36% aux distances routières).\nLe plus grand écart s’observe entre Djerba et les îles Kerkhena (101km en dist euclidienne, 318km par la route).\nAjustement linéaire entre distances euclidienne et routière\n\nplot(distrout ~ disteucl, data = distvil, pch = 16, cex=0.3, \n     # ajout d'un titre principal et des libellés des axes\n     main=\"Comparaison des distances entre les villes tunisiennes\", \n     xlab = \"Distance à vol d'oiseau (en km)\", \n     ylab = \"Distance routière (en km)\")\nmodeleucl &lt;- lm(distrout ~ disteucl, data=distvil)\nsummary(modeleucl)\n\n\nCall:\nlm(formula = distrout ~ disteucl, data = distvil)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-79.830 -14.561  -3.735   7.872 186.805 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.373570   0.966785  -1.421    0.155    \ndisteucl     1.319910   0.004466 295.565   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 28.13 on 3914 degrees of freedom\nMultiple R-squared:  0.9571,    Adjusted R-squared:  0.9571 \nF-statistic: 8.736e+04 on 1 and 3914 DF,  p-value: &lt; 2.2e-16\n\n# Ajout de la droite de régression entre les 2 distances\nabline(a=modeleucl$coefficients[1], b=modeleucl$coefficients[2], col=\"blue\", lwd=2)\n# La 1ère bissectrice, i.e. l'égalité des distances\nabline(a=0, b=1, col=\"red\", lwd=2)\n\n\n\n\nQue pensez-vous des résultats du modèle qui estime les distances routières en fonction des distances euclidiennes ?\nDist_routière = 1,32 * Dist_eucl - 1,42\nChaque fois que la distance euclidienne augmente de 10 km, la distance routière augmente de 13,2 km\nCoefficient de détermination : R²= 96%\np-value : &lt; 2.2e-16"
  },
  {
    "objectID": "SPA2_DistAccess.html#comparaison-des-distances-rectilinéairesroutières",
    "href": "SPA2_DistAccess.html#comparaison-des-distances-rectilinéairesroutières",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Comparaison des distances rectilinéaires/routières",
    "text": "Comparaison des distances rectilinéaires/routières\nCalcul des écarts relatifs entre distances rectilinéaires et euclidiennes\n\ndistvil$diffrel2 &lt;- round(((distvil$...-distvil$...)/\n                             distvil$...)*100,1)\nsummary(distvil$diffrel2)\n\n# valeur absolue des écarts\ndistvil$absdiffrel2 &lt;- abs(round(((distvil$...-distvil$...)/\n                                    distvil$...)*100,1))\nsummary(distvil$absdiffrel2)\n\nQue vous apprend ce résumé de l’écart relatif entre distances routières et distances rectilinéaires ? Quel est l’écart moyen ? A quel itinéraire correspond le plus grand écart ?\nUn modèle pour estimer les distances routières en fonction des distances rectilinéaires ?\nComplétez les lignes de ce programme pour construire un modèle de régression linéaire qui estime la distance routière en fonction de la distance rectilinéaire de la forme Y = a.X + b : distrout = a.distrect + b\n\nplot(... ~ ..., data = ..., pch = 16, cex=0.3, \n     # ajout d'un titre principal et des libellés des axes\n     main=\"Comparaison des distances entre les villes tunisiennes\", \n     xlab = \"Distance à vol d'oiseau (en km)\", \n     ylab = \"Distance routière (en km)\")\n\nmodeldrect &lt;- ...(... ~ ..., data=...)\n...(modeldrect)\n\n# Ajout de la droite de régression entre les 2 distances\nabline(a=modeldrect$coefficients[1], b=modeldrect$coefficients[2], col=\"blue\", lwd=2)\n# La 1ère bissectrice, i.e. l'égalité des distances\nabline(a=0, b=1, col=\"red\", lwd=2)\n\nQue pensez-vous des résultats du modèle qui estime les distances routières en fonction des distances rectilinéaires ?\n\n\n\n\n\n\nUne solution possible pour la comparaison des distances rectilinéaires/routières\n\n\n\n\n\nCalcul des écarts relatifs entre distances rectilinéaires et euclidiennes\n\n# Les écarts relatifs\ndistvil$diffrel2 &lt;- round(((distvil$distrout-distvil$distrect)/\n                             distvil$distrect)*100,1)\nsummary(distvil$diffrel2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-27.300  -7.400   1.200   4.476  13.900 158.500 \n\n# La valeur absolue des écarts relatifs\ndistvil$absdiffrel2 &lt;- abs(round(((distvil$distrout-distvil$distrect)/\n                                    distvil$distrect)*100,1))\nsummary(distvil$absdiffrel2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    4.70    9.80   12.77   17.20  158.50 \n\n\nQue vous apprend ce résumé de l’écart relatif entre distances routières et distances euclidiennes ? Quel écart moyen ? A quel itinéraire correspond le plus grand écart ?\nLa distance rectilinéaire est parfois inférieure à la distance routière (par exemple entre Sidi Bouzid et Ksar, distrou : 98 km et distrect : 131 km), parfois supérieure (par exemple entre Kerkenah et Djerba, distrou : 318 km et distrect : 123 km).\nEn moyenne, l’écart relatif absolu entre la distance rectilinéaire et la distance routière est de 13%.\nPour 3/4 des itinéraires, on a un écart compris entre 5% et 17%.\n\nAjustement linéaire entre distances rectilinéaire et routière\n\nplot(distrout ~ distrect, data = distvil, pch = 16, cex=0.3, \n     # ajout d'un titre principal et des libellés des axes\n     main=\"Comparaison des distances entre les villes tunisiennes\", \n     xlab = \"Distance rectilinéaire (en km)\", \n     ylab = \"Distance routière (en km)\")\nmodeldrect &lt;- lm(distrout ~ distrect, data=distvil)\nsummary(modeldrect)\n\n\nCall:\nlm(formula = distrout ~ distrect, data = distvil)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-132.099  -23.549   -6.679   15.680  193.195 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 6.476253   1.431770   4.523 6.27e-06 ***\ndistrect    1.013279   0.005235 193.541  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.79 on 3914 degrees of freedom\nMultiple R-squared:  0.9054,    Adjusted R-squared:  0.9054 \nF-statistic: 3.746e+04 on 1 and 3914 DF,  p-value: &lt; 2.2e-16\n\n# Ajout de la droite de régression entre les 2 distances\nabline(a=modeldrect$coefficients[1], b=modeldrect$coefficients[2], col=\"blue\", lwd=2)\n# La 1ère bissectrice, i.e. l'égalité des distances\nabline(a=0, b=1, col=\"red\", lwd=2)\n\n\n\n\nQue pensez-vous des résultats du modèle qui estime les distances routières en fonction des distances rectilinéaires ?\nDist_routière = 1,01 * Dist_recti + 6,4\nCoefficient de détermination : R²= 91%\np-value : &lt; 2.2e-16"
  },
  {
    "objectID": "SPA2_DistAccess.html#pour-aller-plus-loin",
    "href": "SPA2_DistAccess.html#pour-aller-plus-loin",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Pour aller plus loin…",
    "text": "Pour aller plus loin…\n\nCours et les applications du module Distances et accessibilité de l’école d’été du CIST au Bénin (2023) : entre autres développements, voir les indices d’efficacité du réseau routier créés à partir de la comparaison entre distance euclidienne et distance routière et de la comparaison entre distance et temps de trajet\n“Tissus” de villes, réseaux potentiels d’échanges\n\n\n\n\nDans l’article Tissu d’un semis de villes européennes, C. Rozenblat (1995) proposait une carte originale pour faire ressortir les réseaux potentiels d’échanges entre villes européennes, à différentes échelles. La 1ère carte à droite s’appuie sur deux hypothèses :\n\n“Les interactions spatiales [étant] plus importantes entre des villes proches” (p.23), on peut rendre visible les continuités et discontinuités de la trame urbaine en reliant les villes proches : “La distribution des villes dans l’espace, leur espacement et leur agencement peuvent ainsi être à la base d’une réflexion sur leurs pouvoirs collectifs de structuration de l’espace économique, politique et social” (p.23).\nLes seuils de proximité varient selon la taille des villes : pour les plus grandes villes, leur rayonnement plus important justifie le choix de seuils de plus grande portée (par exemple, 150 km pour les villes de plus de 100 000 hab., contre 50 km pour l’ensemble des villes de plus de 10 000 hab.).\n\nPlus récemment, dans le cadre du WorldPopProject, H. Chamberlain (2021) a cartographié les villes africaines de la base Global Human Settlement en reliant chaque centre aux 20 villes les plus proches, et en faisant varier la teinte de chaque lien en fonction de l’espacement observé. Le résultat fait ressortir la position relative de chaque ville, selon qu’elle s’inscrit dans une trame urbaine très dense (tons clairs) ou qu’elle est beaucoup plus isolée.\n\n\n\n \n\n\n\n\n\n\n\n\n\nUn “tissu” de villes tunisiennes ?\n\n\n\nVous pouvez construire une carte du “tissu” de villes tunisiennes, par exemple en reliant les villes de plus de 10 000 hab. qui sont distantes de moins de 50 km. Où sont les plus fortes continuités de densités urbaines ? les réseaux potentiels de moindre densité ? les zones où la présence des villes est plus rare ?\nPour aller plus loin, vous pouvez sélectionner plusieurs seuils de distance en fonction de la taille des villes (par exemple 100 km pour les villes de plus de 100 000 habitants), et/ou en choisissant plusieurs dates, en sélectionnant les villes de plusieurs pays voisins à partir de la base Africapolis…\n\n\n\n\n\n\n\n\nUn peu d’aide ?\n\n\n\n\n\n- Comment sélectionner les villes distantes de moins de 50 km ? Vous pouvez vous aider de la syntaxe df2 &lt;- df[df$variable &lt;50,]\n- Comment dessiner les liens entre villes à partir de cette sélection ? La fonction correspondante dans mapsf est get_link_layer. Ses arguments reposent sur la sélection de deux fichiers : celui des points, celui de la table des liens, les identifiants des deux fichiers devant être identiques (par exemple ici les noms des villes) : liens &lt;- mf_get_links(x = …, df = …) On peut ensuite construire une carte thématique à partir de ces liens : mf_map(x = liens, …) Voir l’explication plus détaillée sur le site du package\n\n\n\n\n\n\n\n\n\nUne solution possible…\n\n\n\n\n\nSélection des couples de villes distantes de moins de 50 km (2015)\n\ndist50vil &lt;- distvil[distvil$disteucl&lt;50,]\n\nSélection des couples de grandes villes distantes de moins de 100 km (2015)\n\n# Jointure pour récupérer les populations des villes\ndistvil &lt;- merge(x = distvil,y =st_drop_geometry(vil[,c(\"Nom\",\"Pop2015\")]), \n           by.x= \"j\", by.y= \"Nom\")\nnames(distvil)[15] &lt;- \"Pop2015j\"\n\ndistvil &lt;- merge(x = distvil,y =st_drop_geometry(vil[,c(\"Nom\",\"Pop2015\")]), \n           by.x= \"i\", by.y= \"Nom\")\nnames(distvil)[16] &lt;- \"Pop2015i\"\n\n# Sélection des couples de villes de plus de 100 000 habitants...\ndistvil100k &lt;- distvil[distvil$Pop2015i&gt;100000 & distvil$Pop2015j&gt;100000,]\n# ... et distantes de moins de 100 km\ndist100vil100k &lt;- distvil100k[distvil100k$disteucl&lt;100,]\n\nCarte de liens entre les villes distantes de moins de 50 km ou entre les grandes villes distantes de moins de 100 km\nSélection des identifiants pour le fichier des villes\n\n# Il faut que les identifiants des villes dans le fichier des points soient les mêmes que les identifiants du fichier des liens (les noms des villes) : on ne conserve dans le fichier des villes que la variable \"Nom\"\nvil &lt;- vil[,c(\"Nom\",\"Pop2015\")]\n\nCréation du graphe des liens entre toutes les villes proches (&lt;50km) et entre grandes villes proches (&lt;100 km)\n\nliens50 &lt;- mf_get_links(x = vil, df = dist50vil)\nliens100 &lt;- mf_get_links(x = vil, df = dist100vil100k)\n\nCarte\n\nmf_map(reg, col=\"bisque\", border=\"white\", lwd=0.5)\nmf_map(x=vil, pch = 20, cex = 0.8, col = \"violet\", add=TRUE)\n\nmf_map(x = liens100,\n       var = \"disteucl\",\n       leg_pos = \"topright\",\n       leg_title = \"Moins de 100 km entre les villes de plus de 100 000 hab.\", \n       col = \"purple4\", lwd = 2,add=TRUE)\nmf_map(x = liens50,\n       var = \"disteucl\",\n       leg_pos = \"topright\",\n       leg_title = \"Moins de 50 km entre villes\",\n       col = \"purple1\", lwd = 1,add=TRUE)\n\n# Affichage de qqs noms de villes\nmf_label( x = vil[vil$Pop2015&gt;100000,],\n          var = \"Nom\", \n  col = \"black\",\n  cex = 0.6,\n  font = 1,\n  r = 0.1,\n  halo = TRUE,\n  overlap = FALSE,\n  lines = FALSE\n)\n\nmf_title(\"Villes distantes de moins de 50 km et de moins de 100 km, 2015\", cex = 0.8)\nmf_scale(pos = \"bottomright\", lwd = 2, cex = 0.6, scale_units = \"km\")\nmf_credits(\"Sources : Africapolis 2020, INS & Syfacte/RIATE\")"
  },
  {
    "objectID": "SPA2_DistAccess.html#décrire-laccessibilité-locale-une-première-approche-élémentaire-à-partir-dun-site-unique-et-dun-seuil-de-distance",
    "href": "SPA2_DistAccess.html#décrire-laccessibilité-locale-une-première-approche-élémentaire-à-partir-dun-site-unique-et-dun-seuil-de-distance",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Décrire l’accessibilité locale : une première approche élémentaire à partir d’un site unique et d’un seuil de distance",
    "text": "Décrire l’accessibilité locale : une première approche élémentaire à partir d’un site unique et d’un seuil de distance\nDans l’exemple qui suit, vous allez d’abord voir comment créer et représenter la zone accessible autour d’une site unique :\n\nCarte des distances/temps de trajet autour d’un site (isochrones)\nCombien d’habitants à moins de telle distance/tel temps de trajet de ce site ?\n\nIci on s’appuiera sur l’ensemble des habitants des secteurs (2004), faute d’avoir une information plus précise sur le nombre de jeunes.\nExemple : quels sont les territoires à moins d’1h par la route de l’Université de Sousse ?\nConstruction de l’isochrone autour de l’Université de Sousse\nà l’aide de la fonction osrmIsochrone du package osrm\n\n# Sélection de l'université de Sousse\nUnivSousse &lt;- univ[univ$Nom==\"Sousse\",]\n# Transformation en WGS84 (pour pouvoir ensuite afficher l'isochrone avec le package Leaflet)\nUnivSousseWGS84 &lt;- st_transform(UnivSousse,4326) %&gt;% select(Nom,geom)\n\n# Construction de l'isochrone\nisosousse &lt;- osrmIsochrone(\n  UnivSousseWGS84,\n  breaks = seq(0,60,60),\n  res = 30,\n  osrm.server = getOption(\"osrm.server\"),\n  osrm.profile = getOption(\"osrm.profile\")\n)\n\n# pour récupérer la géométrie de l'isochrone si la connexion au réseau et à OSRM pose problème\n# st_read(\"data/SPA2/isosousse.gpkg\")\n\nAfficher l’isochrone avec le fond leaflet\n\nleaflet(UnivSousseWGS84) %&gt;% addTiles() %&gt;% addPolygons(data = isosousse, fillColor = \"orange\", fillOpacity = 0.3, stroke = FALSE) %&gt;% addCircleMarkers()\n\n\n\n\n\nCombien d’habitants ont accès à l’Université de Sousse en moins d’1h ?\nSélectionner les secteurs qui se trouvent à moins d’1h de l’Université\n\nisosousse3035 &lt;- st_transform(isosousse,crs=3035)\nsecteurs &lt;- st_transform(secteurs,crs=3035)\nsecteursIn &lt;- st_intersection(x = secteurs, y = isosousse3035)\n\n\nsecteursInpop &lt;- secteursIn %&gt;% group_by() %&gt;% summarize(Poptot04 = sum(Population_Tot))\nsecteursInpop$Poptot04\n\n[1] 1709571"
  },
  {
    "objectID": "SPA2_DistAccess.html#quelle-est-la-distance-à-luniversité-la-plus-proche",
    "href": "SPA2_DistAccess.html#quelle-est-la-distance-à-luniversité-la-plus-proche",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Quelle est la distance à l’université la plus proche ?",
    "text": "Quelle est la distance à l’université la plus proche ?\nOn cherche à sélectionner pour chaque délégation la distance à l’université la plus proche, depuis chaque centroïde de délégation. Cette mesure repose sur l’hypothèse selon laquelle on se rend en priorité à l’université la plus proche.\nEtapes suivies :\n\nCréation d’une matrice de distances entre les 264 délégations (origine = centroïdes des dél.) et les 10 universités (source : OSM)\nSélection pour chaque délégation de la distance minimale à une université\n\nCréation d’une matrice des distances (routières) entre les délégations et les universités\nOn extrait d’abord les centroïdes des délégations\n\ndel_ctr &lt;- st_centroid(del)\n\nPuis on construit la matrice des distances routières entre les délégations (origines ori=deleg) et les universités (destinations dest=univ)\n\n# Calcul de temps de trajets avec OSRM\ndeltime &lt;- osrmTable(src = del_ctr, dst = univ, measure = \"duration\")\n# Extraire les temps de trajet\ndeltime &lt;- data.frame(deltime$durations)\n# Renommer les identifiants des lignes et des colonnes\ncolnames(deltime) &lt;- as.character(univ$Nom)\nrow.names(deltime) &lt;- as.character(del_ctr$del_code)\n\n# pour récupérer la matrice deltime si la connexion au réseau et à OSRM pose problème\n# readRDS(file = \"data/SPA2/deltime.rds\")\n\nCarte des temps de trajet vers l’université la plus proche\n\n\n\nRécupération pour chaque délégation des temps de trajets les plus courts (distance minimale) …\n\n# Extraire les temps de parcours minimaux\ntime &lt;- apply(deltime, 1, min) \n# Transformation de la matrice en format dataframe\ntime &lt;- data.frame(time)\ntime$del_code &lt;- rownames(time)\n# Jointure avec le fichier des délégations\ndel2 &lt;- merge(del, time, by = \"del_code\", all.x = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode pour la création de la carte\n\n\n\n\n\n\nlibrary(mapsf)\nmf_init(del)\nmf_map(del, col = \"lightgrey\", \n       border = NA,\n       add = TRUE)\nmf_map(del2, \n       type = \"choro\",\n       var = \"time\",\n       breaks = c(0,15,30,60,120,240,360),\n       pal = \"Purples\",\n       border = \"white\", \n      leg_title = \"Minutes en voiture\",\n       add = TRUE)\nmf_map(univ, pch = 21, col = NA, bg = \"red\",add=TRUE)\n# mf_label(univ,\"Nom\",col = \"black\",cex = 0.7,font = 1,r = 0.1,halo = TRUE,overlap = FALSE,lines = FALSE)\nmf_scale(size = 10)\nmf_title(\"Temps de trajet vers l'Université la plus proche\")\nmf_credits(\"Source : © OpenStreetMap 2024, INS\")\n\n\n\n\nPour récupérer directement le fichier del2 en cas de problème de connexion avec OSRM…\n\n#del2 &lt;- st_read(\"data/SPA2/del2.gpkg\")"
  },
  {
    "objectID": "SPA2_DistAccess.html#résumer-laccessibilité-générale-des-délégations-et-des-populations-aux-universités",
    "href": "SPA2_DistAccess.html#résumer-laccessibilité-générale-des-délégations-et-des-populations-aux-universités",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Résumer l’accessibilité générale des délégations et des populations aux universités",
    "text": "Résumer l’accessibilité générale des délégations et des populations aux universités\n\nIndicateurs d’accessibilité moyenne, médiane, maximale\nQuelle est la distance minimale moyenne ? médiane ? maximale ? des délégations à l’univ la plus proche\n\nsummary(del2$time)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.40   23.80   55.40   63.38   88.85  339.30 \n\n\n\n\n\n\n\n\nQue vous apprend le résumé de la distribution statistique des temps de parcours ?\n\n\n\n\n\nMin. 1st Qu. Median Mean 3rd Qu. Max. 2.40 23.80 55.40 63.39 88.72 342.00\nEn moyenne, une délégation est distante d’un peu plus d’une heure (63 min) de l’université la plus proche. Les trois quarts des délégations se trouvent entre 24 min et 1h30 de l’université la plus proche. La délégation la plus éloignée (distance maximale) se trouve à près de 6 heures de route de l’université la plus proche.\n\n\n\nDistance moyenne pondérée\nCertaines délégations très éloignées de l’université la plus proche pèsent fortement dans le calcul de la distance moyenne alors qu’elles comptent peu d’habitants. Pour tenir compte de ces inégalités de populations dans le calcul de la distance moyenne, on peut calculer une distance moyenne pondérée. Cette dernière estime la distance moyenne des populations à l’université la plus proche (et non la distance moyenne des délégations à l’université).\n\nComme l’illustre la figure ci-dessus, calculer une distance moyenne pondérée revient à multiplier chaque distance par la population de la délégation d’origine et à diviser la somme de ces distances pondérées par la population totale des délégations tunisiennes.\n\n# On multiplie chaque valeur de distance par la population de la délégation d'origine\ndel2$timepond &lt;- del2$time * del2$popto_2014\n# On divise la somme des distances pondérées par la population totale des délégations\ndist_moypond &lt;- round(sum(del2$timepond)/ sum(del2$popto_2014),1)\n\n\n\n-&gt; Alors, en moyenne, quel est le temps de trajet vers l’université la plus proche pour les habitants des délégations ?\nCréation d’un tableau qui résume ces résultats\n\n# Resultats à mettre dans un tableau de données\n# On crée un nouveau tableau de données (de type 'data frame') nommé \"resume_dist\" qui aura 8 colonnes et 2 lignes\nresume_dist &lt;- data.frame(matrix(ncol = 4, nrow = 1))\ncolnames(resume_dist) &lt;- c(\"Variable\", \"Moyenne\", \"Moyenne pondérée\", \"Maximum\")\nresume_dist[1,1] &lt;- \"Dist_univ_pp (min)\"\nresume_dist[1,2] &lt;- mean(del2$time)\nresume_dist[1,3] &lt;- dist_moypond\nresume_dist[1,4] &lt;- max(del2$time)\n\n# Mise en forme soignée à l'aide du package 'kable'\nkable(resume_dist, align = \"c\", escape = F, digits = 0) %&gt;%\n    kable_paper(full_width = F) %&gt;%\n    column_spec(1, bold = TRUE)\n\n\n\n\nVariable\nMoyenne\nMoyenne pondérée\nMaximum\n\n\n\n\nDist_univ_pp (min)\n63\n52\n339"
  },
  {
    "objectID": "SPA2_DistAccess.html#courbe-daccessibilité-générale-des-populations-aux-universités",
    "href": "SPA2_DistAccess.html#courbe-daccessibilité-générale-des-populations-aux-universités",
    "title": "[SPA2] Des distances à l’accessibilité spatiale",
    "section": "Courbe d’accessibilité générale des populations aux universités",
    "text": "Courbe d’accessibilité générale des populations aux universités\nLa fonction freqCum créée par Ronan Ysebaert produit un graphique qui représente le pourcentage cumulé de la population en fonction d’une distance (en minutes) à l’équipement le plus proche. Elle prend en entrée plusieurs arguments détaillés ci-dessous :\n\n\n\n\n\n\nCréation de la fonction freqCum\n\n\n\n\n\n\n# Arguments de la fonction freqCum :\n# x : un data frame qui comprend au minimum une variable exprimant la distance et une variable décrivant une population.&lt;br&gt;\n# dist : label de la variable de distance utilisée, comprise dans x.&lt;br&gt;\n# pop : label(s) des variables de population utilisées dans l’analyse, comprise(s) dans x.&lt;br&gt;\n# label.x : afficher un point (x,y) sur la courbe et son label en fonction d’une ou plusieurs valeurs de x (distance-temps).&lt;br&gt;\n# label.y : afficher un point (y,x) sur la courbe et son label en fonction d’une ou plusieurs valeurs de y (population).&lt;br&gt;\n# xlab: Label de l’axe des abscisses (temps routier).&lt;br&gt;\n# xlim : Emprise du graphique sur l’axe des abscisses (défaut : c(0, 100)).&lt;br&gt;\n# ylim : Emprise du graphique sur l’axe des ordonnées (défaut : c(0, 100)).&lt;br&gt;\n# lwd : Épaisseur de la ligne (défaut : 0.5).&lt;br&gt;\n# lty : Type de ligne (défaut : 1, ligne continue)&lt;br&gt;\n# add : Si TRUE, rajouter sur un graphique pré-existant l’affichage de fréquences cumulées (défaut = FALSE).\n\nfreqCum &lt;- function(x, dist, pop, cols, label.x = NULL, label.y = NULL, xlab, xlim = c(0, 300), ylim = c(0, 100), lwd = 0.5, lty = 1, add = FALSE) {\n\n# Sélectionner les valeurs (toutes les lignes + les colonnes dist et pop)\ndf &lt;- x[, c(dist, pop)]\n\n# Créer des intervalles de temps (minute par minute)\nbrks &lt;- seq(0, max(df[, dist], na.rm = TRUE), by = 0.1)\ndf$dist &lt;- findInterval(df[, dist], vec = brks)\ndf$dist &lt;- brks[df$dist + 1]\n\n# Supprimer valeurs manquantes\ndf &lt;- df[!is.na(df$dist), ]\n\n# Graphique vide\npar(mar = c(4, 4, 1, 1), xaxs = \"i\", yaxs = \"i\")\n\nif (add != TRUE) {\n        plot(1, type = \"n\", xlab = xlab, ylab = \"Effectif cumulé (% population)\",\n            xlim = xlim, ylim = ylim)\n        abline(h = seq(0, 300, 10), col = \"#00000060\", lwd = 0.2, lty = 3)\n        abline(v = seq(0, 300, 10), col = \"#00000060\", lwd = 0.2, lty = 3)\n    }\n\n    for (i in 1:length(pop)) {\n\n# Agréger les données de pop par pas de temps(les individus du tableau\n# deviennent ces intervalles de temps)\n        t &lt;- aggregate(df[, pop[i]], by = list(df$dist), sum)\n\n# Création d'une nouvelle variable de fréquence cumulée (d'abord freq\n# en effectifs puis cumul en pourcentages) en utilisant la fonction cumsum (base)\n        t$freq &lt;- cumsum(t$x)\n        t$cumul &lt;- t$freq/t[nrow(t), 3] * 100\n        lines(t$Group.1, t$cumul, col = cols[i], lwd = lwd, lty = lty)\n\n        if (length(label.x &gt; 0)) {\n            for (j in 1:length(label.x)) {\n                xy &lt;- t[which.min(abs(label.x[j] - t$Group.1)), ]\n                points(y = xy[, \"cumul\"], x = xy[, \"Group.1\"], pch = 21, cex = 1.5,\n                  bg = cols[i])\n                text(y = xy[, \"cumul\"], x = xy[, \"Group.1\"], pos = 2, cex = 0.6,\n                  label = paste(round(xy[, \"Group.1\"], 0), round(xy[, \"cumul\"], 1),\n                    sep = \", \"))\n            }\n        }\n\n        if (length(label.y &gt; 0)) {\n            for (j in 1:length(label.y)) {\n                xy &lt;- t[which.min(abs(label.y[j] - t$cumul)), ]\n                points(y = label.y[j], x = xy[, \"Group.1\"], pch = 21, cex = 1.5,\n                  bg = cols[i])\n                text(y = label.y[j], x = xy[, \"Group.1\"], pos = 2, cex = 0.6, label = paste(label.y[j],\n                  round(xy[, \"Group.1\"], 1), sep = \", \"))\n            }\n        }\n    }\n}\n\n\n\n\n\nCourbe d’accessibilité générale des populations à l’université la plus proche\n\ndf &lt;- del2\ndf &lt;- st_drop_geometry(df)\n\n# Graphique des distances aux universités, situation initiale\nfreqCum(x = df, dist = \"time\", pop = \"popto_2014\", cols = \"blue\",\n    xlab = \"Temps routier (minutes) à l'université la plus proche\",\n    xlim = c(0, 300), lwd = 2)\n\n\n\n\n\n\n\n\n\n\nPour récupérer le tableau des populations cumulées en fonction de la distance\n\n\n\n\n\n\ndf2 &lt;- deltime\n\n# Création d'une nouvelle colonne dist qui identifie la distance à l'Université la plus proche\ndf2$dist &lt;- apply(df2, 1, min)\ndf2$del_code &lt;- rownames(df2)\n# Récupération des populations de chaque délégation\ndf2 &lt;- merge(df2,del,by.x=\"del_code\",by.y=\"del_code\",all.x=TRUE)\n# Sélection de 3 colonnes : le code, la distance minimale, la population\ndf2 &lt;- df2[,c(\"del_code\",\"dist\",\"popto_2014\")]\ncolnames(df2) &lt;- c(\"del_code\",\"dist\",\"pop\")\n\n# Créer des intervalles de temps (minute par minute)\nbrks &lt;- seq(0, max(df2[,\"dist\"]), by = 1)\ndf2$dist &lt;- findInterval(df2[,\"dist\"], vec = brks)\n\n# Supprimer valeurs manquantes\ndf2 &lt;- df2[!is.na(df2$dist), ]\n\n# Agréger les données de pop par pas de temps(les individus du tableau\n# deviennent ces intervalles de temps)\ntab &lt;- aggregate(df2[,\"pop\"], by = list(df2$dist), sum)\ncolnames(tab)&lt;-c(\"dist\",\"pop\")\n\n# Création d'une nouvelle variable de fréquence cumulée (d'abord freq\n# en effectifs puis cumul en pourcentages) en utilisant la fonction cumsum (base)\ntab$freq &lt;- cumsum(tab$pop)\ntab$cumul &lt;- round(tab$freq/tab[nrow(tab), 3] * 100,1)"
  },
  {
    "objectID": "CARTO2_thematique.html#pakages-utilisés-dans-cette-session.",
    "href": "CARTO2_thematique.html#pakages-utilisés-dans-cette-session.",
    "title": "Faire des cartes thématiques avec R",
    "section": "Pakages utilisés dans cette session.",
    "text": "Pakages utilisés dans cette session.\nLes principaux packages utilisés dans cette section sont :\n\nsf\nmapsf"
  },
  {
    "objectID": "CARTO2_thematique.html#initiez-un-nouveau-projet",
    "href": "CARTO2_thematique.html#initiez-un-nouveau-projet",
    "title": "Faire des cartes thématiques avec R",
    "section": "Initiez un nouveau projet",
    "text": "Initiez un nouveau projet\n\nCréez un nouveau répertoire de travail.\nOuvrez Rstudio.\nCréez un nouveau projet et placez-le dans votre dossier.\nCréez un nouveau document Quarto (ou éventuellement un simple script R si vous préférez)\n\nSi vous n’avez pas les packages listés plus haut, vous pouvez les installer en tapant la ligne suivante dans la console.\n\ninstall.packages(c('sf', 'mapsf'))\n\nDans cette séquence, nous travaillons à l’échelle des pays africains. Les données statistiques sont issues de la base de données de la banque mondiale."
  },
  {
    "objectID": "CARTO2_thematique.html#télécharger-le-jeu-de-données",
    "href": "CARTO2_thematique.html#télécharger-le-jeu-de-données",
    "title": "Faire des cartes thématiques avec R",
    "section": "Télécharger le jeu de données",
    "text": "Télécharger le jeu de données\nTéléchargez-le dossier Africa.zip, dézippez-le et placez-les données dans un répertoire data.\nTout est prêt 😎"
  },
  {
    "objectID": "CARTO2_thematique.html#import-et-mise-en-forme-des-données",
    "href": "CARTO2_thematique.html#import-et-mise-en-forme-des-données",
    "title": "Faire des cartes thématiques avec R",
    "section": "Import et mise en forme des données",
    "text": "Import et mise en forme des données\n1 - Import des géométries\n\nlibrary(\"sf\")\n\nOn dispose d’un fichier geopackage contenant plusieurs géométries\n\nst_layers(\"data/Africa/afrique.gpkg\")\n\nDriver: GPKG \nAvailable layers:\n               layer_name     geometry_type features fields crs_name\n1 ne_10m_populated_places             Point     1305    137   WGS 84\n2            ne_10m_roads Multi Line String     6761     31   WGS 84\n3        ne_10m_railroads Multi Line String      758     12   WGS 84\n4                  africa           Polygon       55      4   WGS 84\n5                   world           Polygon      209      4   WGS 84\n\n\nOn importe la couche correspondant aux pays africains et on la reprojette en projection Pseudo-Mercator.\n\ngeom &lt;- st_transform(st_read(\"data/Africa/afrique.gpkg\", layer = \"africa\"),\"epsg:3857\")\n\n\n\n\n\n\n\nContenu du Spatial*DataFrame\n\n\n\n\n\n\n\nSimple feature collection with 4 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -2702989 ymin: -2329942 xmax: 6434678 ymax: 1782119\nProjected CRS: WGS 84 / Pseudo-Mercator\n  ISO3            NAMEen             NAMEfr region\n1  GNQ Equatorial Guinea Guinée-Équatoriale Africa\n2  COM           Comoros            Comores Africa\n3  CPV        Cape Verde           Cap-Vert Africa\n4  MUS         Mauritius            Maurice Africa\n                            geom\n1 MULTIPOLYGON (((1260368 241...\n2 MULTIPOLYGON (((4883099 -13...\n3 MULTIPOLYGON (((-2660139 17...\n4 MULTIPOLYGON (((6424679 -22...\n\n\n\n\n\n2 - Import des données statistiques issues de la banque mondiale.\n\ndata &lt;- read.csv(\"data/Africa/worldbank_africa.csv\")\n\n\n\n\n\n\n\nListe des variables disponibles\n\n\n\n\n\n\n\n          id  type                                      description\n1     region quali                                        subregion\n2        pop stock                                Population, total\n3        urb stock                                 Urban population\n4      rural stock                                 Rural population\n5   ruralpct ratio         Rural population (% of total population)\n6        gdp stock                                GDP (current US$)\n7      gdppc ratio                     GDP per capita (current US$)\n8        esp ratio          Life expectancy at birth, total (years)\n9       elec ratio          Access to electricity (% of population)\n10    forest stock                             Forest area (sq. km)\n11 forestpct ratio                     Forest area (% of land area)\n12  articles stock        Scientific and technical journal articles\n13  internet ratio Individuals using the Internet (% of population)\n14   servers ratio   Secure Internet servers (per 1 million people)\n\n\n\n\n\n3 - Jointure\n\nafrica &lt;-  merge(\n  x = geom[,\"ISO3\"],  \n  y = data,  \n  by.x = \"ISO3\",\n  by.y = \"id\",\n  all.x = TRUE   \n)\n\nOn dispose maintenant du Spatial*DataFrame africa qui contient à la fois des données et des géométries.\nEt on ajoute quelques couches additionnelles\n\nworld &lt;- st_transform(st_read(\"data/Africa/afrique.gpkg\", layer = \"world\"),\"epsg:3857\")\nplaces &lt;- st_transform(st_read(\"data/Africa/afrique.gpkg\", layer = \"ne_10m_populated_places\"),\"epsg:3857\")\nrail &lt;- st_transform(st_read(\"data/Africa/afrique.gpkg\", layer = \"ne_10m_railroads\"),\"epsg:3857\")\nroads &lt;- st_transform(st_read(\"data/Africa/afrique.gpkg\", layer = \"ne_10m_roads\"),\"epsg:3857\")"
  },
  {
    "objectID": "CARTO2_thematique.html#effet-dombrage",
    "href": "CARTO2_thematique.html#effet-dombrage",
    "title": "Faire des cartes thématiques avec R",
    "section": "Effet d’ombrage",
    "text": "Effet d’ombrage\nAvec R, il est aisé de translater une géométrie pour créer un effet d’ombrage.\n\npar(mar = c(0, 0, 0, 0))\nplot(st_geometry(africa) + c(50000,-50000), col = \"#827e6c80\", border = NA)\nplot(st_geometry(africa) , col = \"#5B89A3\", border = NA, add = TRUE)\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nOn peut faire varier la transparence d’une couleur au format hexadécimal en ajouter un nombre de 00 à 99 à la fin du code. Par exemple #827e6c60 applique une opacité de 60% à la couleur #827e6c.\n\n\nOn peut même imaginer cet ombrage en dégardé avec une boucle\n\ndelta &lt;- 20000\nnb &lt;- 15\npar(mar = c(0, 0, 0, 0))\nplot(st_geometry(africa) , col = NA, border = NA)\nfor (i in 1:nb) {\nplot(st_geometry(africa) + c(i * delta,-i * delta), col = \"#827e6c20\", border = NA, add = TRUE)\n}\nplot(st_geometry(africa) , col = \"#5B89A3\", border = NA, add = TRUE)"
  },
  {
    "objectID": "CARTO2_thematique.html#cartographie-thématique",
    "href": "CARTO2_thematique.html#cartographie-thématique",
    "title": "Faire des cartes thématiques avec R",
    "section": "Cartographie thématique",
    "text": "Cartographie thématique\nAvec le package sf, il est (un peu) possible de réaliser des cartes thématiques. Rappelez-vous les couleurs de tout à l’heure. Dans le cas où un seul attribut est sélectionné, une légende est attribuée par défaut à côté de la carte. Ici, une donnée qualitative.\n\nplot(africa[\"region\"])\n\n\n\n\nLe positionnement de la légende peut être défini par le paramètre key.pos (1 = dessous, 2 = gauche, 3 = dessus et 4 = droite). Sa taille peut également être modifiée avec les paramètres key.width et key.length\n\nplot(africa[\"region\"], key.pos = 1, key.length = 1)\n\n\n\n\nSi on souhaite cartographier une variable quantitative, la palette par défaut est différente.\n\nplot(africa[\"pop\"])\n\n\n\n\nGrace au paramètre breaks, il est possible de donner ses propres classes de valeur ou de donner une méthode de discrétisation (méthodes du package classInt).\n\nplot(africa[\"pop\"], breaks = \"jenks\")\n\n\n\n\n\nExports\nIci, on a affiché toutes les cartes dans le document. Mais on peut également choisir de les construire dans un format donné (pdf, svg, png, ps, etc.), ce qui peut être utile pour les retravailler dans un logiciel de DAO. Par exemple, on peut écrire :\n\nsvg(\"my_plot.svg\")\nplot(st_geometry(africa))\ndev.off() \n\n\n\nBilan et limites\n\n\n\n\n\n\nQue retenir ?\n\n\n\nLes fonctions de cartographies dans les fonctionnalités de base de sf sont très limitées. On ne peut pas, par exemple, dessiner des symboles proportionnels et leur légende associée. Si on veut aller plus loin, on a besoin d’un package spécialisé en représentations cartographiques. C’est à ce besoin que répond le package mapsf."
  },
  {
    "objectID": "CARTO2_thematique.html#documentation-et-supports",
    "href": "CARTO2_thematique.html#documentation-et-supports",
    "title": "Faire des cartes thématiques avec R",
    "section": "Documentation et supports",
    "text": "Documentation et supports\nDe nombreux documents permettent de prendre en main ce package.\n\nLe site web\nLa feuille de triche\nLe manuel cartographie avec R\n\nEt surtout, il faut aller voir dans la documentation du package directement dans RStudio. Vous y découvrirez une magnifique vignette."
  },
  {
    "objectID": "CARTO2_thematique.html#afficher-un-fond-de-carte",
    "href": "CARTO2_thematique.html#afficher-un-fond-de-carte",
    "title": "Faire des cartes thématiques avec R",
    "section": "Afficher un fond de carte",
    "text": "Afficher un fond de carte\nLa fonction mf_map() est la fonction centrale du package mapsf. Elle remplace la fonction plot. Elle permet de réaliser la plupart des représentations usuelles en cartographie. Par défaut, elle permet d’afficher un fond de carte.\n\nmf_map(africa)\n\n\n\n\nLa fonction mf_title() permet d’ajouter un titre à la place de main. Avec add = TRUE, on peut supproposer des couches.\n\n\n\n\n\n\nAstuce\n\n\n\nEn affichant une première couche avec border = NA et col = NA, on peut ajouter un calque vide pour fixer l’emprise de la carte\n\n\n\nmf_map(x = africa, border = NA, col = NA)\nmf_map(x = world, border = \"white\", col = \"#CCCCCC50\", lwd = 0.5, add = TRUE)\nmf_map(x = africa, border = \"white\", col = \"#6893d9\", lwd = 0.5, add = TRUE)\nmf_map(x = places, pch = 20, cex = .7, col = \"darkred\", add = TRUE)\nmf_title(txt = \"L'Afrique\")\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nPour déterminer la taille de la figure, vous pouvez utiliser la fonction mf_get_ratio()"
  },
  {
    "objectID": "CARTO2_thematique.html#symboles-proportionnels",
    "href": "CARTO2_thematique.html#symboles-proportionnels",
    "title": "Faire des cartes thématiques avec R",
    "section": "Symboles proportionnels",
    "text": "Symboles proportionnels\nPour représenter une donnée quantitative absolue (i.e. donnée de stock), on utilise la fonction mf_map avec le paramètre type = \"prop\"\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_map(x = africa,\n       var = \"pop\",\n       type = \"prop\",\n       border = \"white\",\n       col = \"#FF000080\",\n       leg_title = \"Nombre d'habitants\\nen 2020\",\n       inches   = 0.4 # taille du plus grand symbole\n)\nmf_title(txt = \"Population totale\")\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nPour dessiner des carrés au lieu des cercles, vous pouvez utiliser symbol = \"square\""
  },
  {
    "objectID": "CARTO2_thematique.html#symboles-gradués",
    "href": "CARTO2_thematique.html#symboles-gradués",
    "title": "Faire des cartes thématiques avec R",
    "section": "Symboles gradués",
    "text": "Symboles gradués\nAvec le type \"grad\", vous pouvez réaliser la même carte avec des symboles gradués (ce qui dans le cas de figure ici, est moins efficace). Pour cela, vous devez choisir un nombre de classes (nbreaks) et une méthode de discrétisation (breaks).\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_map(x = africa,\n       var = \"pop\",\n       type = \"grad\",\n       nbreaks = 5,\n       method = \"quantile\",\n       border = \"white\",\n       col = \"#FF000080\",\n       leg_title = \"Nombre d'habitants\\nen 2020\",\n       inches   = 0.4)\nmf_title(txt = \"Population totale (classes de tailles)\")"
  },
  {
    "objectID": "CARTO2_thematique.html#carte-choroplèthe",
    "href": "CARTO2_thematique.html#carte-choroplèthe",
    "title": "Faire des cartes thématiques avec R",
    "section": "Carte choroplèthe",
    "text": "Carte choroplèthe\nPour représenter des données quantitatives relatives (ratio, indices, échelles…), on utilisera la plupart du temps des dégradés de couleurs. Dans mapsf, cela s’effectue avec le type \"choro\". Comme précédemment, les paramètres nbreaks et breaks permettent de paramétrer les discrétisations.\n\nmf_map(x = africa,\n       var = \"gdppc\",\n       type = \"choro\",\n       nbreaks = 5,\n       border = \"white\",\n       leg_title = \"PIB par habitant\\n(US$ courants)\")\nmf_title(txt = \"Richesse des pays d'Anfrique en 2020\")\n\n\n\n\nPar défaut, la méthode de discrétisation est la méthode des quantiles. Elle s’adapte donc à n’importe quelle distribution de données. Mais avant de réaliser une carte choroplèthe, il est préférable d’étudier d’abord la distribution statistique de la variable que l’on souhaite cartographier. La fonction mf_distr() permet de visualiser cette distributions.\n\nmf_distr(africa$gdppc)\n\n\n\n\nIci, la série est dissymétrique à gauche, on peut donc opter plutôt pour la méthode \"geom\" qui est adaptée à ce type de distribution (les méthodes disponibles sont : \"fixed\", \"sd\", \"equal\", \"pretty\", \"quantile\", \"kmeans\", \"hclust\", \"bclust\", \"fisher\", \"jenks\", \"dpih\", \"q6\", \"geom\", \"arith\", \"em\" ou \"msd\").\n\nmf_map(x = africa,\n       var = \"gdppc\",\n       type = \"choro\",\n       breaks = \"geom\",\n       nbreaks = 4,\n       border = \"white\",\n       leg_title = \"PIB par habitant\\n(US$ courants)\")\nmf_title(txt = \"Richesse des pays d'Afrique en 2020 (method = 'geom')\")\n\n\n\n\nPour changer les couleurs, vous pouvez renseigner une palette de couleur avec l’argument pal. Par exemple :\n\npal = \"Magenta\"\n\n\nSi vous le souhaitez, vous pouvez aussi choisir vos propres couleurs.\n\npal = c(\"#F3CAD2\", \"#E08BB1\", \"#AF4F91\", \"#6D1C68\")\n\nOu créer une palette sur mesure avec la fonction mf_get_pal().\n\npal = mf_get_pal(n = c(6,3), palette = c(\"Burg\", \"Teal\"))"
  },
  {
    "objectID": "CARTO2_thematique.html#carte-de-typologie",
    "href": "CARTO2_thematique.html#carte-de-typologie",
    "title": "Faire des cartes thématiques avec R",
    "section": "Carte de typologie",
    "text": "Carte de typologie\nPour cartographier des données qualitatives, on utilise type = \"typo\".\n\nmf_map(x = africa,\n       var = \"region\",\n       type = \"typo\",\n       breaks = \"geom\",\n       border = \"white\")\nmf_title(txt = \"Les grandes régions d'Afrique\")\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nL’argument val_order sert à ordonner les modalités dans la légende. Par exemple :\n\nval_order = c(\"Northern Africa\", \"Eastern Africa\", \"Western Africa\", \"Middle Africa\", \"Southern Africa\")"
  },
  {
    "objectID": "CARTO2_thematique.html#combinaisons",
    "href": "CARTO2_thematique.html#combinaisons",
    "title": "Faire des cartes thématiques avec R",
    "section": "Combinaisons",
    "text": "Combinaisons\nPour réaliser des cartes combinant deux variables, il est possible de superposer une carte choroplèthe et une carte de stock. Par exemple :\n\nmf_map(x = africa,\n       var = \"gdppc\",\n       type = \"choro\",\n       nbreaks = 5,\n       border = \"white\",\n       leg_pos = \"topleft\",\n       leg_title = \"PIB par habitant\\n(US$ courants)\")\nmf_map(x = africa,\n       var = \"pop\",\n       type = \"prop\",\n       border = \"black\",\n       leg_pos = \"bottomleft\",\n       col = NA,\n       leg_title = \"Nombre d'habitants\\nen 2020\",\n       inches   = 0.4)\nmf_title(txt = \"Population et richesse en Afrique\")\n\n\n\n\nMais vous pouvez aussi utiliser le types \"prop_choro\" et \"prop_typo\".\nDans ce cas, les choses se présentent comme ceci :\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_map(x = africa,\n       var = c(\"pop\",\"gdppc\"),\n       type = \"prop_choro\",\n       nbreaks = 5,\n       border = \"white\",\n       leg_pos = c(\"bottomleft\",\"topleft\"),\n       leg_title = c(\"Nombre d'habitants\\nen 2020\", \"PIB par habitant\\n(US$ courants)\"),\n       inches   = 0.4)\n\n\n\n\nOu bien :\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_map(x = africa,\n       var = c(\"pop\",\"region\"),\n       type = \"prop_typo\",\n       nbreaks = 5,\n       border = \"white\",\n       leg_pos = c(\"bottomleft\",\"topleft\"),\n       leg_title = c(\"Nombre d'habitants\\nen 2020\", \"Régions d'appartenance\"),\n       inches   = 0.4)"
  },
  {
    "objectID": "CARTO2_thematique.html#elements-dhabillage",
    "href": "CARTO2_thematique.html#elements-dhabillage",
    "title": "Faire des cartes thématiques avec R",
    "section": "Elements d’habillage",
    "text": "Elements d’habillage\nLa package mapsf pemet d’ajouter plusieurs éléments d’habillage.\n\nmf_title() permet d’ajouter un titre\nmf_credits() permet d’afficher la source\nmf_scale() ajoute une échelle\nmf_arrow() ajoute une orientation.\n\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_title(txt = \"Population totale\")\nmf_credits(txt = \"Source : Banque mondiale, 2024\")\nmf_scale()\nmf_arrow()\n\n\n\n\nTous ces éléments sont personnalisables.\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_title(txt = \"Population totale\", pos = \"center\", tab = FALSE, bg = \"#6888ba\")\nmf_credits(txt = \"Source : Banque mondiale, 2024\", pos = \"bottomright\", cex = 1)\nmf_scale(col = \"red\", scale_units = \"mi\", pos = \"bottomleft\")\nmf_arrow(pos = \"topright\")\n\n\n\n\n\n\n\n\n\n\nAstuce\n\n\n\nTous ces éléments peuvent être regroupés dans la fonction mf_layout()\n\nmf_layout(\n  title = \"L'AfRique\",\n  credits = \"Banque mondiale, 2024\",\n  arrow = TRUE, \n  scale = TRUE\n)\n\n\n\nAvec mf_shadow() vous pouvez également ajouter un ombrage.\nAvec mf_graticule(), des lignes de latitude et longitude avec de belles annotations.\n\nmf_shadow(x = africa, col = \"grey50\", cex = 1)\nmf_graticule(\n  x = africa,\n  col = \"coral4\",\n  lwd = 2,\n  lty = 2,\n  expandBB = c(.1, 0, 0, .1),\n  label = TRUE,\n  pos = c(\"right\", \"bottom\"),\n  cex = .8,\n  add = TRUE\n)\nmf_map(x = africa, border = \"white\", lwd = 0.5, add= TRUE)"
  },
  {
    "objectID": "CARTO2_thematique.html#textes-et-étiquettes",
    "href": "CARTO2_thematique.html#textes-et-étiquettes",
    "title": "Faire des cartes thématiques avec R",
    "section": "Textes et étiquettes",
    "text": "Textes et étiquettes\nVous pouvez ajouter des etiquettes avec la fonction mf_label()\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_label( x = africa,\n  var = \"name\",\n  col= \"black\",\n  halo = TRUE,\n  overlap = FALSE,\n  lines = TRUE)\n\n\n\n\nEt une simple étiquette avec mf_annotation()\n\nmf_map(x = africa, border = \"white\", lwd = 0.5)\nmf_annotation(\n  x = africa[africa$ISO3 == \"TUN\", ],\n  txt = \"Tunisie\",\n  halo = TRUE,\n  cex = 1.5,\n  pos = \"bottomleft\"\n)"
  },
  {
    "objectID": "CARTO2_thematique.html#les-thèmes",
    "href": "CARTO2_thematique.html#les-thèmes",
    "title": "Faire des cartes thématiques avec R",
    "section": "Les thèmes",
    "text": "Les thèmes\nUne série de thèmes prédéfinis est disponible : \"default\", \"brutal\", \"ink\", \"dark\", \"agolalight\", \"candy\", \"darkula\", \"iceberg\", \"green\", \"nevermind\", \"jsk\", \"barcelona\".\nPar exemple :\n\nmf_theme(\"nevermind\")\nmf_map(x = africa)\nmf_title(txt = \"Le thème nevermind\")\n\n\n\n\nLe système de thèmes est très flexible. Vous pouvez prendre un thème et le modifier.\n\nmf_theme(\"nevermind\", tab = TRUE, bg = \"green\")\nmf_map(x = africa)\nmf_title(txt = \"Le thème nevermind modifié\")"
  },
  {
    "objectID": "CARTO2_thematique.html#planches-cartographiques",
    "href": "CARTO2_thematique.html#planches-cartographiques",
    "title": "Faire des cartes thématiques avec R",
    "section": "Planches cartographiques",
    "text": "Planches cartographiques\nAvec R, il est aisé de construire des figures contenant plusieurs graphiques, grâce à l’argument mfrow de la fonction par().\n\nmf_theme(\"default\")\n\nopar &lt;- par(mfrow = c(1, 2))\n\nmf_map(x = africa,\n       var = \"gdppc\",\n       type = \"choro\",\n       border = \"white\",\n       leg_title = \"PIB par habitant\\n(US$ courants)\",\n       inches   = 0.4)\n\nmf_map(x = africa,\n       var = \"elec\",\n       type = \"choro\",\n       nbreaks = 4,\n       border = \"white\",\n       pal = \"Magenta\",\n       leg_title = \"Accès à l'électricité\\n(% de la pop)\",\n       inches   = 0.4)\n\n\n\npar(opar)"
  },
  {
    "objectID": "CARTO2_thematique.html#cartons",
    "href": "CARTO2_thematique.html#cartons",
    "title": "Faire des cartes thématiques avec R",
    "section": "Cartons",
    "text": "Cartons\nLa fonction mf_inset_on() permet de démarrer la création d’un carton. Il faut ensuite “refermer” le carton avec mf_inset_off().\n\n# Carte principale\nmf_map(africa)\n\n# Petite carte\ntun &lt;- africa[africa$ISO3 == \"TUN\", ]\nmf_inset_on(x = tun, pos = \"topright\", cex = .1)\nmf_map(tun, col = \"#e69749\", border = \"white\")\nmf_scale(pos = \"bottomright\")\nbox()\nmf_inset_off()\n# Fin de la petite carte\n\nmf_title(\"Afrique et Tunisie\")"
  },
  {
    "objectID": "CARTO2_thematique.html#exportez-une-carte",
    "href": "CARTO2_thematique.html#exportez-une-carte",
    "title": "Faire des cartes thématiques avec R",
    "section": "Exportez une carte",
    "text": "Exportez une carte\nEnfin, la fonction mf_export() vous permet d’exporter vos cartes dans différents formats.\n\nmf_export(africa, filename = \"macarte.svg\")\nmf_map(africa, add = TRUE)\ndev.off()\n\nquartz_off_screen \n                2"
  },
  {
    "objectID": "CARTO2_thematique.html#a-vous-de-jouer",
    "href": "CARTO2_thematique.html#a-vous-de-jouer",
    "title": "Faire des cartes thématiques avec R",
    "section": "A vous de jouer",
    "text": "A vous de jouer\nRéalisez une carte sur un indicateur de votre choix. Si besoin, vous pouvez aller chercher d’autres indicateurs grâce au package wbstats\nSi vous ne l’avez pas déjà installé, tapez ceci dans la console.\n\ninstall.packages('wbstats')\n\n\nlibrary(wbstats)\n\nPar exemple\n\nwb_search(pattern = \"Bird\")\n\n# A tibble: 2 × 3\n  indicator_id   indicator                  indicator_desc                      \n  &lt;chr&gt;          &lt;chr&gt;                      &lt;chr&gt;                               \n1 EN.ANM.THRD.NO Animal species, threatened Animal species are mammals (excludi…\n2 EN.BIR.THRD.NO Bird species, threatened   Birds are listed for countries incl…\n\noiseaux_menaces &lt;- wb_data(\"EN.BIR.THRD.NO\", start_date = 2018, end_date = 2018)\nhead(oiseaux_menaces)\n\n# A tibble: 6 × 9\n  iso2c iso3c country              date EN.BIR.THRD.NO unit  obs_status footnote\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;   \n1 AW    ABW   Aruba                2018              2 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;    \n2 AF    AFG   Afghanistan          2018             16 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;    \n3 AO    AGO   Angola               2018             32 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;    \n4 AL    ALB   Albania              2018              8 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;    \n5 AD    AND   Andorra              2018              3 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;    \n6 AE    ARE   United Arab Emirat…  2018             13 &lt;NA&gt;  &lt;NA&gt;       &lt;NA&gt;    \n# ℹ 1 more variable: last_updated &lt;date&gt;\n\nafrica_birds &lt;-  merge(\n  x = geom[,\"ISO3\"],  \n  y = oiseaux_menaces,  \n  by.x = \"ISO3\",\n  by.y = \"iso3c\",\n  all.x = TRUE   \n)\n\n\nmf_map(x = africa, border = NA, col = NA)\nmf_map(x = world, border = \"white\", col = \"#CCCCCC50\", lwd = 0.5, add = TRUE)\nmf_map(x = africa, border = \"white\", col = \"#6893d9\", lwd = 0.5, add = TRUE)\nmf_map(x = africa_birds,\n       var = \"EN.BIR.THRD.NO\",\n       type = \"prop\",\n       symbol = \"square\",\n       border = \"white\",\n       col = \"#FF000080\",\n       leg_title = \"Nombre d'oiseaux\\nmenacés en 2018\",\n       inches   = 0.3)"
  },
  {
    "objectID": "CARTO2_thematique.html#cartogrammes-de-dorling",
    "href": "CARTO2_thematique.html#cartogrammes-de-dorling",
    "title": "Faire des cartes thématiques avec R",
    "section": "Cartogrammes de Dorling",
    "text": "Cartogrammes de Dorling\n\n#library(mapsf)\nlibrary(cartogram)\n\n\npop2020_dorling &lt;- cartogram_dorling(\n  africa[!is.na(africa$pop),],\n  weight = \"pop\",\n  k=2.5\n  )\n\n\nmf_map(africa, col = \"white\", border= NA)\nmf_map(pop2020_dorling, col = \"#5B89A3\", border= \"white\", add = TRUE)\nmf_label(\n  x = pop2020_dorling[order(pop2020_dorling$pop, decreasing = TRUE), ][1:10,],\n  var = \"name\",\n  col = \"#5B89A3\",\n  overlap = FALSE, lines = FALSE,\n  halo = TRUE,\n  r = .15\n)\nmf_title(\"Population totale - Cartogramme de Dorling\")"
  },
  {
    "objectID": "CARTO2_thematique.html#les-cartogrammes-non-continus",
    "href": "CARTO2_thematique.html#les-cartogrammes-non-continus",
    "title": "Faire des cartes thématiques avec R",
    "section": "Les cartogrammes non continus",
    "text": "Les cartogrammes non continus\n\nafr_ncont &lt;- cartogram_ncont(x = africa, weight = \"pop\", k = 1.2)\nmf_map(africa, border = \"white\", lwd = 0.5,)\nmf_map(afr_ncont, col = \"#5B89A3\", border= \"white\", add = TRUE)\nmf_title(\"Population en Afrique - Cartogramme de Olson\")"
  },
  {
    "objectID": "CARTO2_thematique.html#cartogrammes-continus",
    "href": "CARTO2_thematique.html#cartogrammes-continus",
    "title": "Faire des cartes thématiques avec R",
    "section": "Cartogrammes continus",
    "text": "Cartogrammes continus\n\nafrica[is.na(africa$pop),\"pop\"] &lt;- 1\nafr_cont &lt;- cartogram_cont(x = africa,\n                           weight = \"pop\",\n                           itermax = 30)\nmf_map(afr_cont, col = \"#5B89A3\", border= \"white\", add = FALSE)\nmf_title(\"Population en Afrique - Cartogramme de Dougenik\")\nmf_inset_on(africa, cex = .2, pos = \"topleft\")\nmf_map(africa, lwd = .5, border = \"white\")\nmf_inset_off()"
  },
  {
    "objectID": "CARTO2_thematique.html#aller-plus-loin",
    "href": "CARTO2_thematique.html#aller-plus-loin",
    "title": "Faire des cartes thématiques avec R",
    "section": "Aller plus loin",
    "text": "Aller plus loin\nPour en savoir plus sur les différentes formes de cartogrammes, vous pouvez aussi consulter ce document réalisé en 2021 : transcarto.github.io/rcartograms/TRANSCARTO_cartograms.html"
  },
  {
    "objectID": "CARTO2_thematique.html#mapview",
    "href": "CARTO2_thematique.html#mapview",
    "title": "Faire des cartes thématiques avec R",
    "section": "mapview",
    "text": "mapview\nLe package mapview permet de créer rapidement et facilement des visualisations interactives de données spatiales avec ou sans fond de carte. Le package s’installe de la façon suivante :\n\ninstall.packages('mapview')\n\n\nlibrary(sf)\nlibrary(mapview)\n\n\nmapview(africa) + mapview(st_centroid(africa))"
  },
  {
    "objectID": "CARTO2_thematique.html#leaflet",
    "href": "CARTO2_thematique.html#leaflet",
    "title": "Faire des cartes thématiques avec R",
    "section": "Leaflet",
    "text": "Leaflet\nLeaflet est un package basé sur le JavaScript, permettant de faire de la cartographie interactive. On l’installe de la façon suivante :\n\ninstall.packages('leaflet')\n\n\nlibrary(leaflet)\n\nRéalisation d’une première carte simple\n\nm = leaflet() %&gt;% addTiles()\nm\n\n\n\n\n\nZoom sur une localisation précise.\n\nsfax &lt;- c(10.760034694759957, 34.7407779744004)\nm2 &lt;- leaflet() %&gt;% setView(lng = sfax[1], lat = sfax[2], zoom = 12) %&gt;% \n  addTiles() \nm2\n\n\n\n\n\nAjout de géométries\n\nafrica_wgs84 &lt;- st_transform(africa, 4326)\npopup &lt;- paste0(\"&lt;b&gt;\",africa_wgs84$name,\"&lt;/b&gt;&lt;br/&gt;&lt;b&gt;Population: &lt;/b&gt;\", \n                africa_wgs84$pop)\nm3 = leaflet() %&gt;% \n  addTiles() %&gt;% \n  addPolygons(data=africa_wgs84, weight = 2, fillColor = \"yellow\", popup= popup) %&gt;%         \n  addMarkers(data = st_centroid(africa_wgs84)) %&gt;%  addMiniMap(position = \"bottomright\")\n\nWarning: st_centroid assumes attributes are constant over geometries\n\nm3"
  },
  {
    "objectID": "CARTO2_thematique.html#au-delà-de-r",
    "href": "CARTO2_thematique.html#au-delà-de-r",
    "title": "Faire des cartes thématiques avec R",
    "section": "Au delà de R",
    "text": "Au delà de R\nAvec Quarto et Observable JavaScript, il est également possible de créer des cartes thématiques interactives dans Rstudio."
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html",
    "href": "STA2B_biv_quali_quanti.html",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "",
    "text": "Nous allons importer un fichier de données portant sur les revenus de 17000 ménages tunisiens en 2021. Il est tiré de l’enquête consommation et revenu de l’INS que l’on peut télécharger librement en cliquant ici\n\n\nOn commence par charger les données contenues dans le fichier enq_INS_conso_menages_2021.RDS à l’aide de la fonction readRDS(). On tape ensuite la commande str()pour connaître les caractéristiques de l’objet.\n\n# Importe les données au format interne de R\nbase&lt;-readRDS(\"data/ENQ-TUN-2021/enq_INS_conso_menages_2021.RDS\")\nstr(base)\n\n'data.frame':   17114 obs. of  11 variables:\n $ id : num  1 2 3 4 5 6 7 8 9 10 ...\n $ reg: Factor w/ 7 levels \"GT\",\"NE\",\"NO\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ mil: Factor w/ 2 levels \"urbain\",\"rural\": 1 1 1 1 1 1 1 1 1 1 ...\n $ sex: Factor w/ 2 levels \"homme\",\"femme\": 1 1 2 1 1 1 2 1 1 1 ...\n $ age: num  59 52 34 65 35 43 64 71 51 56 ...\n $ mat: Factor w/ 4 levels \"celibataire\",..: 3 3 2 3 3 3 4 3 3 3 ...\n $ ins: Factor w/ 4 levels \"aucun\",\"primaire\",..: 2 2 3 2 3 2 1 3 3 2 ...\n $ csp: Factor w/ 8 levels \"cadre\",\"employé\",..: 7 2 6 8 4 4 4 7 4 4 ...\n $ nbp: num  6 5 2 2 4 5 6 3 2 4 ...\n $ pvr: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ rev: num  5103 5486 5962 3699 5058 ...\n\n\n\n\n\nOn a légèrement changé le fichier initial de l’INS en simplifiant les noms des variables et en fusionnant certaines modalités. Les variables proposées sont les suivantes :\n\nid : identifiant du ménages de 1 à 17114\nreg : région de résidence (NE, NO, CE, CO, SE, SO + Grand Tunis)\nmil : milieu de résidence (urbain ou rural)\nsex : sexe du chef de ménage\nage : age du chef de ménage\nmat : situation matrimoniale (célbataire, marié, veuf, divorcé)\nins : instruction du chef de ménage (aucune, primaire, secondaire, supérieur)\ncsp : catégorie socio professionnelle du chef de ménage (simplifiée)\nnbp : nombre de personnes composant le ménage\npauv: situation de pauvreté selon les critères de l’INS (Oui/Non)\nrev : revenu moyen par personnes en DT / an\n\n\n\n\nOn suppose qu’on ne s’intéresse qu’à quelques variables\n\ndon&lt;-base[,c(\"reg\",\"mil\",\"sex\", \"age\",\"ins\",\"rev\")]\nhead(don)\n\n  reg    mil   sex age        ins  rev\n1  GT urbain homme  59   primaire 5103\n2  GT urbain homme  52   primaire 5486\n3  GT urbain femme  34 secondaire 5962\n4  GT urbain homme  65   primaire 3699\n5  GT urbain homme  35 secondaire 5058\n6  GT urbain homme  43   primaire 3741\n\n\n\n\n\nOn effectue un résumé rapide du tableau à l’aide de la fonction summary():\n\nsummary(don)\n\n reg           mil           sex             age                 ins      \n GT:3944   urbain:10836   homme:13996   Min.   : 19.00   aucun     :3742  \n NE:2458   rural : 6278   femme: 3118   1st Qu.: 46.00   primaire  :6979  \n NO:2502                                Median : 56.00   secondaire:4647  \n CE:2862                                Mean   : 56.34   supérieur :1746  \n CO:2330                                3rd Qu.: 66.00                    \n SE:1845                                Max.   :109.00                    \n SO:1173                                                                  \n      rev        \n Min.   :   185  \n 1st Qu.:  3035  \n Median :  4429  \n Mean   :  5519  \n 3rd Qu.:  6496  \n Max.   :526271  \n                 \n\n\nOn retient comme variable Y quantitative le revenu moyen annuel par personne du ménage. Par exemple si le revenu annuel est de 10000 DT et que ce ménage comporte 4 personnes, alors le revenu moyen annuel par personne sera de 2500 DT."
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#importation-des-données",
    "href": "STA2B_biv_quali_quanti.html#importation-des-données",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "",
    "text": "On commence par charger les données contenues dans le fichier enq_INS_conso_menages_2021.RDS à l’aide de la fonction readRDS(). On tape ensuite la commande str()pour connaître les caractéristiques de l’objet.\n\n# Importe les données au format interne de R\nbase&lt;-readRDS(\"data/ENQ-TUN-2021/enq_INS_conso_menages_2021.RDS\")\nstr(base)\n\n'data.frame':   17114 obs. of  11 variables:\n $ id : num  1 2 3 4 5 6 7 8 9 10 ...\n $ reg: Factor w/ 7 levels \"GT\",\"NE\",\"NO\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ mil: Factor w/ 2 levels \"urbain\",\"rural\": 1 1 1 1 1 1 1 1 1 1 ...\n $ sex: Factor w/ 2 levels \"homme\",\"femme\": 1 1 2 1 1 1 2 1 1 1 ...\n $ age: num  59 52 34 65 35 43 64 71 51 56 ...\n $ mat: Factor w/ 4 levels \"celibataire\",..: 3 3 2 3 3 3 4 3 3 3 ...\n $ ins: Factor w/ 4 levels \"aucun\",\"primaire\",..: 2 2 3 2 3 2 1 3 3 2 ...\n $ csp: Factor w/ 8 levels \"cadre\",\"employé\",..: 7 2 6 8 4 4 4 7 4 4 ...\n $ nbp: num  6 5 2 2 4 5 6 3 2 4 ...\n $ pvr: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n $ rev: num  5103 5486 5962 3699 5058 ..."
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#liste-des-variables",
    "href": "STA2B_biv_quali_quanti.html#liste-des-variables",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "",
    "text": "On a légèrement changé le fichier initial de l’INS en simplifiant les noms des variables et en fusionnant certaines modalités. Les variables proposées sont les suivantes :\n\nid : identifiant du ménages de 1 à 17114\nreg : région de résidence (NE, NO, CE, CO, SE, SO + Grand Tunis)\nmil : milieu de résidence (urbain ou rural)\nsex : sexe du chef de ménage\nage : age du chef de ménage\nmat : situation matrimoniale (célbataire, marié, veuf, divorcé)\nins : instruction du chef de ménage (aucune, primaire, secondaire, supérieur)\ncsp : catégorie socio professionnelle du chef de ménage (simplifiée)\nnbp : nombre de personnes composant le ménage\npauv: situation de pauvreté selon les critères de l’INS (Oui/Non)\nrev : revenu moyen par personnes en DT / an"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#selection-du-tableau-à-analyser",
    "href": "STA2B_biv_quali_quanti.html#selection-du-tableau-à-analyser",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "",
    "text": "On suppose qu’on ne s’intéresse qu’à quelques variables\n\ndon&lt;-base[,c(\"reg\",\"mil\",\"sex\", \"age\",\"ins\",\"rev\")]\nhead(don)\n\n  reg    mil   sex age        ins  rev\n1  GT urbain homme  59   primaire 5103\n2  GT urbain homme  52   primaire 5486\n3  GT urbain femme  34 secondaire 5962\n4  GT urbain homme  65   primaire 3699\n5  GT urbain homme  35 secondaire 5058\n6  GT urbain homme  43   primaire 3741"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#résumé-rapide",
    "href": "STA2B_biv_quali_quanti.html#résumé-rapide",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "",
    "text": "On effectue un résumé rapide du tableau à l’aide de la fonction summary():\n\nsummary(don)\n\n reg           mil           sex             age                 ins      \n GT:3944   urbain:10836   homme:13996   Min.   : 19.00   aucun     :3742  \n NE:2458   rural : 6278   femme: 3118   1st Qu.: 46.00   primaire  :6979  \n NO:2502                                Median : 56.00   secondaire:4647  \n CE:2862                                Mean   : 56.34   supérieur :1746  \n CO:2330                                3rd Qu.: 66.00                    \n SE:1845                                Max.   :109.00                    \n SO:1173                                                                  \n      rev        \n Min.   :   185  \n 1st Qu.:  3035  \n Median :  4429  \n Mean   :  5519  \n 3rd Qu.:  6496  \n Max.   :526271  \n                 \n\n\nOn retient comme variable Y quantitative le revenu moyen annuel par personne du ménage. Par exemple si le revenu annuel est de 10000 DT et que ce ménage comporte 4 personnes, alors le revenu moyen annuel par personne sera de 2500 DT."
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#la-distribution-de-y-est-elle-normale",
    "href": "STA2B_biv_quali_quanti.html#la-distribution-de-y-est-elle-normale",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "2.1 La distribution de Y est-elle normale ?",
    "text": "2.1 La distribution de Y est-elle normale ?\n\nmybreaks &lt;- quantile(don$rev,0:10/10)\npar(mfrow=c(1,2))\nhist(don$rev,\n     breaks = mybreaks,\n     col=\"lightyellow\",\n     probability = TRUE)\nlines(density(don$rev,bw=1000),col=\"red\",lwd=1)\nboxplot(don$rev, col=\"lightyellow\",horizontal = T)\n\n\n\n\nLa distribution ne semble pas du tout normale. Elle est très asymétrique et il y a des valeurs très exceptionnelles."
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#elimination-des-valeurs-exceptionnelles",
    "href": "STA2B_biv_quali_quanti.html#elimination-des-valeurs-exceptionnelles",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "2.2 Elimination des valeurs exceptionnelles",
    "text": "2.2 Elimination des valeurs exceptionnelles\nOn va retirer les individus dont le revenu dépasse 20 000 DT et créer un fichier don2\n\ndon2&lt;-don[don$rev&lt;20000,]\nmybreaks &lt;- quantile(don2$rev,0:10/10)\npar(mfrow=c(1,2))\nhist(don2$rev,\n     breaks = mybreaks,\n     col=\"lightyellow\",\n     probability = TRUE)\nlines(density(don2$rev,bw=1000),col=\"red\",lwd=1)\nboxplot(don2$rev, col=\"lightyellow\",horizontal = T)\n\n\n\n\nIl demeure beaucoup de valeurs exceptionnelles et la dissymétrie n’est pas totalement éliminée. On décide donc de descendre juqu’à 15000\nOn va retirer les individus dont le revenu dépasse 10 000 DT et créer un fichier don3\n\ndon3&lt;-don[don$rev&lt;10000,]\nmybreaks &lt;- quantile(don3$rev,0:10/10)\npar(mfrow=c(1,2))\nhist(don3$rev,\n     breaks = mybreaks,\n     col=\"lightyellow\",\n     probability = TRUE)\nlines(density(don3$rev,bw=1000),col=\"red\",lwd=1)\nboxplot(don3$rev, col=\"lightyellow\",horizontal = T)"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#hypothèses",
    "href": "STA2B_biv_quali_quanti.html#hypothèses",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "3.1 Hypothèses",
    "text": "3.1 Hypothèses\nOn considère une variable Y quantitative continue définie sur une population de réféence P et une variable X qualitative à deux modalités divisant P en deux sous population P1 et P2.\nSoit par exemple la variable Y = rev et la variable X = mil. On peut se demander si les revenus des ménages urbains sont plus ou moins élevés que ceux des ménages ruraux.\n\nY&lt;-don3$rev\nnomY &lt;-\"Revenu par personne\"\n\nX&lt;-don3$mil\nnomX &lt;- \"Milieu\""
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#visualisations",
    "href": "STA2B_biv_quali_quanti.html#visualisations",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "3.2 Visualisations",
    "text": "3.2 Visualisations\nLe plus simple est d’utiliser boxplot() en version de base …\n\nboxplot(Y~X)\n\n\n\n\n… ou améliorée\n\nboxplot(Y~X,\n        horizontal=T, \n        xlab = nomY, \n        ylab=nomX, \n        col=\"gray80\")"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#paramètres-principaux",
    "href": "STA2B_biv_quali_quanti.html#paramètres-principaux",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "3.3 Paramètres principaux",
    "text": "3.3 Paramètres principaux\nLa fonction tapply() permet de calculer les paramètres statistiques de Y en fonction des modalités de X.\n\nmoy&lt;-tapply(Y,X, mean)\nect&lt;-tapply(Y,X,sd)\ncv&lt;-100*ect/moy\nres&lt;-cbind(moy,ect,cv)\nres\n\n            moy      ect      cv\nurbain 5012.590 2029.743 40.4929\nrural  3684.426 1778.546 48.2720"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#test-dégalité-des-moyennes",
    "href": "STA2B_biv_quali_quanti.html#test-dégalité-des-moyennes",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "3.4 Test d’égalité des moyennes",
    "text": "3.4 Test d’égalité des moyennes\n\nTest de student\nLe test de Student permet de tester l’hypothèse d’égalité des moyennes entre deux échantillons. Il suppose que la distribution est gaussienne.\n\nt.test(Y~X)\n\n\n    Welch Two Sample t-test\n\ndata:  Y by X\nt = 43.062, df = 14200, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group urbain and group rural is not equal to 0\n95 percent confidence interval:\n 1267.708 1388.621\nsample estimates:\nmean in group urbain  mean in group rural \n            5012.590             3684.426 \n\n\n\n\nTest de Wilcoxon\nLe test de Wilcoxon permet également de tester l’hypothèse d’égalité des moyennes entre deux échantillons. Il ne suppose que la distribution est gaussienne car il travaille sur les rangs et non pas les valeurs.\n\nwilcox.test(Y~X)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Y by X\nW = 40316246, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#que-faire-lorsque-x-a-plus-de-deux-modalités",
    "href": "STA2B_biv_quali_quanti.html#que-faire-lorsque-x-a-plus-de-deux-modalités",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "Que faire lorsque X a plus de deux modalités ?",
    "text": "Que faire lorsque X a plus de deux modalités ?\nSupposons que nous voulions maintenant examiner la relation entre revenu et niveau d’instruction. On une peut commencer par réaliser une boxplot comme précédemment :\n\nY&lt;-don3$rev\nnomY &lt;-\"Revenu par personne\"\nX&lt;-don3$ins\nnomX &lt;- \"Niveau d'instruction\"\n\nboxplot(Y~X, horizontal=T)\n\n\n\n\nOn peut également construire un tableau de paramètres par modalités\n\nmoy&lt;-tapply(Y,X, mean)\nect&lt;-tapply(Y,X, sd)\ncv=100*moy/ect\n\nparam&lt;-data.frame(moy,ect,cv)\n\nparam\n\n                moy      ect       cv\naucun      4216.892 1957.342 215.4398\nprimaire   4232.572 1951.893 216.8444\nsecondaire 4769.130 2032.135 234.6857\nsupérieur  5787.599 2162.304 267.6588"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#impossible-dutiliser-le-test-dégalité-de-deux-moyennes",
    "href": "STA2B_biv_quali_quanti.html#impossible-dutiliser-le-test-dégalité-de-deux-moyennes",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "Impossible d’utiliser le test d’égalité de deux moyennes",
    "text": "Impossible d’utiliser le test d’égalité de deux moyennes\nLe test d’égalité des moyennes ne fonctionne que lorsque la variable qualitative Y n’a que deux modalités. On ne peut donc pas l’appliquer pour étudier la relation entre le revenu (Y) et le niveau d’instruction (X) car celui-ci comporte 4 modalités.\nLe programme suivant provoquera une erreur :\n\nt.test(Y~X)\n\nError in t.test.formula(Y ~ X) : grouping factor must have exactly 2 levels"
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#solution-générale-lanalyse-de-variance",
    "href": "STA2B_biv_quali_quanti.html#solution-générale-lanalyse-de-variance",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "Solution générale : l’analyse de variance",
    "text": "Solution générale : l’analyse de variance\n\nY&lt;-don3$rev\nmodele &lt;- lm(Y~X)\nsummary(modele)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5337.6 -1522.6  -304.9  1293.3  5766.4 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4216.89      33.25  126.81   &lt;2e-16 ***\nXprimaire      15.68      41.24    0.38    0.704    \nXsecondaire   552.24      45.46   12.15   &lt;2e-16 ***\nXsupérieur   1570.71      65.75   23.89   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1992 on 15614 degrees of freedom\nMultiple R-squared:  0.04776,   Adjusted R-squared:  0.04758 \nF-statistic:   261 on 3 and 15614 DF,  p-value: &lt; 2.2e-16\n\n\nCette méthode étant plus complexe on attendra le cours sur la modélisation pour la discuter plus en détail."
  },
  {
    "objectID": "STA2B_biv_quali_quanti.html#sexe-du-chef-de-ménage-et-revenu",
    "href": "STA2B_biv_quali_quanti.html#sexe-du-chef-de-ménage-et-revenu",
    "title": "[STA2B] : Statistique bivariée : Y qualitative et X quantitative",
    "section": "Sexe du chef de ménage et revenu",
    "text": "Sexe du chef de ménage et revenu\nVous devez analyser l’existence d’une relation entre les variables revenu moyen annuel du ménage (Y) et sexe du chef de ménage (X).\nQuelle est votre hypothèse H1 ?\nQuelle est votre hypothèse H0 ?\n\n\n\nflouze"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html",
    "href": "MOD1_Regression_lineaire.html",
    "title": "[MOD1] : Régression linéaire",
    "section": "",
    "text": "On se propose dans ce TD de modéliser la relation entre latitude (X) et température moyenne (Y) en Tunisie\nContrairement à la corrélation linéaire qui fait jouer un rôle symétrique au variables X et Y (\\(r_{XY} = r_{YX}\\)), la régression linéaire va introduire une dissymétrie en donnant à chacune des variables X et Y un rôle différent et en introduisant une hypothèse de causalité ou de dépendance :\n\nla variable Y est la variable dépendante, c’est-à-dire celle que l’on veut expliquer ou prédire.\nla variable X est la variable indépendante, c’est-à-dire la variable explicative ou du moins celle qui permet de prédire lesvaleurs de Y.\n\nDans notre exemple, il semble logique de considérer que les températures moyennes (Y) sont une conséquences de la position en latitude (X). Nous cherchons donc un modèle de la forme \\(Y = f(X)\\) dans lequel la fonction \\(f\\) peut prendre différentes formes.\nNous commencerons par le cas le plus simple d’une relation linéaire prenant la forme \\(Y = a.X+b\\) On commencera donc par utiliser un modèle de régression linéaire simple."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#objectif",
    "href": "MOD1_Regression_lineaire.html#objectif",
    "title": "[MOD1] : Régression linéaire",
    "section": "",
    "text": "On se propose dans ce TD de modéliser la relation entre latitude (X) et température moyenne (Y) en Tunisie\nContrairement à la corrélation linéaire qui fait jouer un rôle symétrique au variables X et Y (\\(r_{XY} = r_{YX}\\)), la régression linéaire va introduire une dissymétrie en donnant à chacune des variables X et Y un rôle différent et en introduisant une hypothèse de causalité ou de dépendance :\n\nla variable Y est la variable dépendante, c’est-à-dire celle que l’on veut expliquer ou prédire.\nla variable X est la variable indépendante, c’est-à-dire la variable explicative ou du moins celle qui permet de prédire lesvaleurs de Y.\n\nDans notre exemple, il semble logique de considérer que les températures moyennes (Y) sont une conséquences de la position en latitude (X). Nous cherchons donc un modèle de la forme \\(Y = f(X)\\) dans lequel la fonction \\(f\\) peut prendre différentes formes.\nNous commencerons par le cas le plus simple d’une relation linéaire prenant la forme \\(Y = a.X+b\\) On commencera donc par utiliser un modèle de régression linéaire simple."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#importation-des-données",
    "href": "MOD1_Regression_lineaire.html#importation-des-données",
    "title": "[MOD1] : Régression linéaire",
    "section": "1.1 Importation des données",
    "text": "1.1 Importation des données\n\n\n\nTableau de données\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode\nnom\nreg_code\nreg_nom\nlat\nlon\nalt\ntmin\ntmax\ntmoy\nprec\nvent\nrosee\n\n\n\n\nBJ\nBeja\nNO\nNord-ouest\n36.73333\n9.183333\n159.00\n11.45894\n24.62033\n18.55692\n590.000\n6.436291\n10.881502\n\n\nBZ\nBizerte\nNE\nNord-est\n37.24545\n9.791453\n6.09\n13.36735\n23.96475\n18.73467\n639.000\n13.080826\n13.507263\n\n\nGB\nGabes\nSE\nSud-est\n33.87692\n10.103333\n7.92\n15.62121\n25.44585\n20.64563\n192.000\n11.564158\n12.396331\n\n\nGF\nGafsa\nSO\nSud-ouest\n34.42202\n8.822503\n323.08\n13.73596\n26.88865\n20.42736\n163.000\n12.759514\n7.894512\n\n\nJE\nJendouba\nNO\nNord-ouest\n36.48333\n8.800000\n144.00\n12.03502\n25.75739\n19.17381\n458.000\n8.187385\n11.549468\n\n\nKR\nKairouan\nCO\nCentre-ouest\n35.66667\n10.100000\n68.00\n15.05704\n27.37991\n20.88537\n303.000\n5.826256\n10.894726\n\n\nKS\nKasserine\nCO\nCentre-ouest\n35.16667\n8.833333\n707.00\n11.47720\n24.13852\n18.46683\n340.000\n12.853035\n8.366253\n\n\nKB\nKebili\nSO\nSud-ouest\n33.70000\n8.966667\n46.00\n15.34825\n28.66706\n22.71979\n89.000\n14.061362\n10.373775\n\n\nKF\nLe Kef\nNO\nNord-ouest\n36.13333\n8.700000\n518.00\n10.30506\n23.19958\n17.24170\n528.000\n8.246948\n8.059934\n\n\nMH\nMahdia\nCE\nCentre-est\n35.50000\n11.066667\n12.00\n16.50674\n23.29379\n20.16491\n290.000\n10.854368\n14.624500\n\n\nME\nMedenine\nSE\nSud-est\n33.35000\n10.483333\n117.00\n16.17117\n27.56439\n22.57362\n159.000\n8.743863\n11.404804\n\n\nMS\nMonastir\nCE\nCentre-est\n35.66667\n10.750000\n2.00\n15.64783\n24.26410\n19.76152\n322.062\n13.888661\n13.587094\n\n\nNB\nNabeul\nNE\nNord-est\n36.46667\n10.700000\n78.00\n15.70167\n23.43309\n19.81197\n450.000\n12.190401\n14.033335\n\n\nSF\nSfax\nCE\nCentre-est\n34.71795\n10.690972\n25.90\n14.88812\n25.24082\n20.05744\n221.000\n11.408961\n12.427977\n\n\nSZ\nSidi Bou Zid\nCO\nCentre-ouest\n35.00000\n9.483333\n355.00\n13.03144\n26.20685\n20.25616\n280.000\n8.283933\n9.461638\n\n\nSL\nSiliana\nNO\nNord-ouest\n36.06667\n9.366667\n445.00\n11.36109\n24.50220\n19.02255\n389.000\n9.242761\n9.455365\n\n\nSS\nSousse\nCE\nCentre-est\n35.70000\n10.600000\n5.00\n15.70000\n24.40000\n19.90000\n310.000\n12.500000\n13.600000\n\n\nTA\nTataouine\nSE\nSud-est\n32.91667\n10.450000\n215.00\n15.90320\n27.20100\n21.41218\n110.000\n10.298155\n9.182343\n\n\nTO\nTozeur\nSO\nSud-ouest\n33.93972\n8.110556\n87.47\n16.83189\n28.64269\n22.63410\n97.000\n14.732460\n8.697420\n\n\nTU\nTunis\nNE\nNord-est\n36.85103\n10.227217\n6.70\n14.26899\n24.61744\n19.14238\n453.000\n13.405618\n12.626422\n\n\nZA\nZaghouan\nNE\nNord-est\n36.43333\n10.083333\n156.00\n12.43361\n25.06573\n18.57657\n501.000\n10.331711\n11.907365\n\n\n\n\n\nOn charge ensuite le fichier des métadonnées:\n\n# Importe les métadonnées\nmeta&lt;-read_xlsx(path = \"data/TUN-CLIMAT/tun_climat.xlsx\",\n              sheet = \"meta\")\nkable(meta, caption = \"Tableau de métadonnées\")\n\n\nTableau de métadonnées\n\n\nvariable\ndef\n\n\n\n\ncode\ncode de la station\n\n\nnom\nnom de la station\n\n\nreg_code\ncode de la région\n\n\nreg_nom\nnom de la region\n\n\ngouv_nom\nnom du gouvernorat\n\n\nlat\nLatitude\n\n\nlon\nLongitude\n\n\nalt\nAltitude (en mètres)\n\n\ntmin\nMoyenne de Tmin\n\n\ntmax\nMoyenne de Tmax\n\n\ntmoy\nMoyenne de Tmoy\n\n\nprec\nMoyenne de précipitations totales\n\n\nvent\nMoyenne de vent km/h\n\n\nrose\nMoyenne de point de rosée"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#sélection-des-variables",
    "href": "MOD1_Regression_lineaire.html#sélection-des-variables",
    "title": "[MOD1] : Régression linéaire",
    "section": "1.2 Sélection des variables",
    "text": "1.2 Sélection des variables\nOn décide de garder les deux variables et de les renommer X et Y conformément à nos hypothèses.\n\nX : Latitude en degrés\nY : Température moyenne en degrés Celsius\n\nOn procède donc à l’extraction de ces variables en y ajoutant le nom et le code iso des stations.\n\n# Création des variables X et X\ndon$X&lt;-don$lat\ndon$Y&lt;-don$tmoy\n\n# Sélection des colonnes\ntab&lt;-don[,c(\"code\",\"nom\",\"X\",\"Y\")]"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#astuce-stockage-des-textes-dhabillage",
    "href": "MOD1_Regression_lineaire.html#astuce-stockage-des-textes-dhabillage",
    "title": "[MOD1] : Régression linéaire",
    "section": "1.3 Astuce : stockage des textes d’habillage",
    "text": "1.3 Astuce : stockage des textes d’habillage\nOn prépare un ensemble de textes que l’on pourra utiliser pour l’habillage de nos graphiques. Cela évitera de devoir ensuite les retaper à chaque fois.\nOn décide ici que les textes seront en français :\n\nnomX &lt;- \"Latitude \"\nnomY &lt;- \"Température moyenne en degrés\" \ntitre &lt;- \"Le climat de Tunisie\"\nnote &lt;- \"Source : Salem Dahech, 2024\""
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#calculer-les-paramètres-principaux",
    "href": "MOD1_Regression_lineaire.html#calculer-les-paramètres-principaux",
    "title": "[MOD1] : Régression linéaire",
    "section": "2.1 Calculer les paramètres principaux",
    "text": "2.1 Calculer les paramètres principaux\n\nsummary(tab$Y)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  17.24   19.02   19.90   20.01   20.65   22.72 \n\nsd(tab$Y)\n\n[1] 1.459039\n\n\n\nCommentaire : Les températures moyennes vont de 17.24 à 22.72 degrés avec une moyenne de 20.01 degrés et un écart type de 1.46."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#faire-un-histogramme",
    "href": "MOD1_Regression_lineaire.html#faire-un-histogramme",
    "title": "[MOD1] : Régression linéaire",
    "section": "2.2 Faire un histogramme",
    "text": "2.2 Faire un histogramme\n\nHistogramme rapide\n\n\nhist(tab$Y)\n\n\n\n\n\nHistogramme amélioré\n\n\nhist(tab$Y, \n     xlab=nomY,\n     breaks=quantile(tab$Y, c(0,0.25,0.5,0.75,1)),\n     xlim=c(17,23),\n     main = titre,\n     sub = note,\n     col = \"lightyellow\")\nlines(density(tab$Y),col=\"red\")\nrug(tab$Y)\n\n\n\n\n\nCommentaire : La distribution est globalement symétrique et unimodale malgré un petit mode secondaire"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#tester-la-normalité",
    "href": "MOD1_Regression_lineaire.html#tester-la-normalité",
    "title": "[MOD1] : Régression linéaire",
    "section": "2.3 Tester la normalité",
    "text": "2.3 Tester la normalité\nPour savoir si une distribution est gaussienne (normale) on peut utiliser un test statistique (test de Shapiro-Wilks) à l’aide de la fonction shapiro.test() et tracer un graphique d’écart à la loi gaussienne à l’aide des fonctions qqnorm() et qqline() :\n\n\n\n\n\n\nQu’est-ce qu’un qqplot ?\n\n\n\n\n\nEn statistiques, un Q-Q (quantile-quantile) plot est une méthode graphique pour comparer deux distributions de probabilité en affichant leur quantiles contre quantiles. Un point (x,y) du graphique représente un quantile de la seconde distribution (axe y) contre le même quantile de la première distribution (axe x). Ainsi la droite est une courbe paramétrique dont le paramètre est le nombre d’intervalle des quantiles.\n\n\n\nInterprétation d’un qqplot\n\n\n\nNormal qqplot: La distribution normale est symétrique, donc aucun biais (skew) et la moyenne est égale à la médiane.\nRight skewed qqplot : Right-skew aussi appelé positive skew signifie que la distribution comporte des valeurs exceptionnelles à droite et que la moyenne est supérieure à la médiane.\nLeft skewed qqplot: Left-skew aussi appelé negative skew signifie que la distribution comporte des valeurs exceptionnelles à gauche et que la moyenne est inférieure à la médiane\nLight tailed qqplot: Cela veut dire que comparé à la distribution normale il y a un peu plus de données dans les extrémités que dans le centre de la distribution.\nHeavy tailed qqplot: Cela veut dire que comparé à la distribution normale il y a un beaucoup plus de données dans les extrémités que dans le centre de la distribution.\nBiomodel qqplot: illustre une distribution bimodale comportant deux zones de concentration avec donc deux pics sur l’histogramme.\n\nSource : Zach Bogart & Joyce Robbins, 2019, EDAV-Info\n\n\n\n\n# Graphique \nqqnorm(tab$Y)\nqqline(tab$Y, col = \"red\")\n\n\n\n# test\nshapiro.test(tab$Y)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tab$Y\nW = 0.95026, p-value = 0.3446\n\n\n\nCommentaire : Le graphique montre que la distribution suit approximativement une loi gaussienne, ce qui est confirmé par le test de Shapiro-Wilks (p &gt; 0.344)"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#examiner-la-présence-de-valeurs-exceptionnelles",
    "href": "MOD1_Regression_lineaire.html#examiner-la-présence-de-valeurs-exceptionnelles",
    "title": "[MOD1] : Régression linéaire",
    "section": "2.4 Examiner la présence de valeurs exceptionnelles",
    "text": "2.4 Examiner la présence de valeurs exceptionnelles\nLa solution la plus courante est d’utiliser une boxplot :\n\nboxplot(tab$X, \n        horizontal = T,\n        xlab = nomX,\n        main = titre,\n        sub = note)\n\n\n\n\n\nCommentaire : La boxplot ne montre la présence d’aucune valeur exceptionnelle."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#visualiser-la-relation-entre-x-et-y",
    "href": "MOD1_Regression_lineaire.html#visualiser-la-relation-entre-x-et-y",
    "title": "[MOD1] : Régression linéaire",
    "section": "3.1 Visualiser la relation entre X et Y",
    "text": "3.1 Visualiser la relation entre X et Y\n\nGraphique rapide\n\n\nplot(tab$X,tab$Y)\n\n\n\n\n\nGraphique amélioré\n\n\nplot(don$X,don$Y,\n     main = titre,   # titre\n     cex.main = 1,      # police du titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = nomX,    # nom de l'axe X\n     xlim = c(32.7,37.5),   # intervalle de l'axe X\n     ylab = nomY,    # nom de l'axe Y\n    ylim = c(17,24),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n\n# Ajout d'une ligne horizontale  correspondant à la moyenne de Y\nabline(h=mean(don$Y),col=\"red\",lwd = 1, lty = 2)\n# Ajout d'une ligne verticlae  correspondant à la moyenne de X\nabline(v=mean(don$X),col=\"red\",lwd = 1, lty = 2)\n\ntext(x = don$X,\n     y = don$Y,\n     label = don$code,\n     cex = 0.7,\n     pos=3,\n     col = \"blue\")\n\n\n\n\n\nCommentaire : : La relation semble négative et linéaire"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#tester-la-significativité-de-la-relation-entre-x-et-y",
    "href": "MOD1_Regression_lineaire.html#tester-la-significativité-de-la-relation-entre-x-et-y",
    "title": "[MOD1] : Régression linéaire",
    "section": "3.2 Tester la significativité de la relation entre X et Y",
    "text": "3.2 Tester la significativité de la relation entre X et Y\n\nCoefficient de Pearson\n\ncor.test(tab$X,tab$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  tab$X and tab$Y\nt = -5.7451, df = 19, p-value = 1.549e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9140080 -0.5562694\nsample estimates:\n       cor \n-0.7966527 \n\ncor(tab$X,tab$Y)**2\n\n[1] 0.6346554\n\n\n\nCommentaire : Selon le test du coefficient de Pearson, la relation est très significative (p &lt; 0.001) et le pouvoir explicatif de X par rapport à Y mesuré par la coefficient de détermination (\\(r_{XY}^2\\)) sera élevé (63%).\n\n\n\nCoefficien de Spearman\n\ncor.test(tab$X,tab$Y, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  tab$X and tab$Y\nS = 2738, p-value = 4.83e-05\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.7779221 \n\n\n\nCommentaire : Le coefficient de corrélation de Spearman (-0.77) est sensiblement égal à celui celui de Pearson (+0.80). Ceci est en général bon signe et confirme que la distribution est sans doute linéaire."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#calculer-léquation-de-la-droite-y-axb",
    "href": "MOD1_Regression_lineaire.html#calculer-léquation-de-la-droite-y-axb",
    "title": "[MOD1] : Régression linéaire",
    "section": "4.1 Calculer l’équation de la droite Y = aX+B",
    "text": "4.1 Calculer l’équation de la droite Y = aX+B\n\nmodreglin &lt;- lm(tab$Y~tab$X)\nsummary(modreglin)\n\n\nCall:\nlm(formula = tab$Y ~ tab$X)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.02273 -0.43088  0.06247  0.54638  1.32667 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.9170     5.7316   9.232 1.87e-08 ***\ntab$X        -0.9313     0.1621  -5.745 1.55e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9048 on 19 degrees of freedom\nMultiple R-squared:  0.6347,    Adjusted R-squared:  0.6154 \nF-statistic: 33.01 on 1 and 19 DF,  p-value: 1.549e-05\n\n\n\nCommentaire : L’équation de la droite est donc \\(Y =-0.931\\times X + 52.92\\). Le coefficient de pente de la droite indique que les températures diminuent de 0.93 degrés chaque fois que la latitude augmente de 1. Comme 1 degré vaut environ 100 km, cela signifie que la température baisse du sud vers le nord d’environ 0.01 degré par km."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#visualiser-la-droite",
    "href": "MOD1_Regression_lineaire.html#visualiser-la-droite",
    "title": "[MOD1] : Régression linéaire",
    "section": "4.2 Visualiser la droite",
    "text": "4.2 Visualiser la droite\n\nplot(don$X,don$Y,\n     main = titre,   # titre\n     cex.main = 1,      # police du titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = nomX,    # nom de l'axe X\n     xlim = c(32.7,37.5),   # intervalle de l'axe X\n     ylab = nomY,    # nom de l'axe Y\n    ylim = c(17,24),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n\n# Ajout d'une ligne horizontale  correspondant à la moyenne de Y\nabline(h=mean(don$Y),col=\"red\",lwd = 1, lty = 2)\n# Ajout d'une ligne verticlae  correspondant à la moyenne de X\nabline(v=mean(don$X),col=\"red\",lwd = 1, lty = 2)\n\ntext(x = don$X,\n     y = don$Y,\n     label = don$code,\n     cex = 0.7,\n     pos=3,\n     col = \"blue\")\n\nabline(modreglin, col =\"black\", lwd =2)\n\n\n\n\n\nCommentaire: La droite s’ajuste assez bien au nuage de points mais certains points en sont assez éloignés."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#calculer-les-valeurs-estimées-et-les-résidus",
    "href": "MOD1_Regression_lineaire.html#calculer-les-valeurs-estimées-et-les-résidus",
    "title": "[MOD1] : Régression linéaire",
    "section": "4.3 Calculer les valeurs estimées et les résidus",
    "text": "4.3 Calculer les valeurs estimées et les résidus\n\n# Extraction des valeurs estimées et résiduelles\ntab$Yest &lt;- modreglin$fitted.values\ntab$Yres &lt;- modreglin$residuals\n\n# Affichage du tableau trié\nkable(tab[order(tab$Yres),])\n\n\n\n\ncode\nnom\nX\nY\nYest\nYres\n\n\n\n\nKF\nLe Kef\n36.13333\n17.24170\n19.26442\n-2.0227251\n\n\nKS\nKasserine\n35.16667\n18.46683\n20.16472\n-1.6978858\n\n\nTA\nTataouine\n32.91667\n21.41218\n22.26024\n-0.8480634\n\n\nGB\nGabes\n33.87692\n20.64563\n21.36592\n-0.7202877\n\n\nSF\nSfax\n34.71795\n20.05744\n20.58263\n-0.5251847\n\n\nGF\nGafsa\n34.42202\n20.42736\n20.85824\n-0.4308751\n\n\nZA\nZaghouan\n36.43333\n18.57657\n18.98502\n-0.4084519\n\n\nSL\nSiliana\n36.06667\n19.02255\n19.32651\n-0.3039556\n\n\nBJ\nBeja\n36.73333\n18.55692\n18.70561\n-0.1486901\n\n\nSZ\nSidi Bou Zid\n35.00000\n20.25616\n20.31994\n-0.0637850\n\n\nMS\nMonastir\n35.66667\n19.76152\n19.69905\n0.0624704\n\n\nSS\nSousse\n35.70000\n19.90000\n19.66800\n0.2319971\n\n\nJE\nJendouba\n36.48333\n19.17381\n18.93845\n0.2353609\n\n\nMH\nMahdia\n35.50000\n20.16491\n19.85427\n0.3106395\n\n\nBZ\nBizerte\n37.24545\n18.73467\n18.22866\n0.5060068\n\n\nTU\nTunis\n36.85103\n19.14238\n18.59600\n0.5463832\n\n\nME\nMedenine\n33.35000\n22.57362\n21.85666\n0.7169607\n\n\nNB\nNabeul\n36.46667\n19.81197\n18.95397\n0.8579988\n\n\nKR\nKairouan\n35.66667\n20.88537\n19.69905\n1.1863196\n\n\nKB\nKebili\n33.70000\n22.71979\n21.53069\n1.1890956\n\n\nTO\nTozeur\n33.93972\n22.63410\n21.30743\n1.3266717\n\n\n\n\n\nCommentaire : Le tableau permet de repérer les stations qui s’éloignent le plus de la droite en raison d’une surestimation ou d’une sous-estimation de leurs température par la latitude.\n\nLes résidus négatifs correspondent à des stations dont la température est moins chaude que ce que laisserait prévoir leur latitude. C’est par exemple le cas de la station d’El Kef dont la latitude (36.13) laissait prévoir une températude de 19.2 degrés mais qui en pratique a une température de 17.2° soit un résidu de 2 degrés de moins que prévu.\nLes résidus positifs correspondent à des stations dont la température est plus chaude que ce que laisserait prévoir leur latitude. C’est par exemple le cas de la station de Tozeur dont la latitude (33.94) laissait prévoir une températude de 21.3 degrés mais qui en pratique a une température de 22.6 degrés soit un résidu de 1.3 degrés de plus que prévu."
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#sauvegarder-les-résultats-du-modèle",
    "href": "MOD1_Regression_lineaire.html#sauvegarder-les-résultats-du-modèle",
    "title": "[MOD1] : Régression linéaire",
    "section": "4.4 Sauvegarder les résultats du modèle",
    "text": "4.4 Sauvegarder les résultats du modèle\nOn peut si on le souhaite sauvegarder les résultats au format .csv\n\nwrite.table(x = tab,\n            file = \"result.csv\",\n            row.names = FALSE)"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#autocorrélation-des-résidus",
    "href": "MOD1_Regression_lineaire.html#autocorrélation-des-résidus",
    "title": "[MOD1] : Régression linéaire",
    "section": "5.1 Autocorrélation des résidus",
    "text": "5.1 Autocorrélation des résidus\n\nlibrary(car)\nplot(modreglin,\n     which = 1,\n     labels.id = tab$nom,\n     col=\"red\")\n\n\n\ndurbinWatsonTest(modreglin)\n\n lag Autocorrelation D-W Statistic p-value\n   1      -0.5133805      3.014614   0.008\n Alternative hypothesis: rho != 0\n\n\n\nCommentaire : le graphique permet de voir que les résidus sont dans l’ensemble indépendants des valeurs estimées de Y, ce qui signifie que les points sont bien répartis autour de la droite On peut s’en assurer à l’aide du test de Durbin Watson qui pose l’hypothèse H0 : Il existe une autocorrélation des résidus. Cette hypothèse peut être rejetée (p &lt; 0.05) donc il n’existe pas d’autocorrélation susceptible de fausser les résultats"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#normalité-des-résidus",
    "href": "MOD1_Regression_lineaire.html#normalité-des-résidus",
    "title": "[MOD1] : Régression linéaire",
    "section": "5.2 Normalité des résidus",
    "text": "5.2 Normalité des résidus\n\nplot(modreglin,\n     which = 2,\n     labels.id = tab$nom,\n     col=\"red\")\n\n\n\nshapiro.test(tab$Yres)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tab$Yres\nW = 0.95959, p-value = 0.5078\n\n\n\nCommentaire : La normalité de la distribution des résidus est également une condition importante de validité du modèle de régression linéaire puisqu’elle permet de définir un intervalle de confiance des estimations en se servant de l’écart-type de ces résidus (e.g. + ou - 2 écarts-type pour un intervalle de confiance à 95%). Au vu du diagramme QQ plot on voit que la condition de normalité des résidus semble bien vérifiée, ce que confirme le test de Shapiro (p &gt; 0.05)"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#homogénéité-des-résidus",
    "href": "MOD1_Regression_lineaire.html#homogénéité-des-résidus",
    "title": "[MOD1] : Régression linéaire",
    "section": "5.3 Homogénéité des résidus",
    "text": "5.3 Homogénéité des résidus\n\nplot(modreglin,\n     which = 3,\n     labels.id = tab$nom,\n     col=\"red\")\n\n\n\nncvTest(modreglin)\n\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 0.3034993, Df = 1, p = 0.5817\n\n\n\nCommentaire : En liaison avec ce qui précède, l’analyse de l’homogénéité des résidus permet de vérifier si la variance des résidus est constante et donc si l’intervalle de confiance sera le même pour l’ensemble des valeurs estimées. Ici, c’est à peu près le cas même si les résidus varient un peu en fonction de Y. On peut vérifier l’homogénéité en appliquant le test de Breush-Pagan qui examine l’hypothèse “H0 : la distribution des résidus est homogène”. Dans notre exemple H0 ne peut pas être rejetée (p &lt; 0.001) ce qui signifie que l’hypothèse d’homogénéité des résdus est vérifiée"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#absence-de-valeurs-exceptionnellement-influentes",
    "href": "MOD1_Regression_lineaire.html#absence-de-valeurs-exceptionnellement-influentes",
    "title": "[MOD1] : Régression linéaire",
    "section": "5.4 Absence de valeurs exceptionnellement influentes",
    "text": "5.4 Absence de valeurs exceptionnellement influentes\n\nplot(modreglin,\n     which = 4,\n     labels.id = tab$nom,\n     col=\"red\")\n\n\n\noutlierTest(modreglin, labels = tab$nom)\n\nNo Studentized residuals with Bonferroni p &lt; 0.05\nLargest |rstudent|:\n        rstudent unadjusted p-value Bonferroni p\nLe Kef -2.660486           0.015932      0.33457\n\n\n\nCommentaire : Le dernier test consiste à vérifier si la relation observée est bien le résultat d’un ensemble d’observations indépendantes et non pas l’effet de la présence d’une ou deux valeurs exceptionnelles. Plusieurs tests sont ici possibles qui visent au même objectif : déterminer à quel point le retrait d’unevaleur unique modifie le résultat de l’analyse, c’est à dire le coefficient de détermination \\(r_{XY}^2\\) et les paramètres \\(a\\) et \\(b\\) de l’équation \\(Y=aX+b\\). Le graphique proposé par R utilise la distance de Cook pour mettre en valeur l’influence potentielle des valeurs exceptionnelles et on y retrouve les trois stations de Kebeli, El Kef et Tataouine. On peut arriver à un résultat similaire en utilisant le test de Bonferroni qui signale le caractère influent de la station d’El Kef (p &lt; 0.05)"
  },
  {
    "objectID": "MOD1_Regression_lineaire.html#tous-les-tests-dun-coup",
    "href": "MOD1_Regression_lineaire.html#tous-les-tests-dun-coup",
    "title": "[MOD1] : Régression linéaire",
    "section": "5.5 Tous les tests d’un coup",
    "text": "5.5 Tous les tests d’un coup\nUne fois que l’on a bien compris les tests précédents, on peut afficher les quatre graphiques correspondant en une seule commande :\n\npar(mfrow=c(2,2))\nplot(modreglin,\n     which = c(1,2,3,4),\n     labels.id = tab$nom,\n     col=\"red\")"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html",
    "href": "MOD2_Regression_non_lineaire.html",
    "title": "[MOD2] : Régression non linéaire",
    "section": "",
    "text": "A propos de ce document\n\n\n\nCe support de cours a été créé par Claude Grasland et Nadège Gbetototon Djossou pour l’école d’été CIST 2023. Il a été ici légèrement modifié et adapté par C. Grasland et M.Madelin pour l’école d’été GEOUNIV’R 2024 de Tunisie.\nDJOSSOU Gbetoton Nadège, GRASLAND Claude, 2023, «MOD1 : Modélisation d’une variable quantitative », in. EECIST 2022-2023, Méthodes et outils des sciences territoriales : une perspective Nord-Sud, Sud-Nord et Sud-Sud,https://ee2023.netlify.app/modules/mod1_quanti"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#objectif",
    "href": "MOD2_Regression_non_lineaire.html#objectif",
    "title": "[MOD2] : Régression non linéaire",
    "section": "Objectif",
    "text": "Objectif\nOn se propose dans ce TD de modéliser la relation entre PIB par habiatnt (X) et émission de CO2 des pays africains (Y) en 2018.\nContrairement à la corrélation linéaire qui fait jouer un rôle symétrique au variables X et Y (\\(r_{XY} = r_{YX}\\)), la régression linéaire va introduire une dissymétrie en donnant à chacune des variables X et Y un rôle différent et en introduisant une hypothèse de causalité ou de dépendance :\n\nla variable Y est la variable dépendante, c’est-à-dire celle que l’on veut expliquer ou prédire.\nla variable X est la variable indépendante, c’est-à-dire la variable explicative ou du moins celle qui permet de prédire les valeurs de Y.\n\nDans notre exemple, il semble logique de considérer que les émissions de CO2 par habitant (Y) sont une conséquences du développement économique mesuré à l’aide du PIB par habitant (X). Nous cherchons donc un modèle de la forme \\(Y = f(X)\\) dans lequel la fonction \\(f\\) peut prendre différentes formes.\nNous commencerons par le cas le plus simple d’une relation linéaire prenant la forme \\(Y = a.X+b\\) On commencera donc par utiliser un modèle de régression linéaire simple en soulignant les multiples violation des hypothèses qu’il entraîne. Puis on proposera deux solutions alternatives, l’une en retirant les valeurs exceptionnelles, l’autre en transformant les variables X et Y de façon logarithmique."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#importation-des-données",
    "href": "MOD2_Regression_non_lineaire.html#importation-des-données",
    "title": "[MOD2] : Régression non linéaire",
    "section": "1.1 Importation des données",
    "text": "1.1 Importation des données\nOn utilise un tableau de données extrait du Human Development Report 2020. Ce tableau a déjà été utilisé dans le cours de statistique multivariée auquel on pourra se reporter pour plus de détail\n\ndon&lt;-read.csv2(\"data/DEV-AFRIC-2018/data/afrika_don.csv\")\nhead(don)\n\n  iso3                 name                  nom       POP        PIB    IDH\n1  AGO               Angola               Angola 31.317543  6793.7085 0.5815\n2  BDI              Burundi              Burundi 11.352978   756.5941 0.4320\n3  BEN                Benin                Bénin 11.643093  3224.0433 0.5430\n4  BFA         Burkina Faso         Burkina Faso 20.036424  2160.5895 0.4475\n5  BWA             Botswana             Botswana  2.278885 17700.3152 0.7325\n6  CAF Central African Rep. Rep. Centrafricaine   4.705777   938.9888 0.3960\n     ADOFEC     CO2HAB  EMPAGR  EMPSER   INTERN  ESPVIE AGEMED   TELMOB\n1 152.63525 1.12098146 50.4490 41.3865 14.33910 60.9660 16.677  43.1305\n2  56.22750 0.04667763 92.0170  6.4980  2.66075 61.4135 17.320  56.5347\n3  87.37963 0.62247911 38.9125 42.1465 20.00000 61.6200 18.781  82.3843\n4 105.71388 0.19739801 25.5640 40.8700 16.00000 61.3770 17.551  97.9123\n5  46.32212 2.95736420 20.8570 61.0040 47.00000 69.4325 24.044 150.0060\n6 130.24787 0.06508274 77.4450 17.1505  4.33925 53.0425 17.611  27.6743\n    MORINF TXMIGR DVIEUX TUBERC URBANI  DJEUNE          SUBREG LOCKED COLFRA\n1 51.58504  0.211 4.3225    355  65.85 91.4625   Middle Africa      0      0\n2 40.99260  0.181 4.3610    111  13.20 86.9555  Eastern Africa      1      0\n3 60.53574 -0.176 5.9895     56  47.60 77.7865  Western Africa      0      1\n4 49.00709 -1.282 4.5605     48  29.70 84.9065  Western Africa      1      1\n5 29.98541  1.341 6.9540    275  69.80 54.9450 Southern Africa      1      0\n6 84.46370 -8.581 5.3140    540  41.60 83.1095   Middle Africa      1      1\n  COLGBR LANGFR LANGEN\n1      0      0      0\n2      0      1      0\n3      0      1      0\n4      0      1      0\n5      1      0      1\n6      0      1      0"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#sélection-des-variables",
    "href": "MOD2_Regression_non_lineaire.html#sélection-des-variables",
    "title": "[MOD2] : Régression non linéaire",
    "section": "1.2 Sélection des variables",
    "text": "1.2 Sélection des variables\nOn décide de garder les deux variables et de les renommer X et Y conformément à nos hypothèses.\n\nX : PIB en $/habitant\nY : CO2 en tonnes/habitant\n\nOn procède donc à l’extraction de ces variables en y ajoutant le nom et le code iso des pays africains. On élimine les pays ayant des valeurs manquantes pour X ou Y à l’aide de l’instruction na.omit()\n\n# Création des variables X et X\ndon$X&lt;-don$PIB\ndon$Y&lt;-don$CO2HAB\n\n# Sélection des colonnes\ntab&lt;-don[,c(\"iso3\",\"name\",\"X\",\"Y\")]\n\n# Elimination des lignes comportant des valeurs manquantes\ntab&lt;-na.omit(tab)"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#astuce-stockage-des-textes-dhabillage",
    "href": "MOD2_Regression_non_lineaire.html#astuce-stockage-des-textes-dhabillage",
    "title": "[MOD2] : Régression non linéaire",
    "section": "1.3 Astuce : stockage des textes d’habillage",
    "text": "1.3 Astuce : stockage des textes d’habillage\nOn prépare un ensemble de textes que l’on pourra utiliser pour l’habillage de nos graphiques. Cela évitera de devoir ensuite les retaper à chaque fois.\nOn décide ici que les textes seront en français :\n\nnomX &lt;- \"PIB ($/hab)\"\nnomY &lt;- \"Pollution (t. de CO2/hab).\" \ntitre &lt;- \"Les pays Africains en 2018\"\nnote &lt;- \"Source : Rapport sur le développement humain 2020\"\n\nMais vous pouvez par la suite changer les valeurs pour obtenir des graphiques en arabe. Ce qui devrait ressembler à ceci selon le traducteur deepl (???) :\n\nnomX &lt;- \"الناتج المحلي الإجمالي (بالدولار/الفرد)\"\nnomY &lt;- \"التلوث (بالأطنان من ثاني أكسيد الكربون/الفرد)\" \ntitre &lt;- \" البلدان الأفريقية في عام 2018\"\nnote &lt;- \" المصدر: تقرير التنمية البشرية 2020\""
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#la-distribution-de-x",
    "href": "MOD2_Regression_non_lineaire.html#la-distribution-de-x",
    "title": "[MOD2] : Régression non linéaire",
    "section": "2.1 La distribution de X",
    "text": "2.1 La distribution de X\n\nCalculer les paramètres principaux et commentez les\n\nsummary(tab$X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  756.6  2014.9  3289.4  5168.8  6437.0 19458.9 \n\n\n\nCommentaire : Le PIB en $/habitant des pays africians varie entre 756 et 19459. Il est en moyenne de 5169. La moitié des pays ont un taux compris entre Q1 (2015) et Q3 (6437)\n\n\n\nFaire un histogramme\n\nHistogramme rapide\n\n\nhist(tab$X)\n\n\n\n\n\nHistogramme amélioré\n\n\nhist(tab$X, \n     xlab=nomX,\n     breaks=quantile(tab$X, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)),\n     main = titre,\n     sub = note,\n     col = \"lightyellow\")\nlines(density(tab$X),col=\"red\")\n\n\n\n\n\nCommentaire : La distribution semble unimodale mais fortement asymétrique à gauche.\n\n\n\nTester la normalité\nPour savoir si une distribution est gaussienne (normale) on peut utiliser un test statistique (test de Shapiro-Wilks) à l’aide de la fonction shapiro.test() et tracer un graphique d’écart à la loi gaussienne à l’aide des fonctions qqnorm() et qqline() :\n\n\n\n\n\n\nQu’est-ce qu’un qqplot ?\n\n\n\n\n\nEn statistiques, un Q-Q (quantile-quantile) plot est une méthode graphique pour comparer deux distributions de probabilité en affichant leur quantiles contre quantiles. Un point (x,y) du graphique représente un quantile de la seconde distribution (axe y) contre le même quantile de la première distribution (axe x). Ainsi la droite est une courbe paramétrique dont le paramètre est le nombre d’intervalle des quantiles.\n\n\n\nInterprétation d’un qqplot\n\n\n\nNormal qqplot: La distribution normale est symétrique, donc aucun biais (skew) et la moyenne est égale à la médiane.\nRight skewed qqplot : Right-skew aussi appelé positive skew signifie que la distribution comporte des valeurs exceptionnelles à droite et que la moyenne est supérieure à la médiane.\nLeft skewed qqplot: Left-skew aussi appelé negative skew signifie que la distribution comporte des valeurs exceptionnelles à gauche et que la moyenne est inférieure à la médiane\nLight tailed qqplot: Cela veut dire que comparé à la distribution normale il y a un peu plus de données dans les extrémités que dans le centre de la distribution.\nHeavy tailed qqplot: Cela veut dire que comparé à la distribution normale il y a un beaucoup plus de données dans les extrémités que dans le centre de la distribution.\nBiomodel qqplot: illustre une distribution bimodale comportant deux zones de concentration avec donc deux pics sur l’histogramme.\n\nSource : Zach Bogart & Joyce Robbins, 2019, EDAV-Info\n\n\n\n\n# Graphique \nqqnorm(tab$X)\nqqline(tab$X, col = \"red\")\n\n\n\n# test\nshapiro.test(tab$X)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tab$X\nW = 0.796, p-value = 1.584e-06\n\n\n\nCommentaire : Le graphique montre que la distribution ne suit pas une loi gaussienne, ce qui est confirmé par le test de Shapiro-Wilks (p &lt; 0.001)\n\n\n\nExaminer la présence de valeurs exceptionnelles\nLa solution la plus courante est d’utiliser une boxplot :\n\nboxplot(tab$X, \n        horizontal = T,\n        xlab = nomX,\n        main = titre,\n        sub = note)\n\n\n\n\n\nCommentaire : La boxplot montre la présence d’au moins quatre valeurs exceptionnelles situées à plus de 1.5 fois (Q3-Q1) au dessus de Q3. On peut les identifier et les afficher dans un tableau.\n\n\nQ1 &lt;- quantile(tab$X,0.25)\nQ3 &lt;- quantile(tab$X,0.75)\nout_max &lt;- Q3 + 1.5*(Q3-Q1)\ntab_out &lt;- tab[tab$X&gt;out_max,]\ntab_out\n\n   iso3       name        X        Y\n5   BWA   Botswana 17700.32 2.957364\n16  GAB      Gabon 14806.59 2.528365\n21  GNQ Eq. Guinea 19458.92 4.344926\n24  LBY      Libya 15096.08 8.087927\n\n\nOn retrouve sans suprise dans la liste des pays à richesse exceptionnelle trois pays producteurs de pétrole (Gabon, Guinée équatoriale, Libye) et un pays ayant des mines de diamants (Bostwana)."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#la-distribution-de-y",
    "href": "MOD2_Regression_non_lineaire.html#la-distribution-de-y",
    "title": "[MOD2] : Régression non linéaire",
    "section": "2.2 La distribution de Y",
    "text": "2.2 La distribution de Y\n\nCalculer les paramètres principaux\n\nsummary(tab$Y)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.02423 0.18254 0.39648 1.14048 1.10447 8.09036 \n\n\n\nCommentaire : En 2018 les émissions de CO2 des pays d’Afrique varient entre 0.02 t/hab. et 8.1 t./hab. La moyenne est de 1.14 t.hab. La moitié des pays se situent entre 0.18 t./hab (Q1) et 1.10 t./hab (Q3). L’écart entre la moyenne et la médiane suggère une distribution dissymétrique à gauche. Ce que l’on va vérifier avec l’histogramme.\n\n\n\nFaire un histogramme\n\nHistogramme rapide\n\n\nhist(tab$Y)\n\n\n\n\n\nHistogramme amélioré\n\n\nhist(tab$Y, \n     xlab=nomY,\n     breaks=quantile(tab$Y, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)),\n     main = titre,\n     sub = note,\n     col=\"lightyellow\")\nlines(density(tab$Y),col=\"red\")\n\n\n\n\n\nCommentaire : La distribution de Y est unimodale mais très fortement dissymétrique à gauche. Beaucoup plus que dans le cas de la variable X analysée précédemment.\n\n\n\nTester la normalité\n\n# Graphique \nqqnorm(tab$Y)\nqqline(tab$Y, col = \"red\")\n\n\n\n# test\nshapiro.test(tab$Y)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tab$Y\nW = 0.6079, p-value = 7.414e-10\n\n\n\nCommentaire : Le graphique montre que la distribution ne suit absolument pas une loi gaussienne, ce qui est confirmé par le test de Shapiro-Wilks (p &lt; 0.001). Le graphique nous indique que la distribution comporte des valeurs exceptionnelles à droite ce qui la rend non-gaussienne.\n\n\n\nExaminer la présence de valeurs exceptionnelles\n\nboxplot(tab$Y, \n        horizontal = T,\n        xlab = nomY,\n        main = titre,\n        sub = note)\n\n\n\n\n\nCommentaire : La boxplot montre la présence de plusieurs valeurs exceptionnelles situées à plus de 1.5*(Q3-Q1) de Q3. On peut les identifier en utilisant le même programme que pour Y.\n\n\nQ1 &lt;- quantile(tab$Y,0.25)\nQ3 &lt;- quantile(tab$Y,0.75)\nout_max &lt;- Q3 + 1.5*(Q3-Q1)\ntab_out &lt;- tab[tab$Y&gt;out_max,]\ntab_out\n\n   iso3         name        X        Y\n5   BWA     Botswana 17700.32 2.957364\n12  DZA      Algeria 11414.60 3.687691\n16  GAB        Gabon 14806.59 2.528365\n21  GNQ   Eq. Guinea 19458.92 4.344926\n24  LBY        Libya 15096.08 8.087927\n44  TUN      Tunisia 10759.68 2.730311\n47  ZAF South Africa 12556.28 8.090357\n\n\nOn retrouve les pays excpetionnels pour X ainsi que d’autres pays producteurs d’énergie (Algérie) ou de charbon (Afrique du Sud) et la Tunisie."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#visualiser-la-relation-entre-x-et-y",
    "href": "MOD2_Regression_non_lineaire.html#visualiser-la-relation-entre-x-et-y",
    "title": "[MOD2] : Régression non linéaire",
    "section": "3.1 Visualiser la relation entre X et Y",
    "text": "3.1 Visualiser la relation entre X et Y\n\nGraphique rapide\n\n\nplot(tab$X,tab$Y)\n\n\n\n\n\nGraphique amélioré\n\n\nplot(tab$X,tab$Y,\n     cex = 0.6,\n     pch = 19,\n     col = \"red\",\n     xlab = nomX,\n     ylab = nomY,\n     main = titre,\n     sub = note)\n\ntext(tab$X, tab$Y, tab$iso3,\n     cex = 0.6,\n     col = \"blue\",\n     pos = 1)\n\n\n\n\n\nCommentaire : : La relation est clairement positive ce quisignifie que plus le PIB/habitant augmente, plus les émissions de CO2 par habitant augmente. Plus un pays est riche, plus il pollue ! Il n’est toutefois pas évident que la relation soit linéaire car deux pays (Afrique du Sud et Libye) s’écartent clairement de la tendance générale et suggèrent une relation de croissance non linéaire type puissance ou exponentielle."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#tester-la-significativité-de-la-relation-entre-x-et-y",
    "href": "MOD2_Regression_non_lineaire.html#tester-la-significativité-de-la-relation-entre-x-et-y",
    "title": "[MOD2] : Régression non linéaire",
    "section": "3.2 Tester la significativité de la relation entre X et Y",
    "text": "3.2 Tester la significativité de la relation entre X et Y\n\nCoefficient de Pearson\n\ncor.test(tab$X,tab$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  tab$X and tab$Y\nt = 8.9738, df = 44, p-value = 1.688e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6703491 0.8873157\nsample estimates:\n      cor \n0.8041573 \n\ncor(tab$X,tab$Y)**2\n\n[1] 0.6466689\n\n\n\nCommentaire : Selon le test du coefficient de Pearson, la relation est très significative (p &lt; 0.001) et le pouvoir explicatif de X par rapport à Y mesuré par la coefficient de détermination (\\(r_{XY}^2\\)) sera élevé (65%).\n\n\n\nCoefficien de Spearman\n\ncor.test(tab$X,tab$Y, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  tab$X and tab$Y\nS = 1654, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8979957 \n\n\n\nCommentaire : Le coefficient de corrélation de Spearman (+0.90) est sensiblement plus élevée que celui de Pearson (+0.80). Ceci constitue un signal d’alerte et suggère (i) soit la présence de valeurs exceptionnelles, (ii) soit l’existenced’une relation non linéaire."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#calculer-léquation-de-la-droite-y-axb",
    "href": "MOD2_Regression_non_lineaire.html#calculer-léquation-de-la-droite-y-axb",
    "title": "[MOD2] : Régression non linéaire",
    "section": "4.1 Calculer l’équation de la droite Y = aX+B",
    "text": "4.1 Calculer l’équation de la droite Y = aX+B\n\nmodreglin &lt;- lm(tab$Y~tab$X)\nsummary(modreglin)\n\n\nCall:\nlm(formula = tab$Y ~ tab$X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9949 -0.5007 -0.0551  0.1633  4.7028 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.4317539  0.2375862  -1.817    0.076 .  \ntab$X        0.0003042  0.0000339   8.974 1.69e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.088 on 44 degrees of freedom\nMultiple R-squared:  0.6467,    Adjusted R-squared:  0.6386 \nF-statistic: 80.53 on 1 and 44 DF,  p-value: 1.688e-11\n\n\n\nCommentaire : L’équation de la droite est donc **Y = 0.0003*X - 0.432**. Le coefficient de pente de la droite indique que les émissions de CO2 augmentent de 0.0003 tonnes chaque fois que le PIB par habitant augmente de 1 dollar. Ou si l’on préfère, queles émissions de CO2 augmentent de 0.3 tonnes chaque fois que le PIB/hab. augmente de 1000 dollars. La constante (Intercept) indique la valeur qui correspondrait à un pays totalement pauvre et elle serait négative ce qui est évidemment absurde. Le modèle linéaire peut aboutir à des absurdités …"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#visualiser-la-droite",
    "href": "MOD2_Regression_non_lineaire.html#visualiser-la-droite",
    "title": "[MOD2] : Régression non linéaire",
    "section": "4.2 Visualiser la droite",
    "text": "4.2 Visualiser la droite\n\nplot(tab$X,tab$Y,\n     cex = 0.6,\n     pch = 19,\n     col = \"red\",\n     xlab = nomX,\n     ylab = nomY,\n     main = titre,\n     sub = note)\ntext(tab$X, tab$Y, tab$iso3,\n     cex = 0.6,\n     col = \"blue\",\n     pos = 1)\nabline(modreglin, col =\"black\", lwd =2)\n\n\n\n\n\nCommentaire: La droite s’ajuste plus ou moins au nuage de points mais on remarque que les résidus sont mal répartis autour de celle-ci (autocorrélation) et que les points s’éloignent de plus en plus de la droite au fur et à mesure que X augmente ce qui signifie que la variance n’est pas constante (hétéroscédasticité). Même s’il semble avoir un fort pouvoir explicatif, le modèle semble donc souffrir de défauts importants que l’on discutera dans la partie finale."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#calculer-les-valeurs-estimées-et-les-résidus",
    "href": "MOD2_Regression_non_lineaire.html#calculer-les-valeurs-estimées-et-les-résidus",
    "title": "[MOD2] : Régression non linéaire",
    "section": "4.3 Calculer les valeurs estimées et les résidus",
    "text": "4.3 Calculer les valeurs estimées et les résidus\n\n# Extraction des valeurs estimées et résiduelles\ntab$Yest &lt;- modreglin$fitted.values\ntab$Yres &lt;- modreglin$residuals\n\n# Affichage du tableau trié\ntab[order(tab$Yres),]\n\n   iso3                 name          X          Y        Yest        Yres\n5   BWA             Botswana 17700.3152 2.95736420  4.95231246 -1.99494826\n16  GAB                Gabon 14806.5905 2.52836465  4.07210181 -1.54373716\n41  SWZ            Swaziland  8647.0887 1.05493272  2.19850997 -1.14357725\n21  GNQ           Eq. Guinea 19458.9245 4.34492637  5.48724470 -1.14231833\n32  NAM              Namibia  9784.5769 1.74504687  2.54451013 -0.79946325\n7   CIV        Côte d'Ivoire  5133.5905 0.33469716  1.12977713 -0.79507998\n13  EGY                Egypt 11564.7950 2.42640693  3.08601530 -0.65960837\n17  GHA                Ghana  5303.5336 0.61471889  1.18147028 -0.56675138\n11  DJI             Djibouti  5366.7107 0.67179534  1.20068744 -0.52889210\n30  MRT           Mauritania  5119.7260 0.60443125  1.12555986 -0.52112861\n1   AGO               Angola  6793.7085 1.12098146  1.63475038 -0.51376892\n22  KEN                Kenya  4266.8368 0.35970573  0.86612877 -0.50642305\n34  NGA              Nigeria  5145.2871 0.64987572  1.13333499 -0.48345928\n8   CMR             Cameroon  3628.1177 0.32269646  0.67184374 -0.34914729\n48  ZMB               Zambia  3500.5119 0.30129599  0.63302873 -0.33173275\n36  SDN                Sudan  4059.5331 0.50347675  0.80307131 -0.29959456\n45  TZA             Tanzania  2625.1980 0.22195235  0.36677650 -0.14482415\n35  RWA               Rwanda  2157.3935 0.09123742  0.22448015 -0.13324273\n44  TUN              Tunisia 10759.6827 2.73031139  2.84111696 -0.11080557\n15  ETH             Ethiopia  2161.6109 0.13674141  0.22576299 -0.08902158\n46  UGA               Uganda  2151.6788 0.13506038  0.22274186 -0.08768148\n28  MLI                 Mali  2305.2361 0.18661531  0.26945079 -0.08283548\n18  GIN               Guinea  2531.2341 0.25609996  0.33819464 -0.08209468\n4   BFA         Burkina Faso  2160.5895 0.19739801  0.22545229 -0.02805428\n26  MAR              Morocco  7476.1792 1.84045155  1.84234373 -0.00189218\n20  GNB        Guinea-Bissau  1969.2724 0.18117668  0.16725762  0.01391906\n42  TCD                 Chad  1577.9727 0.06553287  0.04823243  0.01730044\n10  COG                Congo  3356.2418 0.61610961  0.58914478  0.02696483\n19  GMB               Gambia  2175.5690 0.26780913  0.23000875  0.03780039\n39  SLE         Sierra Leone  1690.8316 0.14093841  0.08256175  0.05837667\n3   BEN                Benin  3224.0433 0.62247911  0.54893275  0.07354636\n27  MDG           Madagascar  1629.6623 0.16302068  0.06395532  0.09906535\n9   COD      Dem. Rep. Congo  1091.9213 0.02422917 -0.09961426  0.12384343\n38  SEN              Senegal  3354.8272 0.73865658  0.58871450  0.14994208\n33  NER                Niger  1207.7762 0.10333371 -0.06437363  0.16770734\n31  MWI               Malawi  1051.1249 0.07611109 -0.11202366  0.18813475\n6   CAF Central African Rep.   938.9888 0.06508274 -0.14613312  0.21121586\n2   BDI              Burundi   756.5941 0.04667763 -0.20161380  0.24829143\n23  LBR              Liberia  1462.4118 0.32340916  0.01308122  0.31032794\n29  MOZ           Mozambique  1284.9965 0.28091941 -0.04088480  0.32180421\n49  ZWE             Zimbabwe  2982.9890 0.84928791  0.47560907  0.37367884\n43  TGO                 Togo  1574.2385 0.43325640  0.04709655  0.38615984\n12  DZA              Algeria 11414.5995 3.68769052  3.04032896  0.64736157\n25  LSO              Lesotho  2758.1290 1.26133125  0.40721135  0.85411991\n24  LBY                Libya 15096.0769 8.08792735  4.16015754  3.92776981\n47  ZAF         South Africa 12556.2802 8.09035696  3.38760439  4.70275256\n\n\n\nCommentaire : Le tableau permet de repérer les pays qui s’éloignent le plus de la droite en raison d’une surestimation ou d’une sous-estimation de leurs émissions de CO2 par le PIB. Les résidus négatifs correspondent à des pays qui émettent moins de CO2 par habitant que ce que laisserait prévoir leur PIB par habitant. C’est par exemple le cas du Bostwana dont le PIB élevé (17700 $/hab.) laissait prévoir 4.95 t/hab. de CO2 par habitant mais qui en pratique n’en émet que 2.96 soit un résidu de -2 tonnes. Inversement le PIB de l’Afrique du Sud (12256 $/hab) laissait prévoir 3.9 tonnes de CO2 par habitant alors que la valeur observée est de 8.1 tonnes par habitant, soit un résidu de +4.7 tonnes de plus que prévu. Dans les deux cas on peut chercher des explications ad hoc (e.g. importance de la production de charbon en Afrique du Sud) mais il faut aussi se demander si ces écarts ne nont pas justes liés à une mauvaise spécification de notre modèle …"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#sauvegarder-les-résultats-du-modèle",
    "href": "MOD2_Regression_non_lineaire.html#sauvegarder-les-résultats-du-modèle",
    "title": "[MOD2] : Régression non linéaire",
    "section": "4.4 Sauvegarder les résultats du modèle",
    "text": "4.4 Sauvegarder les résultats du modèle\nOn peut si on le souhaite sauvegarder les résultats au format .csv\n\nwrite.table(x = tab,\n            file = \"result.csv\",\n            row.names = FALSE)"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#autocorrélation-des-résidus",
    "href": "MOD2_Regression_non_lineaire.html#autocorrélation-des-résidus",
    "title": "[MOD2] : Régression non linéaire",
    "section": "5.1 Autocorrélation des résidus",
    "text": "5.1 Autocorrélation des résidus\n\nlibrary(car)\nplot(modreglin,\n     which = 1,\n     labels.id = tab$name,\n     col=\"red\")\n\n\n\ndurbinWatsonTest(modreglin)\n\n lag Autocorrelation D-W Statistic p-value\n   1      0.04054838       1.91116    0.69\n Alternative hypothesis: rho != 0\n\n\n\nCommentaire : le graphique permet de voir que les résidus ne sont pas indépendants des valeurs estimées de Y, ce qui signifie que les points se situent en moyenne tantôt au dessus de la droite de régression, tantôt en dessous ce qui fausse leur estimation. Dans un modèle sans autocorrélation, la courbe rouge devrait suivre la ligne pointillé correspondant à une moyenne nulle des résidus, ce qui n’est visiblement pas le cas. On peut s’en assurer à l’aide du test de Durbin Watson qui pose l’hypothèse H0 : Il existe une autocorrélation des résidus. Cette hypothèse ne peut pas être rejetée (p &gt; 0.66) donc il existe bien une autocorrélation des résidus qui va fausser les prévisions du modèle de régression linéaire."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#normalité-des-résidus",
    "href": "MOD2_Regression_non_lineaire.html#normalité-des-résidus",
    "title": "[MOD2] : Régression non linéaire",
    "section": "5.2 Normalité des résidus",
    "text": "5.2 Normalité des résidus\n\nplot(modreglin,\n     which = 2,\n     labels.id = tab$name,\n     col=\"red\")\n\n\n\nshapiro.test(tab$Yres)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tab$Yres\nW = 0.68437, p-value = 1.163e-08\n\n\n\nCommentaire : La normalité de la distribution des résidus est également une condition importante de validité du modèle de régression linéaire puisqu’elle permet de définir un intervalle de confiance des estimations en se servant de l’écart-type de ces résidus (e.g. + ou - 2 écarts-type pour un intervalle de confiance à 95%). Mais il est clair ici au vu du diagramme QQ plot que la condition de normalité des résidus n’est pas vérifiée, ce que confirme le test de Shapiro (p &lt; 0.001)"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#homogénéité-des-résidus",
    "href": "MOD2_Regression_non_lineaire.html#homogénéité-des-résidus",
    "title": "[MOD2] : Régression non linéaire",
    "section": "5.3 Homogénéité des résidus",
    "text": "5.3 Homogénéité des résidus\n\nplot(modreglin,\n     which = 3,\n     labels.id = tab$name,\n     col=\"red\")\n\n\n\nncvTest(modreglin)\n\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 65.47898, Df = 1, p = 5.8737e-16\n\n\n\nCommentaire : En liaison avec ce qui précède, l’analyse de l’homogénéité des résidus permet de vérifier si la variance des résidus est constante et donc si l’intervalle de confiance sera le même pour l’ensemble des valeurs estimées. Ici, ce n’est clairement pas le cas puisque le graphique montre un net accroissement de la variance des résidus lorsque la valeur à estimer augmente. On peut vérifier l’absence d’homogénéité (appelée hétéroscédasticité) en appliquant le test de Breush-Pagan qui examine l’hypothèse “H0 : la distribution des résidus est homogène”. Dans notre exemple H0 est rejetée (p &lt; 0.001) ce qui signifie que l’hypothèse d’homogénéité est clairement rejetée."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#absence-de-valeurs-exceptionnellement-influentes",
    "href": "MOD2_Regression_non_lineaire.html#absence-de-valeurs-exceptionnellement-influentes",
    "title": "[MOD2] : Régression non linéaire",
    "section": "5.4 Absence de valeurs exceptionnellement influentes",
    "text": "5.4 Absence de valeurs exceptionnellement influentes\n\nplot(modreglin,\n     which = 4,\n     labels.id = tab$name,\n     col=\"red\")\n\n\n\noutlierTest(modreglin, labels = tab$name)\n\n             rstudent unadjusted p-value Bonferroni p\nSouth Africa 6.034761         3.2546e-07   1.4971e-05\nLibya        4.657740         3.0790e-05   1.4164e-03\n\n\n\nCommentaire : Le dernier test consiste à vérifier si la relation observée est bien le résultat d’un ensemble d’observations indépendantes et non pas l’effet de la présence d’une ou deux valeurs exceptionnelles. Plusieurs tests sont ici possibles qui visent au même objectif : déterminer à quel point le retrait d’une valeur unique modifie le résultat de l’analyse, c’est à dire le coefficient de détermination \\(r_{XY}^2\\) et les paramètres \\(a\\) et \\(b\\) de l’équation \\(Y=aX+b\\). Le graphique proposé par R utilise la distance de Cook pour mettre en valeur l’influence potentielle des valeurs exceptionnelles et on y retrouve sans surprise la Libye, l’Afrique du Sud et le Bostwana. On peut arriver à un résultat similaire en utilisant le test de Bonferroni qui signale le caractère exceptionellement influent de l’Afrique du Sud et de la Libye."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#tous-les-tests-dun-coup",
    "href": "MOD2_Regression_non_lineaire.html#tous-les-tests-dun-coup",
    "title": "[MOD2] : Régression non linéaire",
    "section": "5.5 Tous les tests d’un coup",
    "text": "5.5 Tous les tests d’un coup\nUne fois que l’on a bien compris les tests précédents, on peut afficher les quatre graphiques correspondant en une seule commande :\n\npar(mfrow=c(2,2))\nplot(modreglin,\n     which = c(1,2,3,4),\n     labels.id = tab$name,\n     col=\"red\")"
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#modèle-linéaire-sans-valeurs-exceptionnelles.",
    "href": "MOD2_Regression_non_lineaire.html#modèle-linéaire-sans-valeurs-exceptionnelles.",
    "title": "[MOD2] : Régression non linéaire",
    "section": "6.1 Modèle linéaire sans valeurs exceptionnelles.",
    "text": "6.1 Modèle linéaire sans valeurs exceptionnelles.\nOn décide de retirer les trois valeurs exceptionellement influentes qui ont été repérées dans la première analyse et de refaire une régression linéaire.\n\nTableau sans valeurs exceptionnelles\n\ntab2&lt;-tab[!(tab$iso3 %in% c(\"ZAF\",\"BWA\",\"LBY\")),]\n\n\n\nCorrélation\n\ncor.test(tab2$X,tab2$Y, method=\"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  tab2$X and tab2$Y\nt = 16.456, df = 41, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8770905 0.9627927\nsample estimates:\n      cor \n0.9319357 \n\ncor.test(tab2$X,tab2$Y, method=\"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  tab2$X and tab2$Y\nS = 1614, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8781335 \n\n\n\n\nRégression\n\nmodreglin2 &lt;- lm(tab2$Y~tab2$X)\nsummary(modreglin2)\n\n\nCall:\nlm(formula = tab2$Y ~ tab2$X)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.67137 -0.21168 -0.02265  0.12596  1.33042 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.452e-01  8.348e-02  -2.937  0.00542 ** \ntab2$X       2.280e-04  1.385e-05  16.456  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3666 on 41 degrees of freedom\nMultiple R-squared:  0.8685,    Adjusted R-squared:  0.8653 \nF-statistic: 270.8 on 1 and 41 DF,  p-value: &lt; 2.2e-16\n\n# Extraction des valeurs estimées et résiduelles\ntab2$Yest &lt;- modreglin2$fitted.values\ntab2$Yres &lt;- modreglin2$residuals\n\n\n\nVisualisation\n\nplot(tab2$X,tab2$Y,\n     cex = 0.6,\n     pch = 19,\n     col = \"red\",\n     xlab = nomX,\n     ylab = nomY,\n     main = titre,\n     sub = note)\ntext(tab2$X, tab2$Y, tab2$iso3,\n     cex = 0.6,\n     col = \"blue\",\n     pos = 1)\nabline(modreglin2, col =\"black\", lwd =2)\n\n\n\n\n\n\nDiagnostics\n\npar(mfrow=c(2,2))\nplot(modreglin2,\n     which = c(1,2,3,4),\n     labels.id = tab2$name,\n     col=\"red\")\n\n\n\ndurbinWatsonTest(modreglin2)\n\n lag Autocorrelation D-W Statistic p-value\n   1      0.05326152      1.856255   0.682\n Alternative hypothesis: rho != 0\n\nshapiro.test(tab2$Yres)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tab2$Yres\nW = 0.91406, p-value = 0.003438\n\nncvTest(modreglin2)\n\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 14.98559, Df = 1, p = 0.00010834\n\noutlierTest(modreglin2,labels = tab2$name)\n\n        rstudent unadjusted p-value Bonferroni p\nAlgeria 4.679998          3.263e-05    0.0014031\n\n\n\nCommentaire : Le nouveau modèle affiche une corrélation beaucoup plus élevée (\\(r_{XY} = + 0.96\\)) et une bien meilleure qualité d’ajustement (\\(r_{XY}^2 = 86.5%\\)). Il demeure une forte autocorrélation des résidus (p &gt;0.60) mais les résidus sont à peu près gaussiens (p &gt;0.05). L’hétéroscédasticité demeure élévée (p &lt; 0.001) et on trouve une nouvelle valeur exceptionellement influente (Algérie). Il y a donc d’indéniables progrès mais le modèle n’est pas encore tout à fait satisfaisant."
  },
  {
    "objectID": "MOD2_Regression_non_lineaire.html#modèles-non-linéaires",
    "href": "MOD2_Regression_non_lineaire.html#modèles-non-linéaires",
    "title": "[MOD2] : Régression non linéaire",
    "section": "6.2 Modèles non linéaires",
    "text": "6.2 Modèles non linéaires\nIl est toujours ennuyeux de retirer des valeurs exceptionnelles car on risque d’en trouver des nouvelles et c’est un processus sans fin. Il s’agit en outre d’une démarche criticable si on effectue le retrait des valeurs sans raisons objectives. Il est donc préférable d’essayer de garder toutes les valeurs mais de chercher à transformer les variables X et Y pour construire des fonctions différentes. On utilise classiquement quatre modèles (linéaire, exponentiel, logarithmique, puissance) selon que l’on applique ou non des transformations linéaires à X et Y.\n\nExamen visuel des quatre modèles\n\npar(mfrow=c(2,2))\n\nplot(tab$X,tab$Y, main = \"Linéaire : Y=a.X+b\", pch=20, col=\"red\",cex=0.5)\nplot(tab$X,log(tab$Y), main = \"Exponentiel : log(Y)=a.X+b\", pch=20, col=\"red\",cex=0.5)\nplot(log(tab$X),tab$Y, main = \"Logarithmique : Y = a.log(X)+b\", pch=20, col=\"red\",cex=0.5)\nplot(log(tab$X),log(tab$Y), main = \"Puissance : log(Y) = a.log(X)+b\", pch=20, col=\"red\",cex=0.5)\n\n\n\n\n\nCommentaire : Un simple examen visuel laisse présager que le modèle puissance est celui qui s’ajustera le mieux à une droite et offrira une répartition régulière des résidus conforme aux hypothèses.\n\n\n\nCalcul des coefficients de corrélation\n\npaste(\"Linéaire : \",round(cor(tab$X,tab$Y),3))\n\n[1] \"Linéaire :  0.804\"\n\npaste(\"Exponentiel : \", round(cor(tab$X,log(tab$Y)),3))\n\n[1] \"Exponentiel :  0.85\"\n\npaste(\"Logarithmique : \",round(cor(log(tab$X),tab$Y),3))\n\n[1] \"Logarithmique :  0.722\"\n\npaste(\"Puissance : \", round(cor(log(tab$X),log(tab$Y)),3))\n\n[1] \"Puissance :  0.913\"\n\n\n\nCommentaire : Le calcul des coefficients de corrélation confirme que cette solution donne le meilleur ajustement aux données. Noter bien que ce critère ne suffit pas à lui seul à choisir un modèle. Un modèle qui aurait un meilleur ajustement mais violerait leshypothèses ne devrait pas être retenu face à un modèle ayant un ajustement plus faible mais des résidus mieux distribués.\n\n\n\nPréparation des données\nOn crée un nouveau tableau de données\n\ndon$X&lt;-log(don$PIB)\ndon$Y&lt;-log(don$CO2)\ntab3&lt;-don[,c(\"iso3\",\"name\",\"X\",\"Y\")]\ntab3&lt;-tab3[complete.cases(tab3), ]\nnomXlog &lt;- \"log(PIB en $/hab)\"\nnomYlog &lt;- \"log(CO2 en t./hab)\" \ntitre &lt;- \"Les pays Africains en 2018\"\nnote &lt;- \"Source : Rapport sur le développement humain 2020\"\n\n\n\nRégression\n\nmodregpuis &lt;- lm(tab3$Y~tab3$X)\nsummary(modregpuis)\n\n\nCall:\nlm(formula = tab3$Y ~ tab3$X)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.21875 -0.34992 -0.09064  0.27574  1.38323 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -12.69651    0.80784  -15.72   &lt;2e-16 ***\ntab3$X        1.45733    0.09822   14.84   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5672 on 44 degrees of freedom\nMultiple R-squared:  0.8334,    Adjusted R-squared:  0.8296 \nF-statistic: 220.2 on 1 and 44 DF,  p-value: &lt; 2.2e-16\n\n# Extraction des valeurs estimées et résiduelles\ntab3$Yest &lt;- modregpuis$fitted.values\ntab3$Yres &lt;- modregpuis$residuals\n\n\n\nVisualisation\n\nplot(tab3$X,tab3$Y,\n     cex = 0.6,\n     pch = 19,\n     col = \"red\",\n     xlab = nomXlog,\n     ylab = nomYlog,\n     main=titre,\n     sub = note)\ntext(tab3$X, tab3$Y, tab3$iso3,\n     cex = 0.6,\n     col = \"blue\",\n     pos = 1)\nabline(modregpuis, col =\"black\", lwd =2)\n\n\n\n\n\n\nDiagnostics\n\npar(mfrow=c(2,2))\nplot(modregpuis,\n     which = c(1,2,3,4),\n     labels.id = tab3$name,\n     col=\"red\")\n\n\n\ndurbinWatsonTest(modregpuis)\n\n lag Autocorrelation D-W Statistic p-value\n   1      0.03349644       1.87894     0.7\n Alternative hypothesis: rho != 0\n\nshapiro.test(tab3$Yres)\n\n\n    Shapiro-Wilk normality test\n\ndata:  tab3$Yres\nW = 0.95564, p-value = 0.07752\n\nncvTest(modregpuis)\n\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 1.248169, Df = 1, p = 0.2639\n\noutlierTest(modregpuis,labels = tab3$name)\n\nNo Studentized residuals with Bonferroni p &lt; 0.05\nLargest |rstudent|:\n        rstudent unadjusted p-value Bonferroni p\nLesotho 2.628744           0.011838      0.54453\n\n\n\nCommentaires : Outre sa qualité d’ajustement élevée (r2 = 83%), le modèle final respecte beaucoup mieux les hypothèses théoriques d’un modèle de régression linéaire. Il demeure certes une légère autocorrélation des résidus et une disribution qui n’est pas tout àfait gaussienne. Mais les résidus sont désormais homogènes (p &gt;0.26) et aucune valeur influente n’est plus détectée par le test de Bonferoni. Bref, le modèle est acceptable.\n\n\n\nReprésenter la forme finale du modèle Y = f(X)\nLe modèle ayant été ajusté sous forme bi-logarithmique, il faut en rétablir l’équation sous la forme Y = f(X), ce qui suppose de transformer l’équation de la façon suivante :\n\n\\(log(Y) = a\\times {log(X)}+b &lt;=&gt; Y = e^{b} \\times X^{a}\\)\n\nCe qui nous donne l’équation finale :\n\n\\(log(CO_2) = a\\times log(PIB) + b &lt;=&gt; CO_2 = e^{-12.696}\\times PIB^{1.47} &lt;=&gt; CO_2 = 0.000003\\times PIB^{1.47}\\)\n\nQue l’on peut représenter de la façon suivante :\n\nx&lt;-seq(0,20000,100)\ny&lt;- 0.000003*(x**1.47)\nplot(x,y,\n     type=\"l\",\n     col=\"red\",\n     lwd =2,\n     xlab = \"PIB en $/hab.\",\n     ylab = \"Estimation du CO2 en t./hab\",\n     main = \"Modèle final\") \ngrid()\n\n\n\n\n\nCommentaire : Notre modèle final offre une représentation assez fiable de la relation qui existe entre le PIB par habitant et les émissions de CO2 des pays africains en 2018. La forme de la relation est de type puissance avec un exposant de 1.41 &gt; 1 ce qui indique que l’accroissement des émissions n’est pas linéaire mais de plus en plus rapide lorsque le développement augmente. Un pays dont le revenu est de 5000 $/hab. émettra moins de 1 tonne de CO2 par habitant alors qu’un pays dont le revenu est de 10 000 $/hab émettra plus de 2 tonnes et un pays dont le revenu est de 20 000 $ par habitant plus de 6 tonnes !"
  },
  {
    "objectID": "STA1_Univariee.html",
    "href": "STA1_Univariee.html",
    "title": "[STA1] : Statistiques univariée",
    "section": "",
    "text": "Nous allons importer un fichier de données portant sur les revenus de 17000 ménages tunisiens en 2021. Il est tiré de l’enquête consommation et revenu de l’INS dont on trouvera la description détaillée en cliquant ici\n\n\n\n\n\n\nTélécharger le jeux de données\n\n\n\n\nENQ-TUN-2021\n\n\n\n\n\nOn commence par charger les données contenues dans le fichier enq_INS_conso_menages_2021.RDS à l’aide de la fonction readRDS() qui permet de lire les fichiers sauvegardés sans le format interne de R et on affiche les 6 premières lignes\n\n# Importe les données au format interne de R\nbase&lt;-readRDS(\"data/ENQ-TUN-2021/enq_INS_conso_menages_2021.RDS\")  \nhead(base)\n\n  id reg    mil   sex age     mat        ins      csp nbp   pvr  rev\n1  1  GT urbain homme  59   marie   primaire retraité   6 FALSE 5103\n2  2  GT urbain homme  52   marie   primaire  employé   5 FALSE 5486\n3  3  GT urbain femme  34 divorce secondaire  chomeur   2 FALSE 5962\n4  4  GT urbain homme  65   marie   primaire  inactif   2 FALSE 3699\n5  5  GT urbain homme  35   marie secondaire  ouvrier   4 FALSE 5058\n6  6  GT urbain homme  43   marie   primaire  ouvrier   5 FALSE 3741\n\n\n\n\n\nOn a légèrement changé le fichier initial de l’INS en simplifiant les noms des variables et en fusionnant certaines modalités. Les variables proposées sont les suivantes :\n\nid : identifiant du ménages de 1 à 17114\nreg : région de résidence (NE, NO, CE, CO, SE, SO + Grand Tunis)\nmil : milieu de résidence (urbain ou rural)\nsex : sexe du chef de ménage\nage : age du chef de ménage\nmat : situation matrimoniale (célbataire, marié, veuf, divorcé)\nins : instruction du chef de ménage (aucune, primaire, secondaire, supérieur)\ncsp : catégorie socio professionnelle du chef de ménage (simplifiée)\nnbp : nombre de personnes composant le ménage\npauv: situation de pauvreté selon les critères de l’INS (Oui/Non)\nrev : revenu moyen par personnes en DT / an\n\n\n\n\nOn suppose qu’on ne s’intéresse qu’à quelques variables\n\ndon&lt;-base[,c(\"reg\",\"mil\",\"sex\", \"age\",\"ins\",\"pvr\",\"rev\")]\nhead(don)\n\n  reg    mil   sex age        ins   pvr  rev\n1  GT urbain homme  59   primaire FALSE 5103\n2  GT urbain homme  52   primaire FALSE 5486\n3  GT urbain femme  34 secondaire FALSE 5962\n4  GT urbain homme  65   primaire FALSE 3699\n5  GT urbain homme  35 secondaire FALSE 5058\n6  GT urbain homme  43   primaire FALSE 3741\n\n\n\n\n\nOn effectue un résumé rapide du tableau à l’aide de la fonction summary():\n\nsummary(don)\n\n reg           mil           sex             age                 ins      \n GT:3944   urbain:10836   homme:13996   Min.   : 19.00   aucun     :3742  \n NE:2458   rural : 6278   femme: 3118   1st Qu.: 46.00   primaire  :6979  \n NO:2502                                Median : 56.00   secondaire:4647  \n CE:2862                                Mean   : 56.34   supérieur :1746  \n CO:2330                                3rd Qu.: 66.00                    \n SE:1845                                Max.   :109.00                    \n SO:1173                                                                  \n    pvr               rev        \n Mode :logical   Min.   :   185  \n FALSE:14665     1st Qu.:  3035  \n TRUE :2449      Median :  4429  \n                 Mean   :  5519  \n                 3rd Qu.:  6496  \n                 Max.   :526271"
  },
  {
    "objectID": "STA1_Univariee.html#importation-des-données",
    "href": "STA1_Univariee.html#importation-des-données",
    "title": "[STA1] : Statistiques univariée",
    "section": "",
    "text": "On commence par charger les données contenues dans le fichier enq_INS_conso_menages_2021.RDS à l’aide de la fonction readRDS() qui permet de lire les fichiers sauvegardés sans le format interne de R et on affiche les 6 premières lignes\n\n# Importe les données au format interne de R\nbase&lt;-readRDS(\"data/ENQ-TUN-2021/enq_INS_conso_menages_2021.RDS\")  \nhead(base)\n\n  id reg    mil   sex age     mat        ins      csp nbp   pvr  rev\n1  1  GT urbain homme  59   marie   primaire retraité   6 FALSE 5103\n2  2  GT urbain homme  52   marie   primaire  employé   5 FALSE 5486\n3  3  GT urbain femme  34 divorce secondaire  chomeur   2 FALSE 5962\n4  4  GT urbain homme  65   marie   primaire  inactif   2 FALSE 3699\n5  5  GT urbain homme  35   marie secondaire  ouvrier   4 FALSE 5058\n6  6  GT urbain homme  43   marie   primaire  ouvrier   5 FALSE 3741"
  },
  {
    "objectID": "STA1_Univariee.html#liste-des-variables",
    "href": "STA1_Univariee.html#liste-des-variables",
    "title": "[STA1] : Statistiques univariée",
    "section": "",
    "text": "On a légèrement changé le fichier initial de l’INS en simplifiant les noms des variables et en fusionnant certaines modalités. Les variables proposées sont les suivantes :\n\nid : identifiant du ménages de 1 à 17114\nreg : région de résidence (NE, NO, CE, CO, SE, SO + Grand Tunis)\nmil : milieu de résidence (urbain ou rural)\nsex : sexe du chef de ménage\nage : age du chef de ménage\nmat : situation matrimoniale (célbataire, marié, veuf, divorcé)\nins : instruction du chef de ménage (aucune, primaire, secondaire, supérieur)\ncsp : catégorie socio professionnelle du chef de ménage (simplifiée)\nnbp : nombre de personnes composant le ménage\npauv: situation de pauvreté selon les critères de l’INS (Oui/Non)\nrev : revenu moyen par personnes en DT / an"
  },
  {
    "objectID": "STA1_Univariee.html#selection-du-tableau-à-analyser",
    "href": "STA1_Univariee.html#selection-du-tableau-à-analyser",
    "title": "[STA1] : Statistiques univariée",
    "section": "",
    "text": "On suppose qu’on ne s’intéresse qu’à quelques variables\n\ndon&lt;-base[,c(\"reg\",\"mil\",\"sex\", \"age\",\"ins\",\"pvr\",\"rev\")]\nhead(don)\n\n  reg    mil   sex age        ins   pvr  rev\n1  GT urbain homme  59   primaire FALSE 5103\n2  GT urbain homme  52   primaire FALSE 5486\n3  GT urbain femme  34 secondaire FALSE 5962\n4  GT urbain homme  65   primaire FALSE 3699\n5  GT urbain homme  35 secondaire FALSE 5058\n6  GT urbain homme  43   primaire FALSE 3741"
  },
  {
    "objectID": "STA1_Univariee.html#résumé-rapide",
    "href": "STA1_Univariee.html#résumé-rapide",
    "title": "[STA1] : Statistiques univariée",
    "section": "",
    "text": "On effectue un résumé rapide du tableau à l’aide de la fonction summary():\n\nsummary(don)\n\n reg           mil           sex             age                 ins      \n GT:3944   urbain:10836   homme:13996   Min.   : 19.00   aucun     :3742  \n NE:2458   rural : 6278   femme: 3118   1st Qu.: 46.00   primaire  :6979  \n NO:2502                                Median : 56.00   secondaire:4647  \n CE:2862                                Mean   : 56.34   supérieur :1746  \n CO:2330                                3rd Qu.: 66.00                    \n SE:1845                                Max.   :109.00                    \n SO:1173                                                                  \n    pvr               rev        \n Mode :logical   Min.   :   185  \n FALSE:14665     1st Qu.:  3035  \n TRUE :2449      Median :  4429  \n                 Mean   :  5519  \n                 3rd Qu.:  6496  \n                 Max.   :526271"
  },
  {
    "objectID": "STA1_Univariee.html#choix-de-la-variables",
    "href": "STA1_Univariee.html#choix-de-la-variables",
    "title": "[STA1] : Statistiques univariée",
    "section": "Choix de la variables",
    "text": "Choix de la variables\nNous allons prendre comme exemple la variable ins que l’on va extraire du tableau pour en faire un vecteur X qui est de type factor\n\nX &lt;-don$ins\nclass(X)\n\n[1] \"factor\""
  },
  {
    "objectID": "STA1_Univariee.html#tableau-de-dénombrement",
    "href": "STA1_Univariee.html#tableau-de-dénombrement",
    "title": "[STA1] : Statistiques univariée",
    "section": "2.1 tableau de dénombrement",
    "text": "2.1 tableau de dénombrement\nPour dénomber une variable qualitative, on utilise l’instruction table() qui crée un objet particulier qui n’est ni un data.frame, ni une matrix.\n\ncréation et affichage du tableau\n\ntab&lt;-table(X)\ntab\n\nX\n     aucun   primaire secondaire  supérieur \n      3742       6979       4647       1746"
  },
  {
    "objectID": "STA1_Univariee.html#tableau-de-dénombrement-1",
    "href": "STA1_Univariee.html#tableau-de-dénombrement-1",
    "title": "[STA1] : Statistiques univariée",
    "section": "2.1 tableau de dénombrement",
    "text": "2.1 tableau de dénombrement\n\nAjout du total\nUn objet de type table peut être manipulé par des fonctions spéciales comme addmargins()\n\ntab2&lt;-addmargins(tab)\ntab2\n\nX\n     aucun   primaire secondaire  supérieur        Sum \n      3742       6979       4647       1746      17114 \n\n\n\n\nTransformation en fréquence\nOn peut également passer en fréquence avec la fonction prop.table()\n\ntab3&lt;-prop.table(tab)\ntab3\n\nX\n     aucun   primaire secondaire  supérieur \n 0.2186514  0.4077948  0.2715321  0.1020217 \n\n\n\n\nTransformation en pourcentage\nOn peut finalement afficher le résultat sous une forme élégante :\n\ntab4&lt;-100*addmargins(tab3)\ntab4\n\nX\n     aucun   primaire secondaire  supérieur        Sum \n  21.86514   40.77948   27.15321   10.20217  100.00000"
  },
  {
    "objectID": "STA1_Univariee.html#visualiation",
    "href": "STA1_Univariee.html#visualiation",
    "title": "[STA1] : Statistiques univariée",
    "section": "2.3 Visualiation",
    "text": "2.3 Visualiation\nLa fonction plot() s’applique à la plupart de objets R. Elle s’adapte au type d’objet et va chercher la fonction la plus adaptée au type de variable. Dans le cas d’une variable de type factor, la fonction plot() appelle en réalité la fonction barplot() après avoir effectué le dénombrement avec table()\n\nDiagramme en bâtons\n\n# Ecriture simple\nplot(X)\n\n\n\n# Ecriture équivalente\n# barplot(table(X))\n\n\n\nplot amélioré\n\nplot(X,col=c(\"orange\",\"yellow\",\n             \"lightyellow\",\"lightgreen\"), \n     main= \"Niveau d'instruction des chefs de ménages\",\n     xlab = \"niveau\", \n     ylab = \"Nombre de ménages\",\n     sub = \"Source : INS, 2021\")"
  },
  {
    "objectID": "STA1_Univariee.html#valeurs-centrales-et-paramètres-de-dispersion",
    "href": "STA1_Univariee.html#valeurs-centrales-et-paramètres-de-dispersion",
    "title": "[STA1] : Statistiques univariée",
    "section": "3.1 Valeurs centrales et paramètres de dispersion",
    "text": "3.1 Valeurs centrales et paramètres de dispersion\n\nfonctions élémentaires\nUne variable numérique peut faire l’objet d’un ensemble de résumés statistiques à l’aide de fonctions élémentaires\n\nmin() : minimum\nmax() : maximum\nmean() : moyenne\nsd() : écart-type\nsum() : somme\n\nOn va prendre l’exemple du revenu moyen par habitant\n\nX &lt;- don$rev\nmin(X)\n\n[1] 185\n\nmax(X)\n\n[1] 526271\n\nmean(X)\n\n[1] 5519.385\n\nsd(X)\n\n[1] 7036.663\n\n\n\n\nquantiles\nPour calculer les quantiles on peut utiliser la fonction quantile() en paramétrant la valeur de fréquence cumulée ascendante\n\nquantile(X,0) : minimum\nquantile(X,0.10) : D1 (premier décile)\nquantile(X,0.25) : Q1 (premier quartile)\nquantile(X,0.5) : Q2 (médiane)\nquantile(X,0.75) : Q3 (troisième quartile)\nquantile(X,0.90) : D9 (dernier décile)\nquantile(X,1) : maximum\n\n\n\nquantiles\n\nX&lt;-don$rev\nquantile(X,0.5)\n\n 50% \n4429 \n\nsel&lt;-c(0,0.25,0.5,0.75,1)\nquantile(X,sel)\n\n       0%       25%       50%       75%      100% \n   185.00   3035.00   4429.00   6495.75 526271.00 \n\nsel&lt;-c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)\nquantile(X,sel)\n\n      0%      10%      20%      30%      40%      50%      60%      70% \n   185.0   2143.6   2757.0   3304.0   3854.0   4429.0   5104.0   5941.0 \n     80%      90%     100% \n  7151.0   9480.4 526271.0"
  },
  {
    "objectID": "STA1_Univariee.html#tableau-de-dénombrement-discrétisation",
    "href": "STA1_Univariee.html#tableau-de-dénombrement-discrétisation",
    "title": "[STA1] : Statistiques univariée",
    "section": "3.2 Tableau de dénombrement (discrétisation)",
    "text": "3.2 Tableau de dénombrement (discrétisation)\nUne variable quantitative peut être discrétisée avec cut(). Elle devient alors un facteur qu’on peut dénomber avec table()\n\nXQ&lt;-cut(don$rev, c(0, 500, 1000, 2000, 5000, 10000, 20000, 50000, 1000000))\ntable(XQ)\n\nXQ\n      (0,500]   (500,1e+03] (1e+03,2e+03] (2e+03,5e+03] (5e+03,1e+04] \n            7            92          1269          8664          5586 \n(1e+04,2e+04] (2e+04,5e+04] (5e+04,1e+06] \n         1333           134            29"
  },
  {
    "objectID": "STA1_Univariee.html#boîte-à-moustaches",
    "href": "STA1_Univariee.html#boîte-à-moustaches",
    "title": "[STA1] : Statistiques univariée",
    "section": "3.3 Boîte à moustaches",
    "text": "3.3 Boîte à moustaches\nLa fonction boxplot() permet de visualiser une distribution sous forme de boîte à moustache où l’on repère facilement :\n\nla médiane\nles quartiles Q1 et Q3\nle minimum et le maximum\nles valeurs extrêmes\n\n\nBoxplot simple\n\nboxplot(X)\n\n\n\n\n\n\nBoxplot améliorée\n\nboxplot(X,horizontal = TRUE, \n        col = \"gray80\",\n        main = \"Revenu par habitant des ménages\",\n        xlab = \"en DT\",\n        outline = F \n        )"
  },
  {
    "objectID": "STA1_Univariee.html#histogramme",
    "href": "STA1_Univariee.html#histogramme",
    "title": "[STA1] : Statistiques univariée",
    "section": "3.4 Histogramme",
    "text": "3.4 Histogramme\nDans le cas d’une variable quantitative continue, la visualisation la plus logique est l’histogramme que l’on peut tracer avec la fonction hist(). Celle-ci comporte plusieurs paramètres que l’on peut visualiser en allant dans l’onglet Help et en tapant le nom de la fonction. On retiendra surtout ici\n\nbreaks : contrôle le choix des classes\nprobability : affiche la densité et non pas l’effectif des classes\n\n\nHistogramme simple\n\nX&lt;-don$rev\nhist(X)\n\n\n\n\n\n\nHistogramme amélioré\n\nX&lt;-don$rev\n\n# Choix des classes\nmybreaks&lt;-c(min(X),1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,\n                       11000, 12000, 13000, 14000, 15000,16000,\n            17000, 18000, 19000, 20000, max(X))\n\nhist(X,\n     breaks = mybreaks, \n     col=\"lightyellow\",\n     main = \"Revenu des ménages tunisiens en 2021\",\n     sub = \"Source : INS, 2021\",\n     xlab = \"en DT par personne et par an\",\n     ylab = \"Probabilité\",\n     xlim=c(0,20000))\n\n\n\n\n\n\nHistogramme superbe\n\nX&lt;-don$rev\n\n# Choix des classes\nmybreaks&lt;-c(min(X),1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,\n                       11000, 12000, 13000, 14000, 15000,16000,\n            17000, 18000, 19000, 20000, max(X))\n\nhist(X,\n     breaks = mybreaks, \n     col=\"lightyellow\",\n     main = \"Revenu des ménages tunisiens en 2021\",\n     sub = \"Source : INS, 2021\",\n     xlab = \"en DT par personne et par an\",\n     ylab = \"Probabilité\",\n     xlim=c(0,20000))\n\n# Ajout d'une courbe de Probabilité lissée\nlines(density(X,\n              bw = sd(X)/2),\n              col=\"red\", lwd=2)\n\n# Ajout de la moyenne et de la médiane\nabline(v=mean(X), col=\"blue\")\nabline(v=median(X), col=\"green\")"
  },
  {
    "objectID": "STA1_Univariee.html#objectif",
    "href": "STA1_Univariee.html#objectif",
    "title": "[STA1] : Statistiques univariée",
    "section": "Objectif",
    "text": "Objectif\nVous allez maintenant essayer de reprendre les programmes précédents en analysant successivement une variable qualitative et une variable quantitative."
  },
  {
    "objectID": "CARTO1_intro.html#les-premières-cartes",
    "href": "CARTO1_intro.html#les-premières-cartes",
    "title": "Petite histoire de la cartographie thématique",
    "section": "Les premières cartes",
    "text": "Les premières cartes\n\n\n “Cadastre” de Bedolina (découverte en en Italie du nord) 2000 ans av.n.è. J.-C. Quatre périodes au moins de gravure se superposent, et cette mystérieuse topographie apparaît sur la deuxième couche, voisinant avec des représentations de cervidés. S’il s’agit bien d’un premier vocabulaire topographique, nous ne savons pas le lire.\n\n Ces cartes polynésiennes appelées Rebbelibs, Medosou ou Mattangs représentants les courants marins et la direction de la houle qui est perturbée par la présence des îles avec des bâtons de bois courbés, les coquillages représentants la position des îles. Elle datent de 1000 av.n.è.\n\n\nDes représentations du Monde qui s’affinent\n\nLambert, N., Zanin C. (2019). Mad Maps - L’Atlas qui va changer votre vision du monde (p. 144p). Armand Colin.\n\nL’humanité produit des cartes depuis plus de 4000 ans pour se repérer et/ou se déplacer. Petit à petit les représentations du monde se sont affinées. On dispose aujourd’hui de bases de données très précises permettant de représenter le monde. Est-ce “la fin de l’histoire” cartographique ?"
  },
  {
    "objectID": "CARTO1_intro.html#les-débuts-de-la-dataviz",
    "href": "CARTO1_intro.html#les-débuts-de-la-dataviz",
    "title": "Petite histoire de la cartographie thématique",
    "section": "Les débuts de la dataviz",
    "text": "Les débuts de la dataviz\n\nNicole Oresme (1370) est un des premiers à concevoir le principe et l’utilité des coordonnées cartésiennes pour la représentation graphique de phénomènes quantitatifs\n\n\n\n\n\n\n\nWilliam Playfair (1786)Commercial and Political Atlas.\n\n\n\n\n\n\n\nFlorence Nightingale (1857)Notes on Matters Affecting the Health, Efficiency and Hospital Administration of the British Army.\n\n\n\nOn va s’intéresser maintenant à une autre histoire, celle de la visualisation de données. Cette histoire est plus courte. Elle commence vraiment au 18e siècle avec William Playfair et Florence Nightingale."
  },
  {
    "objectID": "CARTO1_intro.html#la-rencontre-de-2-mondes",
    "href": "CARTO1_intro.html#la-rencontre-de-2-mondes",
    "title": "Petite histoire de la cartographie thématique",
    "section": "La rencontre de 2 mondes",
    "text": "La rencontre de 2 mondes\nQuand la cartographie rencontre la visualisation de données statistiques\n\n\n\nCarte figurative de l’instruction populaire en France (Charles Dupin, 1826) \n\nFrère de Montizon (1830)  Emile Cheysson (1886) \n\n\nLe GOLD STANDARD de la dataviz\n\nCarte Figurative des pertes successives en hommes de l’armée française dans la campagne de Russie 1812–1813.Charles Joseph Minard (1869). Minard représente en 1869 les pertes colossales de l’armée française dans la campagne de Russie au début du XIXe siècle. Cette fameuse « carte figurative » raconte l’histoire de cette armée, qui arrive à Moscou avec moins d’un quart de son effectif de départ, avant de se faire à nouveau décimer sur le voyage du retour.\n\n\nCes deux histoires s’intersectent pour la première fois en 1826 avec la carte figurative de Charles Dupin. Pour la première fois, on représentait des données statistiques sur un repère géographique. C’est aussi la première carte choroplèthe. S’en suivent de nombreuses autres représentations cartographiques. Les réalisations de C.J. Minard sont particulièrement remarquables."
  },
  {
    "objectID": "CARTO1_intro.html#bertin-1967-et-1973",
    "href": "CARTO1_intro.html#bertin-1967-et-1973",
    "title": "Petite histoire de la cartographie thématique",
    "section": "Bertin, 1967 (et 1973)",
    "text": "Bertin, 1967 (et 1973)\n\nEnorme travail de synthèse.\nApproche plutôt pragmatique.\nPour le papier.\nEn noir et blanc.\nMais un travail qui reste central pour toutes celles et ceux qui travaillent sur la visualisation de données aujourd’hui.\n\n\n\nCette façon de représenter des données via des signes graphiques et synthétisée de façon remarquable en 1967 par Jacques Bertin."
  },
  {
    "objectID": "CARTO1_intro.html#sémiologie-graphique",
    "href": "CARTO1_intro.html#sémiologie-graphique",
    "title": "Petite histoire de la cartographie thématique",
    "section": "Sémiologie graphique",
    "text": "Sémiologie graphique\nLa nature de la donnée détermine le type de représentation.\n\nVariables visuelles de différenciation\nDonnées qualitatives nominales\n \nVariables visuelles d’ordre\nDonnées qualitatives ordinales et données quantitatives relatives\n\nVariables visuelles de proportionnalité\nDonnées de stock\n\nLa règle de base à retenir !️\n⚠️ Pas de stock en aplat"
  },
  {
    "objectID": "CARTO1_intro.html#les-logiciels",
    "href": "CARTO1_intro.html#les-logiciels",
    "title": "Petite histoire de la cartographie thématique",
    "section": "Les logiciels",
    "text": "Les logiciels\nIl existe une multitude de logiciels permettant de réaliser des cartes ou contribuant à leurs réalisation. Logiciels SVG, logiciels de cartographie clic bouton, logiciels en ligne de commande, logiciels DAO…"
  },
  {
    "objectID": "CARTO1_intro.html#cartographie-avec-r",
    "href": "CARTO1_intro.html#cartographie-avec-r",
    "title": "Petite histoire de la cartographie thématique",
    "section": "Cartographie avec R",
    "text": "Cartographie avec R\nDe l’acquisition de données à la carte finale, on mobilise généralement différents logiciels, libres ou propriétaires. Plus on multiplie les logiciels, plus la chaîne de traitement est brisée.\n\nAvec R, on va donc chercher à minimiser ces ruptures logicielles en regroupant l’ensemble de la chaine de traitement dans une seul écosystème.\n\nEt cela permet de documenter notre travail et de rendre nos cartes reproductibles.\n\nVoyons voir comment tout cela fonctionne : neocarto.github.io/geounivr2024/MAR_2_carto"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html",
    "href": "MOD4_Analyse_de_variance.html",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "",
    "text": "library(sf, quietly= TRUE,warn.conflicts = F)\nlibrary(dplyr, quietly = TRUE,warn.conflicts = F)\nlibrary(knitr)\nlibrary(mapsf)\nlibrary(car,warn.conflicts = F,quietly=T)\nL’objectif de cet exercice est de fournir une introduction aux modèles d’analyse de variance simple ou multiples dans lesquels une variable Y quantitative est fonction d’une ou plusieurs variables qualitatives X1, X2, X3…"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#importation-des-données",
    "href": "MOD4_Analyse_de_variance.html#importation-des-données",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Importation des données",
    "text": "Importation des données\nOn commence par charger les données contenues dans le fichier enq_INS_conso_menages_2021.RDS à l’aide de la fonction readRDS() qui permet de lire les fichiers sauvegardés dans le format interne de R et on affiche les 6 premières lignes :\n\n# Importe les données au format interne de R\nbase&lt;-readRDS(\"data/ENQ-TUN-2021/enq_INS_conso_menages_2021.RDS\") \n\nhead(base)\n\n  id reg    mil   sex age     mat        ins      csp nbp   pvr  rev\n1  1  GT urbain homme  59   marie   primaire retraité   6 FALSE 5103\n2  2  GT urbain homme  52   marie   primaire  employé   5 FALSE 5486\n3  3  GT urbain femme  34 divorce secondaire  chomeur   2 FALSE 5962\n4  4  GT urbain homme  65   marie   primaire  inactif   2 FALSE 3699\n5  5  GT urbain homme  35   marie secondaire  ouvrier   4 FALSE 5058\n6  6  GT urbain homme  43   marie   primaire  ouvrier   5 FALSE 3741"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#liste-des-variables",
    "href": "MOD4_Analyse_de_variance.html#liste-des-variables",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Liste des variables",
    "text": "Liste des variables\nOn a légèrement changé le fichier initial de l’INS en simplifiant les noms des variables et en fusionnant certaines modalités. Nous avons décidé de retirer les données incomplètes pour lesquels il manque des informations telles que le sexe, l’âge ou la profession du chef de ménage. Pour cette raison les résultats obtenus seront très légèrement différents de ceux présentés sur le site de l’INS.\nLes variables proposées sont les suivantes :\n\nid : identifiant du ménage de 1 à 17114\nreg : région de résidence (GT = Grand Tunis, NE = Nord-Est, …)\nmil : milieu de résidence (urbain ou rural)\nsex : sexe du chef de ménage\nage : âge du chef de ménage\nmat : situation matrimoniale du chef de ménage (célibataire, marié, veuf, divorcé)\nins : niveau d’instruction du chef de ménage (aucune, primaire, secondaire, supérieur)\ncsp : catégorie socio-professionnelle du chef de ménage (simplifiée par rapport au fichier de l’INS)\nnbp : nombre de personnes composant le ménage\npvr : situation de pauvreté selon les critères de l’INS, c’est-à-dire en tenant compte par exemple du coût de la vie dans la région de résidence (Oui/Non)\nrev : revenu annuel moyen divisé par le nombre de personnes du ménage (en DT / an)"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#selection-du-tableau-à-analyser",
    "href": "MOD4_Analyse_de_variance.html#selection-du-tableau-à-analyser",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Selection du tableau à analyser",
    "text": "Selection du tableau à analyser\nOn suppose qu’on ne s’intéresse qu’à quelques variables\n\ndon&lt;-base[,c(\"reg\",\"mil\",\"sex\", \"ins\", \"age\",\"rev\")]\nhead(don)\n\n  reg    mil   sex        ins age  rev\n1  GT urbain homme   primaire  59 5103\n2  GT urbain homme   primaire  52 5486\n3  GT urbain femme secondaire  34 5962\n4  GT urbain homme   primaire  65 3699\n5  GT urbain homme secondaire  35 5058\n6  GT urbain homme   primaire  43 3741"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#résumé-rapide",
    "href": "MOD4_Analyse_de_variance.html#résumé-rapide",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Résumé rapide",
    "text": "Résumé rapide\nOn effectue un résumé rapide du tableau à l’aide de la fonction summary():\n\nsummary(don)\n\n reg           mil           sex                ins            age        \n GT:3944   urbain:10836   homme:13996   aucun     :3742   Min.   : 19.00  \n NE:2458   rural : 6278   femme: 3118   primaire  :6979   1st Qu.: 46.00  \n NO:2502                                secondaire:4647   Median : 56.00  \n CE:2862                                supérieur :1746   Mean   : 56.34  \n CO:2330                                                  3rd Qu.: 66.00  \n SE:1845                                                  Max.   :109.00  \n SO:1173                                                                  \n      rev        \n Min.   :   185  \n 1st Qu.:  3035  \n Median :  4429  \n Mean   :  5519  \n 3rd Qu.:  6496  \n Max.   :526271  \n                 \n\n\n\n\n\n\n\n\nAbsence de pondération\n\n\n\n\n\nPour cette enquete l’INS a utilisé la méthode de tirage au sort par région, milieu, sexe et âge qui rend l’échantillon représentatif de la population tunisienne sans qu’il soit nécessaire d’introduire une procédure de redressement. Le fait que nous ayons retiré les quelques individus pour lesquels certaines valeurs étaient manquantes ne change pas fondamentalement les résultats."
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#paramètres-principaux",
    "href": "MOD4_Analyse_de_variance.html#paramètres-principaux",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Paramètres principaux",
    "text": "Paramètres principaux\nUn résumé rapide est obtenu à l’aide de la fonction summary() que l’on complète par le calcul de l’écart-type et du coefficient de variation.\n\nres&lt;-summary(don$rev)\nect&lt;-sd(don$rev)\ncv &lt;- 100*sd(don$rev)/mean(don$rev)\nres&lt;-c(res,ect,cv)\nnames(res)&lt;-c(\"Minimum\", \"Q1\",\"Médiane\",\"Moyenne\",\"Q3\",\"Maximum\", \"Ecart-type\", \"CV (%)\")\nkable(res, digits=1, caption = \"Paramètres principaux des revenus en Tunisie\")\n\n\nParamètres principaux des revenus en Tunisie\n\n\n\nx\n\n\n\n\nMinimum\n185.0\n\n\nQ1\n3035.0\n\n\nMédiane\n4429.0\n\n\nMoyenne\n5519.4\n\n\nQ3\n6495.8\n\n\nMaximum\n526271.0\n\n\nEcart-type\n7036.7\n\n\nCV (%)\n127.5\n\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\n\nNous obtenons un revenu annuel moyen de 5519 DT ce qui est un peu plus que la valeur publiée sur le site de l’INS qui est de 5426 DT. La différence s’explique, comme nous l’avons expliqué précédemment, par le fait que nous avons retiré quelques individus ayant des valeurs manquantes.\nl’analyse des quantiles de la distribution indique que le revenu médian est de 4429 DT et que 50% des ménages ont des revenus compris entre Q1 = 3035 DT et Q3 = 6495 DT. Il existe toutefois des valeurs extrêmes puisque le minimum est de 185 DT et le maximum de 526271 DT.\nLa dispersion de la distribution des revenus est donc très forte comme en témoigne l’écart type de 7036 DT et surtout le coefficient de variation qui montre que l’écart-type est égal à 127.5% de la moyenne."
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#forme-de-la-distribution",
    "href": "MOD4_Analyse_de_variance.html#forme-de-la-distribution",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Forme de la distribution",
    "text": "Forme de la distribution\nOn devine à l’aide des résultats précédents que la distribution comporte des valeurs exceptionnelles et doit être fortement dissymétriques à gauche.\n\npar(mfrow=c(2,1))\n\nhist(don$rev, \n     main=\"Histogramme\",\n     col=\"lightyellow\",\n     xlab=\"Revenu par habitant·e (log)\")\n\nboxplot(don$rev, \n        main = \"Boîte à moustache\",\n        col=\"lightyellow\",\n        xlab =\"Revenu par habitant·e (log)\", \n        horizontal=T)\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nLa distribution est effectivemet fortement dissymétrique à gauche en raison de la présence de valeurs exceptionnelles correspondant aux individus les plus riches. L’histogramme est de ce fait totalement illisible."
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#transformation-logarithmique",
    "href": "MOD4_Analyse_de_variance.html#transformation-logarithmique",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Transformation logarithmique",
    "text": "Transformation logarithmique\nOn décide de transformer la variable en son logarithme ce qui est une pratique courante lorsqu’on analyse les revenus des ménages. On espère ainsi que la nouvelle distribution deviendra plus symétrique voire gaussienne ce qui signifierait qu’elle est log-normale.\n\ndon$logrev&lt;-log(don$rev)\n\npar(mfrow=c(2,1))\nhist(don$logrev, \n     main=\"Histogramme\",\n     col=\"lightyellow\",\n     xlab=\"Revenu par habitant·e (log)\")\n\nboxplot(don$logrev, \n        main = \"Boîte à moustache\",\n        col=\"lightyellow\",\n        xlab =\"Revenu par habitant·e (log)\", \n        horizontal=T)\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nLa distribution comporte encore des valeurs exceptionnelles à droite comme à gauche mais elle est désormais symétrique. Elle n’est donc pas véritablement log-normale car elle présente une sur-concentration des valeurs au centre. Nous n’allons cependant pas la modifier davantage et utiliser désormais le logarithme du revenu dans la suite des analyses."
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#modèle-1-le-revenu-moyen-annuel-log-est-il-différent-en-milieu-urbain-et-en-milieu-rural",
    "href": "MOD4_Analyse_de_variance.html#modèle-1-le-revenu-moyen-annuel-log-est-il-différent-en-milieu-urbain-et-en-milieu-rural",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Modèle 1 : Le revenu moyen annuel (log) est-il différent en milieu urbain et en milieu rural ?",
    "text": "Modèle 1 : Le revenu moyen annuel (log) est-il différent en milieu urbain et en milieu rural ?\nDans le cas d’une variable qualitative à deux modalités, nous pourrions utiliser un test d’égalité des moyennes comme cela a été vu dans le premier cours de statistique bivariée. Mais nous préférons utiliser ici l’analyse de variance afin de pouvoir ensuite appliquer la même méthode avec les autres variables qualitatives ayant plus de deux modalités.\n\nParamètres principaux\nOn commence par calculer les paramètres principaux des variables logrev (Y) en fonction de la variable explicative (X).\n\nY &lt;- don$logrev\nX &lt;- don$mil\n\n# création de 2 objets avec les libellés, pour les mobiliser plus facilement\nnameY &lt;- \"log. du revenu moyen (en DT/hab.)\"\nnameX &lt;- \"Milieu (Urbain/Rural)\"\n\n# calcul de la moyenne et de l'écart-type de Y selon les 2 modalités de X \nmoy&lt;-tapply(Y,X,mean)\nect&lt;- tapply(Y,X,sd)\ncv &lt;- 100*ect/moy\ntabres&lt;-rbind(moy,ect,cv)\nkable(tabres, caption = \"Paramètres princiapux du revenu moyen annuel \")\n\n\nParamètres princiapux du revenu moyen annuel\n\n\n\nurbain\nrural\n\n\n\n\nmoy\n8.5667253\n8.1360017\n\n\nect\n0.5679606\n0.5558948\n\n\ncv\n6.6298443\n6.8325299\n\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nLes deux moyennes sont visiblement différentes et les revenus (en log) plus élevés en milieu urbain (8.57) qu’en milieu rural (8.13). Mais chaque milieu présente un fort écart-type (0.57 et 0.56) de sorte qu’il est difficile d’affirmer avec certitude que la différence entre les deux moyennes est significative si on ne fait pas un test statistique.\n\n\n\n\n\nVisualisation graphique\nPour mieux apprécier la différence entre les deux distributions on réalise une boxplot permettant de comparer non seulement les moyennes mais aussi les quartiles et ainsi de mieux apprécier visuellement la différence entre les deux distributions.\n\nboxplot(Y~X,\n    col=\"lightyellow\",\n     cex.axis=0.6, \n     xlab=nameX, \n     ylab= nameY,\n    horizontal=T)\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nIl y a effectivement un net décalage entre le centre des deux distributions où se trouvent la médiane et les quartiles Q1 et Q3.\n\n\n\n\n\nModélisation linéaire\nOn réalise le modèle d’analyse de variance en utilisant le modèle linéaire général, c’est-à-dire la fonction lm() qu’on a utilisé précédemment pour mettre en relation deux variables quantitatives à l’aide de modèles de régression. Puis on résume les parts de variance intra-groupe et inter-groupe à l’aide de la fonction anova().\n\nmod&lt;-lm(Y~X)\nsummary(mod)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9156 -0.3659 -0.0118  0.3454  5.0376 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.566725   0.005414 1582.36   &lt;2e-16 ***\nXrural      -0.430724   0.008939  -48.19   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5636 on 17112 degrees of freedom\nMultiple R-squared:  0.1195,    Adjusted R-squared:  0.1194 \nF-statistic:  2322 on 1 and 17112 DF,  p-value: &lt; 2.2e-16\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: Y\n             Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX             1  737.5  737.46  2321.9 &lt; 2.2e-16 ***\nResiduals 17112 5434.9    0.32                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nInterprétation des résultats\nComme nous avons utilisé le logarithme du revenu, il faut utiliser une transformation exponentielle pour analyser correctement les coefficients. En effet on a :\n\n\\(log(rev) = a + b\\times mil\\)\n\\(rev = exp(a + b\\times mil)\\)\n\\(rev = exp(a) \\times exp(b)^{mil}\\)\n\n\nexp(mod$coefficients)\n\n (Intercept)       Xrural \n5253.8967919    0.6500385 \n\n\nDans cet exemple, les coefficients nous indiquent donc que le revenu moyen en milieu urbain est de 5254 DT/hab. (« (Intercept) »), tandis qu’il n’est que de en milieu rural. Le coefficient du modèle indique que le revenu ruar est égal à 65% de la valeur observée en milieu rural.\n\n\n\n\n\n\nMoyenne arithmétique et moyenne géométrique\n\n\n\n\n\nVous avez sans doute remarqué que les valeurs moyennes de revenu en milieu urbain et rural que nous obtenons ici ne correspondant pas à celles fournies par l’INS. La différence s’explique par le fait que nous avons travaillé sur le logarithme des revenus et non pas sur les revenus. En procédant ainsi nous avons en fait comparé la différence entre les moyennes géométriques des individus situés en milieu urbain et rural et non pas la différence entre les moyennes arithmétiques.\n\\(Moy_{arithmétique} = \\sum_{i=1}^{n}{X_i} / n\\) \\(Moy_{geométrique} = exp(\\sum_{i=1}^{n}log({X_i}) / n)\\)"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#modèle-2-le-revenu-moyen-annuel-est-il-lié-au-genre-du-chef-de-ménage",
    "href": "MOD4_Analyse_de_variance.html#modèle-2-le-revenu-moyen-annuel-est-il-lié-au-genre-du-chef-de-ménage",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Modèle 2 : Le revenu moyen annuel est-il lié au genre du chef de ménage ?",
    "text": "Modèle 2 : Le revenu moyen annuel est-il lié au genre du chef de ménage ?\nOn rassemble nos quatre petits blocs de programme en un seul et on change juste le choix de la variable explicative. Désormais c’est à vous de faire les commentaires !\n\n# Choix des variables\nY&lt;-don$logrev \nX&lt;- don$sex\nnameY &lt;-\"log. du Revenu (en DT/hab.)\"\nnameX &lt;- \"Genre du chef de ménage\"\n\n# Paramètres principaux\ntapply(Y,X,mean)\n\n   homme    femme \n8.378079 8.546267 \n\ntapply(Y,X,sd)\n\n    homme     femme \n0.5958316 0.6025676 \n\n# Visualisation\nboxplot(Y~X,\n    col=\"lightyellow\",\n     cex.axis=0.6, \n     xlab=nameX, \n     ylab= nameY,\n    horizontal=T)\n\n\n\n# Modélisation\nmod&lt;-lm(Y~X)\nsummary(mod)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1577 -0.3861 -0.0128  0.3657  4.7955 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.378079   0.005047 1660.07   &lt;2e-16 ***\nXfemme      0.168188   0.011824   14.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5971 on 17112 degrees of freedom\nMultiple R-squared:  0.01169,   Adjusted R-squared:  0.01163 \nF-statistic: 202.3 on 1 and 17112 DF,  p-value: &lt; 2.2e-16\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: Y\n             Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX             1   72.1  72.131  202.34 &lt; 2.2e-16 ***\nResiduals 17112 6100.2   0.356                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Paramètres\nexp(mod$coefficients)\n\n(Intercept)      Xfemme \n4350.643239    1.183159 \n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nQue pouvez-vous dire des résultats ?"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#modèle-3-le-revenu-des-habitantes-est-il-lié-au-niveau-dinstruction-du-chef-de-ménage",
    "href": "MOD4_Analyse_de_variance.html#modèle-3-le-revenu-des-habitantes-est-il-lié-au-niveau-dinstruction-du-chef-de-ménage",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Modèle 3 : Le revenu des habitant·es est-il lié au niveau d’instruction du chef de ménage ?",
    "text": "Modèle 3 : Le revenu des habitant·es est-il lié au niveau d’instruction du chef de ménage ?\nMême programme mais avec une variable qualitative ayant quatre niveaux.\n\n# Choix des variables\nY&lt;-don$logrev\nX&lt;- don$ins\nnameY &lt;-\"log. du Revenu (en DT/hab.)\"\nnameX &lt;- \"Instruction du chef de ménage\"\n\n# Paramètres principaux\ntapply(Y,X,mean)\n\n     aucun   primaire secondaire  supérieur \n  8.288205   8.295452   8.501042   8.874047 \n\ntapply(Y,X,sd)\n\n     aucun   primaire secondaire  supérieur \n 0.5629074  0.5562095  0.5908929  0.6076974 \n\n# Visualisation\nboxplot(Y~X,\n    col=\"lightyellow\",\n     cex.axis=0.6, \n     xlab=nameX, \n     ylab= nameY,\n    horizontal=T)\n\n\n\n# Modélisation\nmod&lt;-lm(Y~X)\nsummary(mod)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0751 -0.3714 -0.0042  0.3619  4.8854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 8.288205   0.009361 885.374   &lt;2e-16 ***\nXprimaire   0.007247   0.011603   0.625    0.532    \nXsecondaire 0.212836   0.012578  16.922   &lt;2e-16 ***\nXsupérieur  0.585841   0.016597  35.299   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5726 on 17110 degrees of freedom\nMultiple R-squared:  0.09098,   Adjusted R-squared:  0.09082 \nF-statistic: 570.8 on 3 and 17110 DF,  p-value: &lt; 2.2e-16\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: Y\n             Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX             3  561.6 187.184  570.82 &lt; 2.2e-16 ***\nResiduals 17110 5610.8   0.328                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Paramètres\nexp(mod$coefficients)\n\n(Intercept)   Xprimaire Xsecondaire  Xsupérieur \n3976.691268    1.007273    1.237182    1.796502 \n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nQue pouvez-vous dire des résultats ?"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#modèle-4-le-revenu-des-habitantes-est-il-lié-à-la-région-où-ils-se-trouvent",
    "href": "MOD4_Analyse_de_variance.html#modèle-4-le-revenu-des-habitantes-est-il-lié-à-la-région-où-ils-se-trouvent",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Modèle 4 : Le revenu des habitant·es est-il lié à la région où ils se trouvent ?",
    "text": "Modèle 4 : Le revenu des habitant·es est-il lié à la région où ils se trouvent ?\nMême programme mais avec une variable qualitative ayant cinq niveaux.\n\n# Choix des variables\nY&lt;-don$logrev\nX&lt;- don$reg\nnameY &lt;-\"log. du Revenu (en DT/hab.)\"\nnameX &lt;- \"Région\"\n\n# Paramètres principaux\ntapply(Y,X,mean)\n\n      GT       NE       NO       CE       CO       SE       SO \n8.739277 8.340811 8.231761 8.516970 8.062688 8.312937 8.390937 \n\ntapply(Y,X,sd)\n\n       GT        NE        NO        CE        CO        SE        SO \n0.5414742 0.5446345 0.5585463 0.5891304 0.5630847 0.5684727 0.5301464 \n\n# Visualisation\nboxplot(Y~X,\n    col=\"lightyellow\",\n     cex.axis=0.6, \n     xlab=nameX, \n     ylab= nameY,\n    horizontal=T)\n\n\n\n# Modélisation\nmod&lt;-lm(Y~X)\nsummary(mod)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0926 -0.3644 -0.0166  0.3462  5.1109 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.739277   0.008881  984.01   &lt;2e-16 ***\nXNE         -0.398466   0.014333  -27.80   &lt;2e-16 ***\nXNO         -0.507516   0.014255  -35.60   &lt;2e-16 ***\nXCE         -0.222307   0.013696  -16.23   &lt;2e-16 ***\nXCO         -0.676588   0.014574  -46.42   &lt;2e-16 ***\nXSE         -0.426340   0.015732  -27.10   &lt;2e-16 ***\nXSO         -0.348340   0.018550  -18.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5578 on 17107 degrees of freedom\nMultiple R-squared:  0.1378,    Adjusted R-squared:  0.1375 \nF-statistic: 455.6 on 6 and 17107 DF,  p-value: &lt; 2.2e-16\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: Y\n             Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX             6  850.5 141.743  455.63 &lt; 2.2e-16 ***\nResiduals 17107 5321.9   0.311                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Paramètres\nexp(mod$coefficients)\n\n (Intercept)          XNE          XNO          XCE          XCO          XSE \n6243.3778591    0.6713493    0.6019892    0.8006695    0.5083484    0.6528945 \n         XSO \n   0.7058590 \n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nQue pouvez-vous dire des résultats ?"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#modèle-5-le-revenu-des-habitantes-est-il-lié-à-lâge-du-chef-de-ménage",
    "href": "MOD4_Analyse_de_variance.html#modèle-5-le-revenu-des-habitantes-est-il-lié-à-lâge-du-chef-de-ménage",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Modèle 5 : Le revenu des habitant·es est-il lié à l’âge du chef de ménage ?",
    "text": "Modèle 5 : Le revenu des habitant·es est-il lié à l’âge du chef de ménage ?\nInitialement la variable âge est quantitative. On pourrait envisager de construire une régression mais rien de prouve que le revenu augmente avec l’âge.\n\nplot(don$age,don$logrev, pch=20, cex=0.2)\n\n\n\n\nOn va donc transformer la variable age en classes qui doivent être bien réfléchies car elles vont conditionner les résultats. On peut utiliser les quantiles ou bien choisir ses propres classes en fonction de la connaissance que l’on a du phénomène. Par exemple ici on va retenir , 4 classes échelonnées en intervalles de 15 ans\n\nclasses&lt;-c(min(don$age),35,50,65, max(don$age))\ndon$age4 &lt;- cut(don$age,classes)\ntable(don$age4)\n\n\n (19,35]  (35,50]  (50,65] (65,109] \n    1075     5042     6478     4517 \n\n\nOn peut alors appliquer le même programme que précédemment :\n\n# Choix des variables\nY&lt;-don$logrev\nX&lt;- don$age4\nnameY &lt;-\"log. du Revenu (en DT/hab.)\"\nnameX &lt;- \"Age du chef de ménage\"\n\n# Paramètres principaux\ntapply(Y,X,mean)\n\n (19,35]  (35,50]  (50,65] (65,109] \n8.399881 8.216320 8.455677 8.558383 \n\ntapply(Y,X,sd)\n\n  (19,35]   (35,50]   (50,65]  (65,109] \n0.6684426 0.5873870 0.5647931 0.5923722 \n\n# Visualisation\nboxplot(Y~X,\n    col=\"lightyellow\",\n     cex.axis=0.6, \n     xlab=nameX, \n     ylab= nameY,\n    horizontal=T)\n\n\n\n# Modélisation\nmod&lt;-lm(Y~X)\nsummary(mod)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0004 -0.3745 -0.0130  0.3539  4.6152 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.39988    0.01787 470.176  &lt; 2e-16 ***\nX(35,50]    -0.18356    0.01968  -9.328  &lt; 2e-16 ***\nX(50,65]     0.05580    0.01929   2.892  0.00383 ** \nX(65,109]    0.15850    0.01988   7.974 1.64e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5858 on 17108 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.04896,   Adjusted R-squared:  0.04879 \nF-statistic: 293.6 on 3 and 17108 DF,  p-value: &lt; 2.2e-16\n\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: Y\n             Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nX             3  302.2 100.729  293.58 &lt; 2.2e-16 ***\nResiduals 17108 5869.9   0.343                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Paramètres\nexp(mod$coefficients)\n\n (Intercept)     X(35,50]     X(50,65]    X(65,109] \n4446.5360045    0.8323016    1.0573829    1.1717547 \n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nQue pouvez-vous dire des résultats ?"
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#modèle-sans-interaction",
    "href": "MOD4_Analyse_de_variance.html#modèle-sans-interaction",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Modèle sans interaction",
    "text": "Modèle sans interaction\nSi on suppose que toutes les variables explicatives sont indépendantes, on peut construire un modèle décrivant la prévision du revenu en fonction de l’effet des modalités de chacune des variables.\n\nmod&lt;-lm(formula = logrev~sex+age4+ins+mil+reg, data=don)\nsummary(mod)\n\n\nCall:\nlm(formula = logrev ~ sex + age4 + ins + mil + reg, data = don)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8541 -0.3160 -0.0053  0.2974  5.1697 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    8.311428   0.021026 395.284  &lt; 2e-16 ***\nsexfemme       0.204795   0.010614  19.294  &lt; 2e-16 ***\nage4(35,50]   -0.073096   0.016830  -4.343 1.41e-05 ***\nage4(50,65]    0.201689   0.016787  12.015  &lt; 2e-16 ***\nage4(65,109]   0.354050   0.017738  19.960  &lt; 2e-16 ***\ninsprimaire    0.128949   0.011287  11.425  &lt; 2e-16 ***\ninssecondaire  0.330686   0.012744  25.948  &lt; 2e-16 ***\ninssupérieur   0.647722   0.016273  39.802  &lt; 2e-16 ***\nmilrural      -0.211446   0.008892 -23.780  &lt; 2e-16 ***\nregNE         -0.278030   0.013094 -21.234  &lt; 2e-16 ***\nregNO         -0.296649   0.013478 -22.010  &lt; 2e-16 ***\nregCE         -0.121768   0.012377  -9.838  &lt; 2e-16 ***\nregCO         -0.450201   0.013859 -32.484  &lt; 2e-16 ***\nregSE         -0.322928   0.014129 -22.856  &lt; 2e-16 ***\nregSO         -0.281712   0.016577 -16.994  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4967 on 17097 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3166,    Adjusted R-squared:  0.316 \nF-statistic: 565.7 on 14 and 17097 DF,  p-value: &lt; 2.2e-16\n\nAnova(mod,type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: logrev\n            Sum Sq    Df   F value    Pr(&gt;F)    \n(Intercept)  38551     1 156249.64 &lt; 2.2e-16 ***\nsex             92     1    372.27 &lt; 2.2e-16 ***\nage4           403     3    544.54 &lt; 2.2e-16 ***\nins            474     3    640.78 &lt; 2.2e-16 ***\nmil            140     1    565.51 &lt; 2.2e-16 ***\nreg            342     6    230.91 &lt; 2.2e-16 ***\nResiduals     4218 17097                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nComme on peut le voir, toutes les variables ont des effets significatifs toutes choses égales quant à celui des autres. Mais Le fait de procéder à une estimation simultanée entraîne des modifications des coefficients par rapport à ceux que l’on avait obtenu à l’aide des modèles simples. Ce modèle final résume 31.6% de la variance du logarithme des revenus ((« R-squared »), ce qui est un bon résultat. Mais il demeure évidemment plus de deux-tiers de variance résiduelle imputable à des facteurs non pris en compte."
  },
  {
    "objectID": "MOD4_Analyse_de_variance.html#interprétation-des-résultats-1",
    "href": "MOD4_Analyse_de_variance.html#interprétation-des-résultats-1",
    "title": "[MOD4] : Analyse de variance simple et multiple",
    "section": "Interprétation des résultats",
    "text": "Interprétation des résultats\nNous construisons un tableau final dans lequel on a indiqué pour chaque modalité le coefficient correspondant et sa transformation exponentielle.\n\nx &lt;- mod$coefficients\ntabres &lt;- data.frame(parametre=x, exp_parametre=exp(x))\nkable(tabres, digits=3)\n\n\n\n\n\nparametre\nexp_parametre\n\n\n\n\n(Intercept)\n8.311\n4070.120\n\n\nsexfemme\n0.205\n1.227\n\n\nage4(35,50]\n-0.073\n0.930\n\n\nage4(50,65]\n0.202\n1.223\n\n\nage4(65,109]\n0.354\n1.425\n\n\ninsprimaire\n0.129\n1.138\n\n\ninssecondaire\n0.331\n1.392\n\n\ninssupérieur\n0.648\n1.911\n\n\nmilrural\n-0.211\n0.809\n\n\nregNE\n-0.278\n0.757\n\n\nregNO\n-0.297\n0.743\n\n\nregCE\n-0.122\n0.885\n\n\nregCO\n-0.450\n0.638\n\n\nregSE\n-0.323\n0.724\n\n\nregSO\n-0.282\n0.754\n\n\n\n\n\n\nla ligne « (Intercept) » correspond à la situation de référence par laquelle on va calculer l’effet des différentes modalités. Il s’agit ici d’un homme (*sex*), de 19-34 ans (*age*), sans instruction (*ins*) et résidant en milieu urbain (*mil*) dans le Grand Tunis (*reg*). Son revenu par personne sera selon le modèle de 4070 DT/hab.\nles femmes chefs de ménage ont en moyenne un revenu supérieur de 27% par rapport aux autres chefs de ménage, toutes choses égales quant à leurs caractéristiques.\nle revenu varie de façon non linéaire avec l’âge. Les chefs de ménage de 35-50 ans ont en effet un niveau de revenu inférieur de -7% à celui des 19-34 ans. Par contre il est supérieur de +22% pour les 50-64 ans et de +43% pour les 65 ans et plus.\nle revenu augmente régulièrement avec le niveau d’instruction des chefs de ménage. Par rapport à un non diplômé, le revenu sera augmenté de +13.8% pour un niveau primaire, +39% pour un niveau secondaire et +91% pour un niveau supérieur.\nles ménages ruraux ont des revenus plus faibles que les ménages urbains. La différence est environ de -20% en moyenne.\nle revenu varie fortement selon les régions. Ce résultat n’est évidemment pas une surprise, mais les coefficients d’inégalités sont ici calculés toutes choses égales quant aux autres facteurs (milieu, âge, sexe, instruction) ce qui rend l’analyse plus précise. Par rapport à la région du Grand Tunis, les autres régions se classent par ordre décroissant ainsi : Centre Est (-11.5%), Nord Est (-24.3%), Sud-Ouest (-24.6%), Nord Ouest (-25.7%), Sud Est (-27.6%) et surtout Centre-Ouest (-36.2%)."
  },
  {
    "objectID": "STA2A_biv_quali_quali.html",
    "href": "STA2A_biv_quali_quali.html",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "",
    "text": "Nous allons importer un fichier de données portant sur les revenus de 17000 ménages tunisiens en 2021. Il est tiré de l’enquête consommation et revenu de l’INS dont on trouvera la description détaillée en cliquant ici\n\n\n\n\n\n\nTélécharger le jeux de données\n\n\n\n\nENQ-TUN-2021\n\n\n\n\n\nOn commence par charger les données contenues dans le fichier enq_INS_conso_menages_2021.RDS à l’aide de la fonction readRDS() qui permet de lire les fichiers sauvegardés sans le format interne de R et on affiche les 6 premières lignes\n\n# Importe les données au format interne de R\nbase&lt;-readRDS(\"data/ENQ-TUN-2021/enq_INS_conso_menages_2021.RDS\")  \n\n\n\n\nOn a légèrement changé le fichier initial de l’INS en simplifiant les noms des variables et en fusionnant certaines modalités. Les variables proposées sont les suivantes :\n\nid : identifiant du ménages de 1 à 17114\nreg : région de résidence (NE, NO, CE, CO, SE, SO + Grand Tunis)\nmil : milieu de résidence (urbain ou rural)\nsex : sexe du chef de ménage\nage : age du chef de ménage\nmat : situation matrimoniale (célbataire, marié, veuf, divorcé)\nins : instruction du chef de ménage (aucune, primaire, secondaire, supérieur)\ncsp : catégorie socio professionnelle du chef de ménage (simplifiée)\nnbp : nombre de personnes composant le ménage\npauv: situation de pauvreté selon les critères de l’INS (Oui/Non)\nrev : revenu moyen par personnes en DT / an\n\n\n\n\nOn suppose qu’on ne s’intéresse qu’à quelques variables de type qualitatif.\n\ndon&lt;-base[,c(\"reg\",\"mil\",\"sex\",\"ins\",\"pvr\")]\nhead(don)\n\n  reg    mil   sex        ins   pvr\n1  GT urbain homme   primaire FALSE\n2  GT urbain homme   primaire FALSE\n3  GT urbain femme secondaire FALSE\n4  GT urbain homme   primaire FALSE\n5  GT urbain homme secondaire FALSE\n6  GT urbain homme   primaire FALSE\n\n\n\n\n\nLa variable pvr exprime sous forme logique le fait qu’un ménage soit riche ou pauvre. Elle a été créée par l’INS en tenant compte du revenu, du nombre de personnes mais aussi de la région et du milieu rural ou urbain. Un revenu de 1000 Dt n’aura en effet pas le même effet selon qu’on habite à Tunis ou Sidi Bouzid.\nOn décide de la recoder en “Pauvre”, “Non Pauvre”.\n\n# Transforme du type logic au type factor\ndon$pvr&lt;-as.factor(don$pvr)\n\n# Examine les étiquettes\ntable(don$pvr)\n\n\nFALSE  TRUE \n14665  2449 \n\n# Change les étiquettes \nlevels(don$pvr)&lt;-c(\"Non pauvre\",\"Pauvre\")\n\n# Examine les nouvelles étiquettes\ntable(don$pvr)\n\n\nNon pauvre     Pauvre \n     14665       2449 \n\n\n\n\n\nOn effectue un résumé rapide du tableau à l’aide de la fonction summary():\n\nsummary(don)\n\n reg           mil           sex                ins               pvr       \n GT:3944   urbain:10836   homme:13996   aucun     :3742   Non pauvre:14665  \n NE:2458   rural : 6278   femme: 3118   primaire  :6979   Pauvre    : 2449  \n NO:2502                                secondaire:4647                     \n CE:2862                                supérieur :1746                     \n CO:2330                                                                    \n SE:1845                                                                    \n SO:1173"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#importation-des-données",
    "href": "STA2A_biv_quali_quali.html#importation-des-données",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "",
    "text": "On commence par charger les données contenues dans le fichier enq_INS_conso_menages_2021.RDS à l’aide de la fonction readRDS() qui permet de lire les fichiers sauvegardés sans le format interne de R et on affiche les 6 premières lignes\n\n# Importe les données au format interne de R\nbase&lt;-readRDS(\"data/ENQ-TUN-2021/enq_INS_conso_menages_2021.RDS\")"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#liste-des-variables",
    "href": "STA2A_biv_quali_quali.html#liste-des-variables",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "",
    "text": "On a légèrement changé le fichier initial de l’INS en simplifiant les noms des variables et en fusionnant certaines modalités. Les variables proposées sont les suivantes :\n\nid : identifiant du ménages de 1 à 17114\nreg : région de résidence (NE, NO, CE, CO, SE, SO + Grand Tunis)\nmil : milieu de résidence (urbain ou rural)\nsex : sexe du chef de ménage\nage : age du chef de ménage\nmat : situation matrimoniale (célbataire, marié, veuf, divorcé)\nins : instruction du chef de ménage (aucune, primaire, secondaire, supérieur)\ncsp : catégorie socio professionnelle du chef de ménage (simplifiée)\nnbp : nombre de personnes composant le ménage\npauv: situation de pauvreté selon les critères de l’INS (Oui/Non)\nrev : revenu moyen par personnes en DT / an"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#selection-du-tableau-à-analyser",
    "href": "STA2A_biv_quali_quali.html#selection-du-tableau-à-analyser",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "",
    "text": "On suppose qu’on ne s’intéresse qu’à quelques variables de type qualitatif.\n\ndon&lt;-base[,c(\"reg\",\"mil\",\"sex\",\"ins\",\"pvr\")]\nhead(don)\n\n  reg    mil   sex        ins   pvr\n1  GT urbain homme   primaire FALSE\n2  GT urbain homme   primaire FALSE\n3  GT urbain femme secondaire FALSE\n4  GT urbain homme   primaire FALSE\n5  GT urbain homme secondaire FALSE\n6  GT urbain homme   primaire FALSE"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#recodage-de-la-variable-pvr",
    "href": "STA2A_biv_quali_quali.html#recodage-de-la-variable-pvr",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "",
    "text": "La variable pvr exprime sous forme logique le fait qu’un ménage soit riche ou pauvre. Elle a été créée par l’INS en tenant compte du revenu, du nombre de personnes mais aussi de la région et du milieu rural ou urbain. Un revenu de 1000 Dt n’aura en effet pas le même effet selon qu’on habite à Tunis ou Sidi Bouzid.\nOn décide de la recoder en “Pauvre”, “Non Pauvre”.\n\n# Transforme du type logic au type factor\ndon$pvr&lt;-as.factor(don$pvr)\n\n# Examine les étiquettes\ntable(don$pvr)\n\n\nFALSE  TRUE \n14665  2449 \n\n# Change les étiquettes \nlevels(don$pvr)&lt;-c(\"Non pauvre\",\"Pauvre\")\n\n# Examine les nouvelles étiquettes\ntable(don$pvr)\n\n\nNon pauvre     Pauvre \n     14665       2449"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#résumé-rapide",
    "href": "STA2A_biv_quali_quali.html#résumé-rapide",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "",
    "text": "On effectue un résumé rapide du tableau à l’aide de la fonction summary():\n\nsummary(don)\n\n reg           mil           sex                ins               pvr       \n GT:3944   urbain:10836   homme:13996   aucun     :3742   Non pauvre:14665  \n NE:2458   rural : 6278   femme: 3118   primaire  :6979   Pauvre    : 2449  \n NO:2502                                secondaire:4647                     \n CE:2862                                supérieur :1746                     \n CO:2330                                                                    \n SE:1845                                                                    \n SO:1173"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#création",
    "href": "STA2A_biv_quali_quali.html#création",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Création",
    "text": "Création\nLe coeur du travail d’analyse du questionnaire est la réalisation de tris croisés c’est-à-dire de tableaux de contingence croisant les réponses à deux questions (X et Y). Prenons comme exemple la pauvreté du ménage (pvr) définie par l’INS comme une variable binaire (Y) et le niveau d’instruction (ins) du chef de ménage (X) en quatre classes.\n\ntableau de contingence\n\nX&lt;-don$ins\nY&lt;-don$pvr\ntab&lt;-table(X,Y)\naddmargins(tab)\n\n            Y\nX            Non pauvre Pauvre   Sum\n  aucun            3098    644  3742\n  primaire         5755   1224  6979\n  secondaire       4145    502  4647\n  supérieur        1667     79  1746\n  Sum             14665   2449 17114\n\n\nExemple de lecture : 644 ménages ont un chef sans diplôme et sont pauvres."
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#pourcentage-en-ligne",
    "href": "STA2A_biv_quali_quali.html#pourcentage-en-ligne",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Pourcentage en ligne",
    "text": "Pourcentage en ligne\nLe tableau de contingence permet de produire différents tableaux de pourcentage.\n\nlprop(tab)\n\n            Y\nX            Non pauvre Pauvre Total\n  aucun       82.8       17.2  100.0\n  primaire    82.5       17.5  100.0\n  secondaire  89.2       10.8  100.0\n  supérieur   95.5        4.5  100.0\n  All         85.7       14.3  100.0\n\n\nExemple de lecture : 17.2% des ménages dont le chef n’a pas de diplôme sont pauvres"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#pourcentage-en-colonnes",
    "href": "STA2A_biv_quali_quali.html#pourcentage-en-colonnes",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "pourcentage en colonnes",
    "text": "pourcentage en colonnes\nLe tableau de contingence permet de produire différents tableaux de pourcentage.\n\ncprop(tab)\n\n            Y\nX            Non pauvre Pauvre All  \n  aucun       21.1       26.3   21.9\n  primaire    39.2       50.0   40.8\n  secondaire  28.3       20.5   27.2\n  supérieur   11.4        3.2   10.2\n  Total      100.0      100.0  100.0\n\n\nExemple de lecture : 26.3% des ménages pauvres ont pour chef une personne non diplômée"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#pourcentage-du-total",
    "href": "STA2A_biv_quali_quali.html#pourcentage-du-total",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "pourcentage du total",
    "text": "pourcentage du total\n\nprop(tab)\n\n            Y\nX            Non pauvre Pauvre Total\n  aucun       18.1        3.8   21.9\n  primaire    33.6        7.2   40.8\n  secondaire  24.2        2.9   27.2\n  supérieur    9.7        0.5   10.2\n  Total       85.7       14.3  100.0\n\n\nExemple de lecture : 3.8% des ménages sont pauvres et ont pour chef une personne non diplômée"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#utilisation-de-mosaicplot",
    "href": "STA2A_biv_quali_quali.html#utilisation-de-mosaicplot",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Utilisation de mosaicplot",
    "text": "Utilisation de mosaicplot\nIl est facile de visualiser un tableau de contingence avec mosaicplot()\n\nmosaicplot(tab)\n\n\n\n\nCette figure est très pratique car elle montre à la fois l’effectif des ménages par diplôme (largeur de la barre) et la proportion de ménages pauvres (hauteur à laquelle la barre est coupée)"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#figure-améliorée",
    "href": "STA2A_biv_quali_quali.html#figure-améliorée",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "figure améliorée",
    "text": "figure améliorée\nOn peut ensuite améliorer le figure\n\nmosaicplot(tab,\n           xlab = \"Diplôme du chef de ménage\",\n           ylab = \"Pauvreté\",\n           main = \"Relation entre diplome et pauvreté en Tunisie en 2021\",\n           sub = \"Source : INS, 2021\",\n           col=c(\"lightyellow\", \"orange\"))"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#hypothèse-de-recherche",
    "href": "STA2A_biv_quali_quali.html#hypothèse-de-recherche",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Hypothèse de recherche",
    "text": "Hypothèse de recherche\nOn remarque qu’il semble exister un lien entre le niveau de diplôme du chef de ménage. Cette relation semble négative puisque les ménages les moins instruits sont ceux qui sont le plus souvent pauvre. On a donc envie d’affirmer l’hypothèse de recherche H1 :\nH1: Dans le cas de la population tunisienne en 2021, il existe un lien entre le niveau de diplôme du chef de ménage (X) et la situation de pauvreté (Y).\nEn statistique, on ne teste jamais directement l’hypothèse H1 (il y a une relation entre X et Y) mais on teste l’hypothèse inverse (il n’y a pas de relation entre X et Y) qu’on appelle hypothèse nulle."
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#hypothèse-nulle",
    "href": "STA2A_biv_quali_quali.html#hypothèse-nulle",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Hypothèse nulle",
    "text": "Hypothèse nulle\nPourquoi cette complication apparente ?\n\nParce que l’hypothèse nulle est plus rigoureuse et revient à se demander si ce n’est pas le hasard qui explique les différence de pourcentage observées. Dans notre exemple on va donc poser :\n\nH0 : Il n’y a pas de relation entre le niveau de diplôme (X) et le fait d’être pauvre (Y). Les différences de pourcentage que nous avons mises en évidence peuvent très bien être l’effet du hasard."
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#la-fonction-chisq.test",
    "href": "STA2A_biv_quali_quali.html#la-fonction-chisq.test",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "La fonction chisq.test()",
    "text": "La fonction chisq.test()\nCette fonction très puissance s’applique à un tableau de contingence créé avec la fonction table(). Elle renvoie un gros objet que l’on va stocker pour en extraire les résultats dont on a besoin. On peut choisir le nom de l’objet dans lequel seront stockés les résultats. Ici je vais choisir le nom resul mais j’aurais aussi bien pu l’appeler toto ou titi.\n\nresul&lt;-chisq.test(tab)\nclass(resul)\n\n[1] \"htest\"\n\n\nL’instruction class() nousindique que l’objet a un type spécial appelé htest. Il s’agit en fait d’une liste de résultats, comme un gros sac de course remplis de fruits, légumes, pain, etc.\nQu’y a-t-il dans l’objet resul ?\n\nstr(resul)\n\nList of 9\n $ statistic: Named num 268\n  ..- attr(*, \"names\")= chr \"X-squared\"\n $ parameter: Named int 3\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value  : num 8.6e-58\n $ method   : chr \"Pearson's Chi-squared test\"\n $ data.name: chr \"tab\"\n $ observed : 'table' int [1:4, 1:2] 3098 5755 4145 1667 644 1224 502 79\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ X: chr [1:4] \"aucun\" \"primaire\" \"secondaire\" \"supérieur\"\n  .. ..$ Y: chr [1:2] \"Non pauvre\" \"Pauvre\"\n $ expected : num [1:4, 1:2] 3207 5980 3982 1496 535 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ X: chr [1:4] \"aucun\" \"primaire\" \"secondaire\" \"supérieur\"\n  .. ..$ Y: chr [1:2] \"Non pauvre\" \"Pauvre\"\n $ residuals: 'table' num [1:4, 1:2] -1.92 -2.91 2.58 4.42 4.69 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ X: chr [1:4] \"aucun\" \"primaire\" \"secondaire\" \"supérieur\"\n  .. ..$ Y: chr [1:2] \"Non pauvre\" \"Pauvre\"\n $ stdres   : 'table' num [1:4, 1:2] -5.73 -10.01 8 12.32 5.73 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ X: chr [1:4] \"aucun\" \"primaire\" \"secondaire\" \"supérieur\"\n  .. ..$ Y: chr [1:2] \"Non pauvre\" \"Pauvre\"\n - attr(*, \"class\")= chr \"htest\"\n\n\nPlein de choses …"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#distribution-observée",
    "href": "STA2A_biv_quali_quali.html#distribution-observée",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Distribution observée",
    "text": "Distribution observée\nOn retrouve dans l’objet resul notre tableau de contingence initial\n\nNij = effectifs observés\n\ntabobs &lt;- resul$observed\naddmargins(tabobs)\n\n            Y\nX            Non pauvre Pauvre   Sum\n  aucun            3098    644  3742\n  primaire         5755   1224  6979\n  secondaire       4145    502  4647\n  supérieur        1667     79  1746\n  Sum             14665   2449 17114"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#distribution-théorique",
    "href": "STA2A_biv_quali_quali.html#distribution-théorique",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Distribution théorique",
    "text": "Distribution théorique\nAfin de voir si le hasard est effectivement intervenu, on va reconstituer ce que serait le tableau de contingence croisant X et Y dans le cas où les deux variables ne sont pas reliées. On extrait cette information de l’objet resul la partie appelée expected.\n\nTij = (Ni. x N.j)/N..\n\ntabtheo &lt;- resul$expected\nround(addmargins(tabtheo),1)\n\n            Y\nX            Non pauvre Pauvre   Sum\n  aucun          3206.5  535.5  3742\n  primaire       5980.3  998.7  6979\n  secondaire     3982.0  665.0  4647\n  supérieur      1496.1  249.9  1746\n  Sum           14665.0 2449.0 17114"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#résidus",
    "href": "STA2A_biv_quali_quali.html#résidus",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Résidus",
    "text": "Résidus\nOn va ensuite mesurer les écarts entre effectifs observés et théoriques appelés résidus (Nij-Tij).\n\nRésidus (Nij-Tij)\n\ntabresid &lt;- tabobs-tabtheo\nround(addmargins(tabresid),1)\n\n            Y\nX            Non pauvre Pauvre    Sum\n  aucun          -108.5  108.5    0.0\n  primaire       -225.3  225.3    0.0\n  secondaire      163.0 -163.0    0.0\n  supérieur       170.9 -170.9    0.0\n  Sum               0.0    0.0    0.0"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#chi-2",
    "href": "STA2A_biv_quali_quali.html#chi-2",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Chi-2",
    "text": "Chi-2\nOn va ensuite exprimer les écartes entre effectifs observés et estimés sous une forme mathématique appelée chi2 définie par la formule (Nij-Tij)x(Nij-Tij)/Tij. Ce résultat n’est pas fourni mais on peut le calculer :\n\nChi-2 = (Nij-Tij)x(Nij-Tij)/Tij\n\ntabchi2&lt;-(tabobs-tabtheo)**2 / tabtheo\nround(addmargins(tabchi2),1)\n\n            Y\nX            Non pauvre Pauvre   Sum\n  aucun             3.7   22.0  25.7\n  primaire          8.5   50.8  59.3\n  secondaire        6.7   39.9  46.6\n  supérieur        19.5  116.8 136.3\n  Sum              38.3  229.6 267.9\n\n\nCe qui nous intéresse c’est la somme du chi2 de toutes les cases qui mesure la différence entre les distributions observées et théoriques. Plus le chi2 total est grand, plus il y a de chance qu’il existe une relation entre X et Y."
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#test-du-chi-2-1",
    "href": "STA2A_biv_quali_quali.html#test-du-chi-2-1",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "test du chi-2",
    "text": "test du chi-2\nOn peut calculer beaucoup plus rapidement le chi-2 total d’un tableau et sa significativité en utilisant la fonction chisq.test() sans la stocker :\n\nchisq.test(tab)\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 267.94, df = 3, p-value &lt; 2.2e-16\n\n\nOn obtient directement la valeur du chi-2 du tableau (X-squared = 267.94) ainsi que le nombre de degrés de libertés (df = 3) et la significativité de la relation (p-value &lt; 2.2e-16)"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#interprétation-du-résultat-du-test",
    "href": "STA2A_biv_quali_quali.html#interprétation-du-résultat-du-test",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Interprétation du résultat du test",
    "text": "Interprétation du résultat du test\nLe chi-2 total du tableau (267.9) sera d’autant plus élevé que la distribution observée s’éloigne de la distribution théorique. Plus le chi-2 augmente, moins il y a de chance que le hasard explique les différences entre valeurs observées et estimées. On peut alors faire un test pour connaître la probabilité que le chi-2 observé soit l’effet du hasard.\n\nle tableau possède 3 degré de liberté = (lignes - 1) x (colonnes - 1)\nle tableau possède un chi-2 égal à 267.9\nUn calcul effectué par un logiciel de statistique montre que la probabilité que cette valeur soit l’effet du hasard (p-value) est presque nulle p &lt;0.0001\n\nOn va donc rejeter H0 et accepter H1\nConclusion : On peut affirmer sans grand risque d’erreur (1 chance sur 10 000) qu’en Tunisie en 2021 il existe une relation significative entre le niveau de diplôme du chef de ménage et la situation de pauvreté"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#seuils-de-décision",
    "href": "STA2A_biv_quali_quali.html#seuils-de-décision",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Seuils de décision",
    "text": "Seuils de décision\nDans l’exemple précédent, nous sommes tombé sur une relation très significative. Mais ce n’est pas toujours le cas. Pour fixer les ordres de grandeur, voici un tableau simple à retenir :\n\n\n\n\n\nTest..p.value.\nInterprétation\ncode\n\n\n\n\n&gt; 0.10\nNon significatif\nn.s\n\n\n0.05 à 0.10\nPresque significatif\n.\n\n\n0.01 à 0.05\nlégèrement significatif\n*\n\n\n0.001 à 0.01\nsignificatif\n**\n\n\n0.001 &lt;\ntrès significatif\n***\n\n\n\n\n\nLa taille de l’échantillon influence beaucoup le résultat du test du chi-2. Plus l’échantillon est grand, plus on a de chances de rejeter H0. ici nous avions 17000 personnes ce qui est considérable pourune enquête.\nMais qu’aurions nous observée si nous n’avions eu que 50, 100 ou 200 personnes ?"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#taille-de-léchantillon-n50",
    "href": "STA2A_biv_quali_quali.html#taille-de-léchantillon-n50",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Taille de l’échantillon (n=50)",
    "text": "Taille de l’échantillon (n=50)\n\n\n\n\n\nEffectif\n\n\n\nNon pauvre\nPauvre\nSum\n\n\n\n\naucun\n8\n1\n9\n\n\nprimaire\n21\n3\n24\n\n\nsecondaire\n13\n0\n13\n\n\nsupérieur\n4\n0\n4\n\n\nSum\n46\n4\n50\n\n\n\n\n\n\n% en ligne\n\n\n\nNon pauvre\nPauvre\nTotal\n\n\n\n\naucun\n88.9\n11.1\n100\n\n\nprimaire\n87.5\n12.5\n100\n\n\nsecondaire\n100.0\n0.0\n100\n\n\nsupérieur\n100.0\n0.0\n100\n\n\nAll\n92.0\n8.0\n100\n\n\n\n\n\n\n\n\n\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 2.2569, df = 3, p-value = 0.5208"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#taille-de-léchantillon-n100",
    "href": "STA2A_biv_quali_quali.html#taille-de-léchantillon-n100",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Taille de l’échantillon (n=100)",
    "text": "Taille de l’échantillon (n=100)\n\n\n\n\n\nEffectif\n\n\n\nNon pauvre\nPauvre\nSum\n\n\n\n\naucun\n17\n4\n21\n\n\nprimaire\n35\n6\n41\n\n\nsecondaire\n28\n1\n29\n\n\nsupérieur\n8\n1\n9\n\n\nSum\n88\n12\n100\n\n\n\n\n\n\n% en ligne\n\n\n\nNon pauvre\nPauvre\nTotal\n\n\n\n\naucun\n81.0\n19.0\n100\n\n\nprimaire\n85.4\n14.6\n100\n\n\nsecondaire\n96.6\n3.4\n100\n\n\nsupérieur\n88.9\n11.1\n100\n\n\nAll\n88.0\n12.0\n100\n\n\n\n\n\n\n\n\n\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 3.2722, df = 3, p-value = 0.3515"
  },
  {
    "objectID": "STA2A_biv_quali_quali.html#taille-de-léchantillon-n200",
    "href": "STA2A_biv_quali_quali.html#taille-de-léchantillon-n200",
    "title": "[STA2A] : Statistique bivariée : X et Y qualitatives",
    "section": "Taille de l’échantillon (n=200)",
    "text": "Taille de l’échantillon (n=200)\n\n\n\n\n\nEffectif\n\n\n\nNon pauvre\nPauvre\nSum\n\n\n\n\naucun\n29\n9\n38\n\n\nprimaire\n77\n15\n92\n\n\nsecondaire\n48\n4\n52\n\n\nsupérieur\n15\n3\n18\n\n\nSum\n169\n31\n200\n\n\n\n\n\n\n% en ligne\n\n\n\nNon pauvre\nPauvre\nTotal\n\n\n\n\naucun\n76.3\n23.7\n100\n\n\nprimaire\n83.7\n16.3\n100\n\n\nsecondaire\n92.3\n7.7\n100\n\n\nsupérieur\n83.3\n16.7\n100\n\n\nAll\n84.5\n15.5\n100\n\n\n\n\n\n\n\n\n\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 4.4277, df = 3, p-value = 0.2188"
  },
  {
    "objectID": "STA3_multivariee.html",
    "href": "STA3_multivariee.html",
    "title": "[STA3] : Introduction à la statistique multivariée",
    "section": "",
    "text": "## Packages utilitaire\nlibrary(knitr)\nlibrary(dplyr,quiet=T)\n\n### Package d'analyse des données\nlibrary(FactoMineR)\n\n### Packages de cartographie\nlibrary(sf, quietly-TRUE)\nlibrary(mapsf)\nlibrary(RColorBrewer)\n\n\n## Options du document\noptions(max.print=\"80\")\nopts_chunk$set(echo=TRUE,\n               cache=FALSE,\n               prompt=FALSE,\n               tidy=FALSE,\n               comment=NA,\n               message=FALSE,\n               warning=FALSE,\n               options(scipen=999))\nopts_knit$set(width=75)"
  },
  {
    "objectID": "STA3_multivariee.html#a-preparation-des-donnees",
    "href": "STA3_multivariee.html#a-preparation-des-donnees",
    "title": "[STA3] : Introduction à la statistique multivariée",
    "section": "(A) PREPARATION DES DONNEES",
    "text": "(A) PREPARATION DES DONNEES\nOn peut préparer les données à partir du dossier RP-Tunisie. Mais on peut aussipasser cette partie et démarrer si on le souhaite directement à la partie suivante dès lors que les fichiers ont été créés dans le dossier EXPLO.\n\n\n\n\n\n\nTélécharger les jeux de données\n\n\n\n\nRP-Tunisie\nEXPLO\n\n\n\n\nImporte les données statistiques\n\n# Importation du fichier .csv\ndon &lt;- read.table(\"data/RP_Tunisie/data/don_gou.csv\", \n                  header = TRUE,   # Il y a un en-tête\n                  sep = \";\",       # le séparateur est ;\n                  encoding = \"UTF-8\"  # Encodage pour français et arabe\n                  )\n\n\n# Création ou recodage des variables\ncode&lt;-don$gou_code\nnom&lt;-don$gou_nom\npopto &lt;- don$popto_2004\nmenag &lt;- don$menag_2004\ntailm &lt;- don$popto_2004/don$menag_2004\ndensi &lt;- don$popto_2004/don$surfa_2010\n#urban &lt;- 100*don$popco_2004/don$popto_2004\nmobil &lt;- 100*(don$immig_2004+don$emigr_2004)/don$popto_2004\nacmig &lt;- 100*(don$immig_2004-don$emigr_2004)/don$popto_2004\nordin &lt;- 100*don$ordin_2004/don$menag_2004\nporta &lt;- 100*don$porta_2004/don$menag_2004\n\n# Affichage\ntab&lt;-data.frame(code,nom, popto,menag, tailm, densi,mobil, acmig, ordin, porta)\nkable(tab, \n      digits = c(0,0,0,0,2,1,1,1,1,1), # decimales par colonnes\n      caption = \"Tableau de données 2004\"   # Titre du tableau\n      )\n\n# Sauvegarde aux formats .RDS et .csv\nsaveRDS(tab, \"data/EXPLO/don2004.RDS\") # sauvegarde au format interne de R\n\nwrite.table(tab, \"data/EXPLO/don2004.csv\",\n            sep=\";\", \n            row.names=F,\n            fileEncoding = \"UTF-8\")\n\n# Importation du shapefile des gouvernorats à l'aide de sf\nmap&lt;-sf::st_read(\"data/RP_Tunisie/geom/map_gou.shp\")\n\n\n# Jointure des données statistiques et géométriques\nmap&lt;- merge(map, tab, by.x=\"gou_code\",by.y=\"code\")\n\n# Sauvegarde aux formats .RDS .shp et  .geojson\n\nsaveRDS(map, \"data/EXPLO/map2004.RDS\") ## Format interne de R\n\nsf::st_write(map, \"data/EXPLO/map2004.geojson\",delete_dsn = T)  ## Format geojson\n\nsf::st_write(map, \"data/EXPLO/map2004.shp\",delete_dsn = T)"
  },
  {
    "objectID": "STA3_multivariee.html#exploration-univariee",
    "href": "STA3_multivariee.html#exploration-univariee",
    "title": "[STA3] : Introduction à la statistique multivariée",
    "section": "(2) EXPLORATION UNIVARIEE",
    "text": "(2) EXPLORATION UNIVARIEE\nAvant de procéder à une ACP, on effectue un certain nombre d’analyse sur les variables qui seront utilisées. On prend ici l’exemple des données de 2004.\n\ndon&lt;-readRDS(\"data/EXPLO/don2004.RDS\") # recharge le fichier\nhead(don,3)  # Affiche les 3 premières lignes\n\n  code       nom  popto  menag    tailm      densi    mobil     acmig     ordin\n1   AN    Ariana 422246 101327 4.167162 1017.07792 21.84982  8.974863 16.324376\n2   BA Ben Arous 505773 117901 4.289811  769.97310 24.05644  7.303474 13.018549\n3   BJ      Beja 304501  68584 4.439826   81.41738 10.56384 -3.153027  3.235449\n     porta\n1 59.31193\n2 60.50415\n3 32.18681\n\ntail(don,3)  # Affiche les 3 dernières lignes\n\n   code      nom  popto  menag    tailm      densi     mobil      acmig\n22   TO   Tozeur  97526  20485 4.760849   17.43747 10.393126 -0.6008654\n23   TU    Tunis 983861 244018 4.031920 4064.26494 26.375474 -2.7646182\n24   ZA Zaghouan 160963  33532 4.800280   56.14531  9.408995 -0.4876897\n       ordin    porta\n22  5.042714 43.56358\n23 14.012901 60.46972\n24  2.701897 37.94286\n\n\n\nExploration statistique\nOn regarde pour chaque variable retenue la forme de sa distribution afin de procéder éventuellement à des transformations si celle-ci est trop éloignée d’une forme gaussienne.\n\nTaille moyenne des ménages (tailm)\n\nX&lt;-don$tailm\n\n# résumé statistique\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  4.032   4.371   4.754   4.682   4.912   5.401 \n\n# graphique en R-base\nhist(X)\n\n\n\nboxplot(X, horizontal=T)\n\n\n\n\n\n\nDensité de population (densi)\n\nX&lt;-don$densi\nsummary(X)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   3.691   49.421   82.123  342.739  241.184 4064.265 \n\nhist(X)\n\n\n\nboxplot(X, horizontal=T)\n\n\n\n\nOn essaye une transformation logarithmique\n\nX&lt;-log(don$densi)\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.306   3.900   4.408   4.598   5.486   8.310 \n\nhist(X)\n\n\n\nboxplot(X, horizontal=T)\n\n\n\n\nC’est mieux !\n\n\nTaux de mobilité (mobil)\n\nX&lt;-don$mobil\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.351   9.831  11.209  13.128  14.652  26.375 \n\nhist(X)\n\n\n\nboxplot(X, horizontal=T)\n\n\n\n\n\n\nTaux d’accroissement migratoire (acmig)\n\nX&lt;-don$acmig\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-4.9969 -2.8617 -0.6699 -0.3281  1.0955  8.9749 \n\nhist(X)\n\n\n\nboxplot(X, horizontal=T)\n\n\n\n\n\n\nTaux d’équipement des ménages en téléphones mobiles (mobil)\n\nX&lt;-don$mobil\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.351   9.831  11.209  13.128  14.652  26.375 \n\nhist(X)\n\n\n\nboxplot(X, horizontal=T)\n\n\n\n\n\n\nTaux d’équipement des ménages en ordinateur (ordin)\n\nX&lt;-don$ordin\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.243   2.957   4.835   5.720   7.050  16.324 \n\nhist(X)\n\n\n\nboxplot(X, horizontal=T)\n\n\n\n\n\n\n\nExploration cartographique\nOn procède à une cartographie rapide des six variables sous forme de planches utilisant la même méthode de discrétisation (quartiles)\n\n# Charge le fichier stat + geom\nmap&lt;-readRDS(\"data/EXPLO/map2004.RDS\")\n\n\nDonnées structurelles\nOn compare ici la taille moyenne des ménages et la densité de population\n\n# Définit un cadre avec deux cartes côte à côte\npar(mfrow=c(1,2)) # une ligne et deux colonnes\n\n# Carte n°1\nmf_map(x = map, \n       type = \"choro\",\n       var=\"tailm\",\n       breaks = \"quantile\",\n       nbreaks=4, \n       leg_title = \"quartiles\")\nmf_layout(title = \"Taille moyenne des ménages\", \n          credits = \"Source : INS\",\n          frame=T)\n\n# Carte n°2 \nmf_map(x = map, type = \"choro\",var=\"densi\",\n       breaks = \"quantile\",nbreaks=4, leg_title = \"quartiles\")\nmf_layout(title = \"Densité de population\", \n          credits = \"Source : INS\",\n          frame=T)\n\n\n\n\n\n\nDonnées démographiques\nOn compare ici le taux de mobilité et le taux d’accroissement migratoire\n\n# Définit un cadre avec deux cartes côte à côte\npar(mfrow=c(1,2))\n\n# Carte n°1\nmf_map(x = map,\n       type = \"choro\",\n       var=\"mobil\",\n       breaks = \"quantile\",\n       nbreaks=4, \n       leg_title = \"quartiles\")\nmf_layout(title = \"Taux de mobilité\", \n          credits = \"Source : INS\",\n          frame=T)\n\n# Carte n°2 \nmf_map(x = map, \n       type = \"choro\",\n       var=\"acmig\",\n       breaks = \"quantile\",\n       nbreaks=4, \n       leg_title = \"quartiles\")\nmf_layout(title = \"Taux d'accroissement migratoire\", \n          credits = \"Source : INS\",\n          frame=T)\n\n\n\n\n\n\nDonnées d’équipement\nOn compare ici le taux d’équipement des ménages en ordinateur et téléphones portables\n\n# Définit un cadre avec deux cartes côte à côte\npar(mfrow=c(1,2))\n\n# Carte n°1\nmf_map(x = map, type = \"choro\",var=\"porta\",\n       breaks = \"quantile\",nbreaks=4, leg_title = \"quartiles\")\nmf_layout(title = \"Equipement en téléphones portables\", \n          credits = \"Source : INS\",\n          frame=T)\n\n# Carte n°2 \nmf_map(x = map, type = \"choro\",var=\"ordin\",\n       breaks = \"quantile\",nbreaks=4, leg_title = \"quartiles\")\nmf_layout(title = \"Equipement en ordinateurs\", \n          credits = \"Source : INS\",\n          frame=T)"
  },
  {
    "objectID": "STA3_multivariee.html#analyse-en-composantes-principales-acp",
    "href": "STA3_multivariee.html#analyse-en-composantes-principales-acp",
    "title": "[STA3] : Introduction à la statistique multivariée",
    "section": "(3) ANALYSE EN COMPOSANTES PRINCIPALES (ACP)",
    "text": "(3) ANALYSE EN COMPOSANTES PRINCIPALES (ACP)\nAu vu de l’exploration statistique, on décide de transformer la densité de population en logarithme. Le reste des variables demeure inchangé. On choisit comme précédemment l’exemple de la situation en 2004.\n\nTableau brut\nOn constitue un tableau ne gardant que les 6 variables utiles. On ajoute en nom de lignes le code des gouvernorats\n\ndon&lt;-readRDS(\"data/EXPLO/don2004.RDS\")\n\n# transforme la densité\ndon$logden&lt;-log(don$densi) \n\n# choisit les variables\ntab&lt;-don[,c(\"tailm\", \"logden\",\"mobil\", \"acmig\", \"ordin\",\"porta\")]   \n\n# Ajoute un identifiant en numéro de ligne\nrow.names(tab) &lt;- don$code\n\n# Affiche le tableau\nkable(tab, digits=2, caption = \"Tableau brut\")\n\n\nTableau brut\n\n\n\ntailm\nlogden\nmobil\nacmig\nordin\nporta\n\n\n\n\nAN\n4.17\n6.92\n21.85\n8.97\n16.32\n59.31\n\n\nBA\n4.29\n6.65\n24.06\n7.30\n13.02\n60.50\n\n\nBJ\n4.44\n4.40\n10.56\n-3.15\n3.24\n32.19\n\n\nBZ\n4.37\n5.01\n9.85\n-0.54\n4.98\n38.72\n\n\nGB\n4.92\n3.87\n14.71\n-0.69\n6.00\n46.11\n\n\nGF\n4.91\n3.72\n11.22\n-2.40\n6.81\n43.60\n\n\nJE\n4.49\n4.90\n10.11\n-2.38\n2.50\n32.93\n\n\nKB\n5.39\n1.85\n9.99\n-1.20\n3.38\n50.70\n\n\nKF\n4.38\n3.93\n13.73\n-4.31\n3.04\n33.02\n\n\nKR\n5.06\n4.42\n9.78\n-4.21\n1.72\n29.51\n\n\nKS\n5.19\n3.91\n9.73\n-4.10\n1.60\n31.19\n\n\nME\n4.81\n3.85\n11.87\n0.62\n4.69\n49.46\n\n\nMH\n4.77\n4.88\n7.35\n-0.65\n3.32\n42.78\n\n\nMN\n4.75\n5.71\n14.63\n2.89\n6.61\n43.52\n\n\nMS\n4.51\n6.13\n11.19\n3.72\n7.81\n56.02\n\n\nNB\n4.27\n5.50\n9.22\n1.02\n6.10\n46.51\n\n\nSF\n4.31\n4.81\n16.89\n1.33\n7.77\n47.60\n\n\nSL\n4.83\n3.92\n12.32\n-5.00\n2.25\n32.68\n\n\nSS\n4.37\n5.48\n17.58\n4.02\n9.62\n56.75\n\n\nSZ\n5.15\n3.98\n8.73\n-3.55\n1.24\n36.69\n\n\nTA\n5.40\n1.31\n13.52\n-1.71\n3.48\n45.79\n\n\nTO\n4.76\n2.86\n10.39\n-0.60\n5.04\n43.56\n\n\nTU\n4.03\n8.31\n26.38\n-2.76\n14.01\n60.47\n\n\nZA\n4.80\n4.03\n9.41\n-0.49\n2.70\n37.94\n\n\n\n\n\n\n\nStandardisation\nL’ACP normée va travailler non pas sur le tableau brut mais sur le tableau standardisé afin que les variables soient comparables. Pour éliminer les effets de taille et d’unité de mesure. Chaque variable aura alors le même poids.\n\n# applique la standardiation à chaque variable (2)\ntabstd &lt;- apply(tab,2, scale) \n\n# Ajoute les identifiants des unités \nrow.names(tabstd)&lt;-don$code\n\n#Affiche le tableau\nkable(tabstd, \n      digits=1,\n      caption=\"Tableau standardisé\")\n\n\nTableau standardisé\n\n\n\ntailm\nlogden\nmobil\nacmig\nordin\nporta\n\n\n\n\nAN\n-1.3\n1.5\n1.8\n2.6\n2.6\n1.6\n\n\nBA\n-1.0\n1.3\n2.2\n2.1\n1.8\n1.7\n\n\nBJ\n-0.6\n-0.1\n-0.5\n-0.8\n-0.6\n-1.2\n\n\nBZ\n-0.8\n0.3\n-0.7\n-0.1\n-0.2\n-0.5\n\n\nGB\n0.6\n-0.5\n0.3\n-0.1\n0.1\n0.2\n\n\nGF\n0.6\n-0.6\n-0.4\n-0.6\n0.3\n0.0\n\n\nJE\n-0.5\n0.2\n-0.6\n-0.6\n-0.8\n-1.1\n\n\nKB\n1.9\n-1.8\n-0.6\n-0.2\n-0.6\n0.7\n\n\nKF\n-0.8\n-0.4\n0.1\n-1.1\n-0.7\n-1.1\n\n\nKR\n1.0\n-0.1\n-0.7\n-1.1\n-1.0\n-1.5\n\n\nKS\n1.3\n-0.4\n-0.7\n-1.0\n-1.0\n-1.3\n\n\nME\n0.3\n-0.5\n-0.3\n0.3\n-0.3\n0.6\n\n\nMH\n0.2\n0.2\n-1.2\n-0.1\n-0.6\n-0.1\n\n\nMN\n0.2\n0.7\n0.3\n0.9\n0.2\n-0.1\n\n\nMS\n-0.4\n1.0\n-0.4\n1.1\n0.5\n1.2\n\n\nNB\n-1.1\n0.6\n-0.8\n0.4\n0.1\n0.3\n\n\nSF\n-1.0\n0.1\n0.8\n0.5\n0.5\n0.4\n\n\nSL\n0.4\n-0.4\n-0.2\n-1.3\n-0.9\n-1.2\n\n\nSS\n-0.8\n0.6\n0.9\n1.2\n1.0\n1.3\n\n\nSZ\n1.2\n-0.4\n-0.9\n-0.9\n-1.1\n-0.8\n\n\nTA\n1.9\n-2.1\n0.1\n-0.4\n-0.6\n0.2\n\n\nTO\n0.2\n-1.1\n-0.6\n-0.1\n-0.2\n-0.1\n\n\nTU\n-1.7\n2.4\n2.7\n-0.7\n2.0\n1.7\n\n\nZA\n0.3\n-0.4\n-0.7\n0.0\n-0.7\n-0.6\n\n\n\n\n\n\n\nMatrice de corrélation\nOn peut examiner la matrice de corrélation entre les variables :\n\nmatcor&lt;-cor(tab)\nkable(matcor,digits=2, caption = \"Matrice des corrélations\")\n\n\nMatrice des corrélations\n\n\n\ntailm\nlogden\nmobil\nacmig\nordin\nporta\n\n\n\n\ntailm\n1.00\n-0.81\n-0.56\n-0.46\n-0.67\n-0.40\n\n\nlogden\n-0.81\n1.00\n0.62\n0.50\n0.73\n0.48\n\n\nmobil\n-0.56\n0.62\n1.00\n0.52\n0.87\n0.70\n\n\nacmig\n-0.46\n0.50\n0.52\n1.00\n0.76\n0.77\n\n\nordin\n-0.67\n0.73\n0.87\n0.76\n1.00\n0.86\n\n\nporta\n-0.40\n0.48\n0.70\n0.77\n0.86\n1.00\n\n\n\n\n\n? ajouter un corrélogramme ?\n\n\nParamètres principaux\n\nparam &lt;- apply(tab, 2, summary)\nvariance&lt;-apply(tab,2,var)\nectype&lt;-apply(tab,2,sd)\ntabres&lt;-rbind(param, variance,ectype)\ntabres&lt;-data.frame(tabres)\nrow.names(tabres)&lt;-c(\"Minimum\",\"Q1\",\"Mediane\",\"Moyenne\",\"Q3\",\"Maximum\",\"Variance\",\"Ecart-Type\")\n\nkable(tabres, \n      digits=1,\n      caption = \"Paramètres principaux\",\n      )\n\n\nParamètres principaux\n\n\n\ntailm\nlogden\nmobil\nacmig\nordin\nporta\n\n\n\n\nMinimum\n4.0\n1.3\n7.4\n-5.0\n1.2\n29.5\n\n\nQ1\n4.4\n3.9\n9.8\n-2.9\n3.0\n35.8\n\n\nMediane\n4.8\n4.4\n11.2\n-0.7\n4.8\n43.6\n\n\nMoyenne\n4.7\n4.6\n13.1\n-0.3\n5.7\n44.1\n\n\nQ3\n4.9\n5.5\n14.7\n1.1\n7.1\n49.8\n\n\nMaximum\n5.4\n8.3\n26.4\n9.0\n16.3\n60.5\n\n\nVariance\n0.1\n2.4\n24.7\n13.0\n16.4\n95.3\n\n\nEcart-Type\n0.4\n1.5\n5.0\n3.6\n4.0\n9.8\n\n\n\n\n\n\n\nACP\nOn lance la procédure d’Analyse en Composantes Principales sur le tableau des variables initiales tab Pour cela on utilise la library FactoMineR Vocabulaire : composante = axe = facteurs\n\n# Réalisation de l'ACP : la sortie est une liste\nacp &lt;- PCA(tab, \n           graph=FALSE)\n\n# Nom des éléments de la liste\nnames(acp)\n\n[1] \"eig\"  \"var\"  \"ind\"  \"svd\"  \"call\"\n\n\nLa procédure a créé un objet acp qui est une liste de tableaux\nL’objet acp contient de nombreux résultats que nous pouvons extraire, puis analyser. Les résultats qui décrivent : - les composantes de l’ACP : Eig : les valeurs propres - les positions des variables du tableau initial sur les composantes Var : les informations relatives aux variables - les positions des individus sur les composantes Ind : les informations relatives aux individus\n\n\nAnalyse des valeurs propres\nOn commence par récupérer les résultats sur les valeurs propres des composantes eig\n\n# Extrait les valeurs propres (eig = eigenvalue)\nValprop&lt;-acp$eig\n\nkable(Valprop, \n      digits=2,\n      caption = \"Les valeurs propres des composantes \",\n      col.names = c (\"Valeurpropre\", \"PCVariance\", \"CumVariance\"))\n\n\nLes valeurs propres des composantes\n\n\n\nValeurpropre\nPCVariance\nCumVariance\n\n\n\n\ncomp 1\n4.26\n70.95\n70.95\n\n\ncomp 2\n0.90\n14.95\n85.91\n\n\ncomp 3\n0.47\n7.76\n93.67\n\n\ncomp 4\n0.18\n3.04\n96.70\n\n\ncomp 5\n0.16\n2.59\n99.29\n\n\ncomp 6\n0.04\n0.71\n100.00\n\n\n\n\n\nOn représente graphiquement les valeurs propres\nSyntaxe las = 2 #pour que les noms des barres soient à la verticale names.arg = VALPROP$Comp, #pour nommer chaque barre du graphique avec les noms d’axes\n\nVALPROP &lt;- as.data.frame(Valprop)\nVALPROP$Comp &lt;- c(\"F1\", \"F2\", \"F3\", \"F4\", \"F5\", \"F6\")\nVALPROP &lt;- VALPROP %&gt;% rename(ValeurPropre='eigenvalue', \n                    PCVariance='percentage of variance',\n                    CumVariance='cumulative percentage of variance')\nbarplot(VALPROP$PCVariance,  \n        ylim = c(0, 80), col= \"skyblue\" , \n        names.arg = VALPROP$Comp,\n      main = \"Le % de variance des composantes\",\n     xlab = \"les composantes\",\n     ylab = \"le % de variance\",\n     las = 2)\n\n\n\n\n\n\nAnalyse des variables / composantes\n\nQualités de représentation\n\nExtraction des qualités de représentations des variables sur les composantes (contenues dans acp)\nRécupération des qualités de représentations des variables sur les composantes dans un dataframe Var$cos2\nNous n’analyserons que les 2 1ères composantes\n\n\nqualvar&lt;-acp$var$cos2\nQUALVAR &lt;- as.data.frame(qualvar)\nQUALVAR &lt;- QUALVAR %&gt;% select (Dim.1:Dim.2)\nQUALVAR &lt;- QUALVAR %&gt;% rename(QualF1='Dim.1', QualF2='Dim.2')\nkable(QUALVAR, \n      digits=2,\n      caption = \"Qualités de représentations des variables sur les composantes\")\n\n\nQualités de représentations des variables sur les composantes\n\n\n\nQualF1\nQualF2\n\n\n\n\ntailm\n0.58\n0.31\n\n\nlogden\n0.66\n0.23\n\n\nmobil\n0.73\n0.00\n\n\nacmig\n0.63\n0.14\n\n\nordin\n0.95\n0.01\n\n\nporta\n0.71\n0.21\n\n\n\n\n\n\n\nContributions\nVar$contrib\n\nctrvar&lt;-acp$var$contrib\nCTRVAR &lt;- as.data.frame(ctrvar)\nCTRVAR &lt;- CTRVAR %&gt;% select (Dim.1:Dim.2)\nCTRVAR &lt;- CTRVAR %&gt;% rename(CtrF1='Dim.1', CtrF2='Dim.2')\nkable(CTRVAR, \n      digits=2,\n      caption = \"Contributions des variables aux composantes\")\n\n\nContributions des variables aux composantes\n\n\n\nCtrF1\nCtrF2\n\n\n\n\ntailm\n13.68\n34.86\n\n\nlogden\n15.62\n25.17\n\n\nmobil\n17.15\n0.16\n\n\nacmig\n14.74\n15.13\n\n\nordin\n22.25\n1.31\n\n\nporta\n16.57\n23.37\n\n\n\n\n\n\n\nCorrélations\n\ncorvar&lt;-acp$var$cor\nCORVAR &lt;- as.data.frame(corvar)\nCORVAR &lt;- CORVAR %&gt;% select(Dim.1:Dim.2)\nCORVAR &lt;- CORVAR %&gt;% rename(CorF1='Dim.1', CorF2='Dim.2')\nkable(CORVAR, \n      digits=2,\n      caption = \"Corrélations des variables avec les composantes\")\n\n\nCorrélations des variables avec les composantes\n\n\n\nCorF1\nCorF2\n\n\n\n\ntailm\n-0.76\n0.56\n\n\nlogden\n0.82\n-0.48\n\n\nmobil\n0.85\n0.04\n\n\nacmig\n0.79\n0.37\n\n\nordin\n0.97\n0.11\n\n\nporta\n0.84\n0.46\n\n\n\n\n\n\n\nTableau de synthèse\nRéunion des descriptions des variables (QUAL, COR, CTR) sur les composantes dans un seul tableau\n\nACPComp &lt;- cbind.data.frame(CORVAR, CTRVAR,QUALVAR)\nkable(ACPComp, \n      digits=2,\n      caption = \"Descriptions des composantes par les variables\")\n\n\nDescriptions des composantes par les variables\n\n\n\nCorF1\nCorF2\nCtrF1\nCtrF2\nQualF1\nQualF2\n\n\n\n\ntailm\n-0.76\n0.56\n13.68\n34.86\n0.58\n0.31\n\n\nlogden\n0.82\n-0.48\n15.62\n25.17\n0.66\n0.23\n\n\nmobil\n0.85\n0.04\n17.15\n0.16\n0.73\n0.00\n\n\nacmig\n0.79\n0.37\n14.74\n15.13\n0.63\n0.14\n\n\nordin\n0.97\n0.11\n22.25\n1.31\n0.95\n0.01\n\n\nporta\n0.84\n0.46\n16.57\n23.37\n0.71\n0.21\n\n\n\n\n\n\n\nGraphique n°1 : corrélations des variables avec les composantes\nReprésentation graphique des positions des variables sur le 1er plan factoriels : 1-2 soit 86% de la variance du tableau de données\n\nplot.PCA(acp,choix = \"var\",axes = c(1,2))\n\n\n\n\n\n\n\nAnalyse des individus / composantes\nOn fait la même chose pour les individus : on récupère les résultats pour les coordonnées et contributions des individus sur les composantes ind\\(coord* *ind\\)contrib On pourrait aussi récupérer les qualités de représentations (cos2) On ne travaille que sur les 2 premiers axes\n\nTableau de synthèse\n\ncooind&lt;-data.frame(acp$ind$coord)\nCOOIND &lt;- cooind %&gt;% select(Dim.1:Dim.2)\nCOOIND &lt;- COOIND %&gt;% rename(CorIndF1='Dim.1', CorIndF2='Dim.2')\n\nctrind&lt;-data.frame(acp$ind$contrib)\nCTRIND &lt;- ctrind %&gt;% select(Dim.1:Dim.2)\nCTRIND &lt;- CTRIND %&gt;% rename(CtrIndF1='Dim.1', CtrIndF2='Dim.2')\n\nACPIndComp &lt;- cbind.data.frame(COOIND, CTRIND)\nkable(ACPIndComp, \n      digits=2,\n      caption = \"Descriptions des composantes par les variables\")\n\n\nDescriptions des composantes par les variables\n\n\n\nCorIndF1\nCorIndF2\nCtrIndF1\nCtrIndF2\n\n\n\n\nAN\n4.78\n0.59\n22.40\n1.62\n\n\nBA\n4.25\n0.68\n17.70\n2.12\n\n\nBJ\n-1.14\n-1.32\n1.28\n8.07\n\n\nBZ\n-0.20\n-0.97\n0.04\n4.38\n\n\nGB\n-0.21\n0.70\n0.04\n2.25\n\n\nGF\n-0.73\n0.41\n0.53\n0.79\n\n\nJE\n-1.07\n-1.32\n1.11\n8.05\n\n\nKB\n-1.78\n2.18\n3.10\n22.10\n\n\nKF\n-1.05\n-1.32\n1.08\n8.14\n\n\nKR\n-2.22\n-0.65\n4.84\n1.96\n\n\nKS\n-2.42\n-0.19\n5.72\n0.16\n\n\nME\n-0.21\n0.78\n0.04\n2.83\n\n\nMH\n-0.88\n-0.17\n0.76\n0.14\n\n\nMN\n0.79\n0.10\n0.61\n0.05\n\n\nMS\n1.60\n0.32\n2.51\n0.48\n\n\nNB\n0.61\n-0.70\n0.36\n2.31\n\n\nSF\n1.32\n-0.21\n1.71\n0.20\n\n\nSL\n-1.80\n-0.74\n3.17\n2.54\n\n\nSS\n2.39\n0.49\n5.60\n1.12\n\n\nSZ\n-2.20\n0.05\n4.73\n0.01\n\n\nTA\n-1.88\n2.10\n3.47\n20.50\n\n\nTO\n-0.90\n0.61\n0.79\n1.71\n\n\nTU\n4.16\n-1.35\n16.96\n8.44\n\n\nZA\n-1.22\n-0.07\n1.46\n0.02\n\n\n\n\n\n\n\nGraphique des coordonnées des individus sur les composantes\n\nplot.PCA(acp, choix = \"ind\",  cex = 0.8)\n\n\n\n\n\n\nCartographie des résultats de l’ACP\nOn fait une jointure\n\n# Chargement du fonds de carte\nmap&lt;-readRDS(\"data/EXPLO/map2004.RDS\")\nmap&lt;-map[,c(\"gou_code\",\"gou_nom\",\"geometry\")]\n# Ajout du code aux résultats de l'ACP sur les individus\nACPIndComp$gou_code&lt;-rownames(ACPIndComp)\n# Jointure\nmapACP&lt;-merge(map,ACPIndComp,by=\"gou_code\")\n\nOn cartographie l’axe factoriel n°1\n\n# Choix des classes et paliers\nmybreaks&lt;-c(-10,-3,-2,-1,0,1,2,3,10)\nmypal&lt;-brewer.pal(n = 8,name=\"RdBu\")\n\n# Carte des coordonnées des individus sur le 1er axe\nmf_map(x = mapACP, type = \"choro\",var=\"CorIndF1\",\n       breaks = mybreaks,\n       pal=mypal,\n       leg_title = \"Coordonnées\", leg_pos=\"right\")\nmf_map(x=mapACP, type=\"prop\", var =\"CtrIndF1\",\n       col=\"gray\",border=\"black\",inches=0.05,\n       leg_title = \"Contributions\", leg_pos = \"topright\")\nmf_layout(title =  \"Axe factoriel n°1 : Opposition entre les métropoles littorales et l'intérieur\", \n          credits = \"Source : INS\",\n          frame=T)\n\n\n\n\nOn cartographie l’axe factoriel n°2\n\n# Choix des classes et paliers\nmybreaks&lt;-c(-10,-3,-2,-1,0,1,2,3,10)\nmypal&lt;-brewer.pal(n = 8,name=\"RdBu\")\n\n# Carte des coordonnées des individus sur le 1er axe\nmf_map(x = mapACP, type = \"choro\",var=\"CorIndF2\",\n       breaks = mybreaks,\n       pal=mypal,\n       leg_title = \"Coordonnées\", leg_pos=\"right\")\nmf_map(x=mapACP, type=\"prop\", var =\"CtrIndF2\",\n       col=\"gray\",border=\"black\",inches=0.05,\n       leg_title = \"Contributions\", leg_pos = \"topright\")\nmf_layout(title = \"Axe factoriel n°2 : Spécificité des zones intérieures du Nord et du Sud\", \n          credits = \"Source : INS\",\n          frame=T)"
  },
  {
    "objectID": "STA3_multivariee.html#classification-ascendante-hierarchique-cah",
    "href": "STA3_multivariee.html#classification-ascendante-hierarchique-cah",
    "title": "[STA3] : Introduction à la statistique multivariée",
    "section": "(4) CLASSIFICATION ASCENDANTE HIERARCHIQUE (CAH)",
    "text": "(4) CLASSIFICATION ASCENDANTE HIERARCHIQUE (CAH)\n\nRéalisation de la CAH\n\ncah&lt;-HCPC(acp,nb.clust = 4)\n\n\n\n\n\n\n\n\n\ntabres&lt;-cah$data.clust\n\n\n\nAide à l’interprétation du profil des classes\n\ncatdes(tabres,num.var = 7)\n\n\nLink between the cluster variable and the quantitative variables\n================================================================\n            Eta2           P-value\nlogden 0.8742961 0.000000003430429\nordin  0.8626694 0.000000008258952\nmobil  0.7922782 0.000000498388749\nporta  0.6942662 0.000022432310735\ntailm  0.6628743 0.000058422533025\nacmig  0.5586204 0.000803095528735\n\nDescription of each cluster by quantitative variables\n=====================================================\n$`1`\n          v.test Mean in category Overall mean sd in category Overall sd\ntailm   2.754972         5.397597     4.681510    0.003118411  0.3758509\nlogden -2.900932         1.579334     4.598438    0.273543036  1.5049016\n           p.value\ntailm  0.005869713\nlogden 0.003720544\n\n$`2`\n         v.test Mean in category Overall mean sd in category Overall sd\nmobil -2.833720        10.697866   13.1278048       1.876258   4.865936\nacmig -3.086236        -2.247168   -0.3281443       1.765304   3.528411\nordin -3.165110         3.509918    5.7196433       1.659890   3.961662\nporta -3.670047        37.883834   44.0643183       6.067117   9.556057\n           p.value\nmobil 0.0046009675\nacmig 0.0020270800\nordin 0.0015502425\nporta 0.0002425055\n\n$`3`\n        v.test Mean in category Overall mean sd in category Overall sd\nacmig 2.038861         2.595971   -0.3281443       1.221718   3.528411\n         p.value\nacmig 0.04146395\n\n$`4`\n          v.test Mean in category Overall mean sd in category Overall sd\nmobil   4.085085        24.093913   13.1278048      1.8477795  4.8659360\nordin   3.995453        14.451942    5.7196433      1.3848440  3.9616623\nlogden  3.246416         7.293678    4.5984382      0.7275680  1.5049016\nporta   3.040853        60.095267   44.0643183      0.5540810  9.5560575\nacmig   2.482717         4.504573   -0.3281443      5.1851866  3.5284107\ntailm  -2.500845         4.162964    4.6815104      0.1053255  0.3758509\n             p.value\nmobil  0.00004406077\nordin  0.00006457066\nlogden 0.00116868064\nporta  0.00235909247\nacmig  0.01303847659\ntailm  0.01238973441\n\n\n\n\nVisualisation du profils des classes\n\nplot.catdes(catdes(tabres,7,proba = 1),level = 1,barplot = T)\n\n\n\n\n\n\n\n\n\nJointure du fonds de carte et des résultats de la CAH\n\n# Chargement du fonds de carte\nmap&lt;-readRDS(\"data/EXPLO/map2004.RDS\")\nmap&lt;-map[,c(\"gou_code\",\"gou_nom\",\"geometry\")]\n# Ajout du code aux résultats de l'ACP sur les individus\ntabres$gou_code&lt;-rownames(tabres)\n# Jointure\nmapCAH&lt;-merge(map,tabres,by=\"gou_code\")\n\n\n\nCartographie des résultats de la CAH\n\n# Ajout de noms aux classes\nmapCAH$classes&lt;-as.factor(mapCAH$clust)\nlevels(mapCAH$classes)&lt;- c(\"1 : Spécifique\",\n                           \"2 : Défavorisé\",\n                           \"3 : Favorisé\",\n                           \"4 : Très favorisé\")\nmypal=c(\"lightgreen\",\"lightyellow\",\"orange\",\"red\")\n\n# Carte des coordonnées des individus sur le 1er axe\nmf_map(x = mapCAH, type = \"typo\",var=\"classes\",\n       leg_title = \"Classes\", leg_pos=\"right\",\n       pal=mypal)\nmf_layout(title = \"Typologie des gouvernorats\", \n          credits = \"Source : INS\",\n          frame=T)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GEOUNIV’R 2024",
    "section": "",
    "text": "Objectif\n\n\n\nL’ objectif de cette école d’été était de former des formateurs en réunissant des enseignants et ingénieurs français et tunisien intéressés par l’usage du logiciel R pour la cartographie, la géomatique, la statistique et l’analyse spatiale. Les enseignements ont été co-construits à partir de données et de questions d’enseignement et de recherche intéressant en premier lieu la Tunisie. Les formateurs français ont apporté leur expertise dans la résolution de ces questions à l’aide du programme R. Une partie des outils de formations avaient été préalablement développée lors de l’Ecole d’été CIST 2022-2023 qui avait réuni des enseignants chercheurs de France et d’Afrique de l’Ouest.\n\n\n\n\n\n\n\n\nPrérequis\n\n\n\nPrérequis : Initiation à R\nEn amont de la semaine de formation, une initiation à l’usage du logiciel R et de son environnement R-Studio avait été dispensée par Taher Yengui, maître assistant du département de géographie l’Université de Sfax. Le suivi de cette initiation était une condition d’inscription à la formation.\n\n\n\n\n\n\nTélécharger le module d’initiation à R et R studio\n\n\n\n\nInitiation à R Ce dossier rédigé par Taher Yengui comporte un document expliquant les bases des langages R et R markdown ainsi qu’un jeu de données d’exemple pour de premières applications.\n\n\n\n\n\n\n\n\n\n\n\nThéorie et pratique\n\n\n\nMatin : cours\nLes matinées étaient consacrées à des cours portant sur les différents sujets du programme avec des applications sur des exemples communs. \n\n\nAprès-midi : ateliers\nLes après-midi étaient consacrées à des ateliers par groupes de 3 à 4 participants travaillant sur un projet à partir de leurs propres jeux de données. \n\n\n\n\n\nLieu et date\n\n\n\nL’école d’été GEONUIV’R 2024 s’est tenue à l’hôtel Sentido Bellevue de Sousse du 12 au 18 Mai 2024; L’hôtel Sentido Bellevue Park est dédié au toursime. Mais offre aussi des salles de réunions pour les congrès et meetings. Il a offert un tarif préférentiel à la formation ce dont nous le remercions.\n\n\n\n\n\n\n\n\nInstitutions et financement\n\n\n\nL’école d’été GEOUNIV’R 2024 a été organisée par la Fédération de Recherche CIST conjointement par le département de géographie de la FLSH de Universié Sfax et l’UFR GHES de l’université Paris-Cité.\nLe financement principal a été apporté par les crédits de l’IDEX Innovation Pédagogique de l’Université Paris-Cité\nLe projet a été réalisé avec le soutien d’enseignants-chercheurs des laboratoires de recherche Géographie-cités et Prodig et d’ingénieurs des unités de service Riate Geoteca.\n   \n\n\n \n\n\n\n\n\n\nComité d’organisation\n\n\n\nL’école d’été GEONUIV’R 2024 a été organisé conjointement par la FALSH de l’Université de Sfax, l’Université Paris Cité et la FR 2007 CIST avec le soutien des équipes de recherche SYFACTE, Géographie-cités, Prodig, Geoteca et Riate. Le comité d’organisation était composé de Claude Grasland et Salem Dahech pour l’Université Paris Cité, Riadh Bouaziz et Sami Charfi pour l’Université de Sfax.\n\n\n\n\n\n\n\n\nListe des participants\n\n\n\nL’école d’été a rassemblé 34 participants parmi lesquels 9 enseignants-chercheurs ou ingénieurs côté français et 25 enseignants-chercheurs côté tunisien, appartenant aux différents départements de géographie en Tunisie (Sfax, Sousse, Tunis, Manouba et Jendouba).\n\n\n\n\n\nLes 34 participants lors de la cérémonie de clôture\n\n\n\n\n\n\n\n\nFrance\n\nBaudet-Michel Sophie (Géographie-cités)\nDahech Salem (PRODIG)\nGrasland Claude (CIST & Géographie-cités)\nGuérois Marianne (Géographie-cités)\nLambert Nicolas (RIATE)\nMadelin Malika (PRODIG)\nMarveaux Elina (CIST)\nPlaisant Brian (Geoteca)\nYsebaert Ronan (RIATE)\n\n\n\nTunisie\n\nBouaziz Riadh\nCharfi Sami\nFeki Mohamed\nYengui Taher\nKacem Abir\nSouissi Mohamed\nHammami Zayed\nNsiri Hsan\nJarraya Mounir\nGhribi Marwen\nRebei Hédi\nZenati Hedi\nHamza Dalel\nBarrani Yassine\nBen Fguira Sami\nHamila Hajer\nHeni Sabeh\nMadani Wassime\nSaadaoui Khaoula\nSoudeni Sghaira\nEuchi Hamdi\nBen Romdhan Safa\nNasrallah Wafa\nAbdelkhalak Abderrahmen\nChkir Ben Jmâa Najiba"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#point-moyen",
    "href": "SPA1_ResumeSemis.html#point-moyen",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "1.1 Point moyen",
    "text": "1.1 Point moyen\nPour un ensemble de n points (1…i…n) décrits par leurs coordonnées (Xi, Yi), le point moyen, noté par convention G (pour centre de Gravité), est le point qui a pour coordonnées mX, mY, c’est-à-dire la moyenne des distributions des Xi et des Yi.\nTout comme la moyenne est la valeur qui minimise la somme des carrés des écarts à toutes les autres valeurs, le point moyen est le point qui minimise la somme des carrés des distances à tous les autres points. Ce point est un résumé moyen des positions et s’avère utile pour comparer les distributions spatiales de différentes catégories de points à une même date (par ex. plusieurs essences végétales, plusieurs catégories d’équipements…) ou bien pour suivre l’évolution d’une distribution à différentes dates, en indiquant l’orientation et le rythme d’une diffusion spatiale :\n\nDans R… Quel est le point moyen du semis des villes tunisiennes ? (2015)\nLe centre de gravité G simple (non pondéré) a pour coordonnées (Xm, Ym) : on extrait d’abord du fichier sf les coordonnées des villes, à l’aide de la fonction st_coordinates(), puis on calcule les moyennes de ces coordonnées et on transforme ces valeurs en point, à l’aide de la fonction st_point().\nCalcul du point moyen et transformation en fichier sf :\n\n# Extraction des coordonnées des villes et création d'un fichier df des villes avec leur nom, leurs coordonnées X et Y\ncoordsvil15 &lt;- data.frame(Nom = vil2015$Nom, \n                          X = st_coordinates(vil2015)[,1], \n                          Y = st_coordinates(vil2015)[,2], stringsAsFactors = FALSE)\n\n# Calcul de la moyenne de ces coordonnées en X et Y : on récupère directement la valeur de Xm et de Ym à partir de la moyenne calculée sur la 2e colonne (X) et la 3e colonne (Y) du tableau\n# Puis transformation en point\nptmoy_vil15 &lt;- st_point(c(mean(coordsvil15[, 2]), mean(coordsvil15[, 3])))"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#point-médian",
    "href": "SPA1_ResumeSemis.html#point-médian",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "1.2 Point médian",
    "text": "1.2 Point médian\nLe point médian M est, comme la médiane par rapport à la moyenne, une mesure de la tendance centrale robuste aux points exceptionnels ou aberrants. Il identifie l’emplacement qui minimise les trajets depuis et vers toutes les autres entités dans le jeu de données. C’est pourquoi il est souvent utilisé pour déterminer une localisation optimale, en cherchant le point le plus accessible à l’ensemble des points du semis.\nÀ la différence du point moyen, le point médian est défini par une propriété générale et non pas par une formule particulière de calcul qui n’est valable que pour une métrique particulière. Dans un référentiel rectilinéaire, le point médian est le point qui partage la distribution spatiale en sous-parties égales (même effectif au nord, au sud, à l’est, à l’ouest). Il a pour coordonnées Xmed, Ymed qui sont les médianes des distributions des Xi et des Yi de l’ensemble du semis.\n\nDans R… Quel est le point médian du semis des villes tunisiennes ? (2015)\nLe point médian simple M (non pondéré) a pour coordonnées (Xmed, Ymed) : on calcule les médianes de ces coordonnées et on transforme ces valeurs en point, à l’aide de la fonction st_point().\n\n# Les coordonnées des villes ont déjà été extraites pour le point moyen. On repart du même fichier coordsvil2015.\n\n# Calcul de la médiane des coordonnées X et Y puis transformation en point\nptmed_vil15 &lt;- st_point(c(median(coordsvil15[, 2]), median(coordsvil15[, 3])))"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#comparaison-carte-des-points-moyenmédian-en-2015",
    "href": "SPA1_ResumeSemis.html#comparaison-carte-des-points-moyenmédian-en-2015",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "1.3. Comparaison : carte des points moyen/médian en 2015",
    "text": "1.3. Comparaison : carte des points moyen/médian en 2015\n\n\n\n\n\n\nÀ vous de jouer\n\n\n\n\n\n\nDans la carte ci-contre, les autrices de l’exercice ont oublié de mettre la légende…  Où est le point médian ? le point moyen ?  Et qu’est-ce que leur comparaison vous apprend sur la forme du semis ?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode R pour la carte de comparaison des points moyen/médian (2015)\n\n\n\n\n\n\n# Localisation des villes en 2015\nmf_map(del, col=\"bisque\", border=\"white\")\nmf_map(x=vil2015, pch = 20, cex = 0.7, col = \"grey60\", add=TRUE) \n\n# Ajout point moyen (2015)\nmf_map(ptmoy_vil15, pch = 20, cex = 1.5, col = \"brown2\", lwd = 2, add=TRUE)\n\n# Ajout point médian (2015)\nmf_map(ptmed_vil15, pch = 20, cex = 1.5, col = \"purple1\", lwd = 2, add=TRUE)\n\nmf_credits(\"Sources : Africapolis 2020, INS & Syfacte/Riate\")\n# Adapter nom de pays pour le titre\nmf_title(\"Comparaison des points moyen/médian, 2015\")\nmf_scale(pos = \"bottomright\", lwd = 2, cex = 0.6, scale_units = \"km\")\n\n\n\n\n\n\n\n\n\n\nCommentaires\n\n\n\n\n\n\nLe point médian étant le point qui partage l’ensemble de la distribution en sous-parties de même effectif, on aura autant de villes au nord et au sud de ce point, et autant à l’est qu’à l’ouest. Représenté en violet sur la carte, il est plus proche des fortes concentrations urbaines du littoral. Les coordonnées du point moyen, en rouge, sont influencées par les positions méridionales et occidentales extrêmes et plus rares de quelques villes. Le faible décalage entre les points moyen et médian reflète cependant le caractère relativement symétrique de ce semis.\nnb : pour faire réapparaître la légende, on peut ajouter une ligne de code, par exemple pour le point moyen : mf_legend(type = \"symb\",     title=\"Point moyen\", pos = \"topright\", pal= \"brown2\", pt_pch =     15,pt_cex = 1,val = \"\")"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#point-moyen-pondéré-où-est-le-centre-de-la-population-urbaine",
    "href": "SPA1_ResumeSemis.html#point-moyen-pondéré-où-est-le-centre-de-la-population-urbaine",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "1.4. Point moyen pondéré : où est le centre de la population urbaine ?",
    "text": "1.4. Point moyen pondéré : où est le centre de la population urbaine ?\nPour tenir compte non seulement des positions des points du semis mais aussi de leur poids respectif (par exemple, des populations plus ou moins importantes des villes), on peut affecter des poids aux points et prendre en compte ces poids dans le calcul des coordonnées du point moyen.\nAinsi, pour un ensemble de n points (1…i…n) décrits par leurs coordonnées (Xi, Yi) et par leur masse Mi, le centre de gravité pondéré (noté Gp), barycentre des masses localisées, est le point qui a pour coordonnées Xmp, Ymp (moyenne des coordonnées en Xi et en Yi pondérées par les populations).\nAttribuer un poids à des coordonnées, c’est multiplier chacune des coordonnées par la « masse » (ici la population) de chaque ville. Puis, pour trouver la position du centre de gravité pondéré, on doit diviser la somme des coordonnées pondérées par la somme des populations des villes. Sur le graphique, la pondération a pour effet de rapprocher le centre de gravité pondéré (Gp) de la ville la plus peuplée du semis.\n\nDans R… Comment calculer le point moyen pondéré ? Exemple pour le centre des populations urbaines tunisiennes (2015)\nAjout des populations au tableau coordsvil15 :\n\ncoordsvil15 &lt;- merge(coordsvil15, vil2015, by = \"Nom\")\ncoordsvil15 &lt;- coordsvil15[,c(\"Nom\", \"X\", \"Y\", \"Pop2015\")]\n\nCalcul des coordonnées pondérées par les populations, pour chaque ville :\n\ncoordsvil15$Xmp &lt;- coordsvil15$X * coordsvil15$Pop2015\ncoordsvil15$Ymp &lt;- coordsvil15$Y * coordsvil15$Pop2015\n\nPuis on calcule les coordonnées du point moyen pondéré en divisant la somme des Xmp par la somme des populations (idem pour Ymp).\n\nxctrp15 &lt;- sum(coordsvil15$Xmp)/sum(coordsvil15$Pop2015)\nyctrp15 &lt;- sum(coordsvil15$Ymp)/sum(coordsvil15$Pop2015)\n\nEnfin on crée un nouveau fichier sf pour représenter ce point moyen pondéré par les populations.\n\nptmoyp_vil15 &lt;- st_point(c(xctrp15, yctrp15))\n\n\n\n\n\n\n\nÀ vous de jouer\n\n\n\n\n\n\n\n\nDans la carte ci-contre, les autrices de l’exercice ont oublié de mettre la légende…\n\nOù est le point moyen non pondéré ? pondéré ?\n\nEt qu’est-ce que leur comparaison vous apprend sur la forme du semis ?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode R pour la carte de comparaison des points moyens pondérés / non pondérés (2015)\n\n\n\n\n\n\n# Carte des populations des villes en 2015\nmf_map(gou, col=\"bisque\", border=\"white\")\nmf_map(x=vil2015, \"Pop2015\", \"prop\", val_max = 2000000, leg_pos=\"bottomleft\", col = \"grey80\", border=\"white\", add=TRUE) \nmf_title(\"Pop. urbaine, 2015\")\nmf_scale(pos = \"bottomright\", lwd = 2, cex = 0.6, scale_units = \"km\")\nmf_credits(\"Sources : Africapolis 2020, INS & Syfacte/Riate\")\n\n# Ajout point moyen (2015)\nmf_map(ptmoy_vil15, pch = 20, cex = 2, col = \"brown2\", lwd = 3, add=TRUE)\n\n# Ajout point moyen pondéré (2015)\nmf_map(ptmoyp_vil15, pch = 20, cex = 2, col = \"lightsalmon\", lwd = 3, add=TRUE)\n\n# Affichage de qqs noms de villes\nmf_label( x = vil2015[vil2015$Pop2015&gt;50000,],var = \"Nom\", \n  col = \"black\",\n  cex = 0.5,\n  font = 1,\n  r = 0.1,\n  halo = TRUE,\n  overlap = FALSE,\n  lines = FALSE\n)\n\n# Adapter nom de pays pour le titre\nmf_title(\"Points moyens non pondéré / pondéré, 2015\")"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#la-distance-type",
    "href": "SPA1_ResumeSemis.html#la-distance-type",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "2.1 La distance-type",
    "text": "2.1 La distance-type\nLa distance-type (ou distance standard) mesure la dispersion des points autour du point moyen. Tout comme une valeur centrale est précisée par un paramètre de dispersion statistique, un point central peut être accompagné d’un paramètre de dispersion spatiale qui indique l’éloignement des points ou de la population par rapport à celui-ci.\nCette distance-type a pour valeur la racine de la somme des variances de X et de Y. Il en résulte une valeur unique qui est une mesure d’éloignement au centre : cette dernière peut être représentée sur une carte en traçant un cercle de rayon égal à la valeur de distance-type et dont le centre correspond au point moyen.\nDans le cas d’une distribution spatiale symétrique, 67% des points sont théoriquement situés à moins d’une distance type du centre de gravité, 95% à moins de deux distances-types.\n\nDans R… Calcul de la distance-type à l’aide de la fonction sf::st_buffer() (2015)\nQuelle est la dispersion moyenne des villes autour du centre ? où se trouvent la majorité des villes autour du point moyen ?\nLa dispersion moyenne des villes autour du centre moyen peut être visualisée à l’aide de la mesure de la distance-type. On calcule d’abord la distance-type des coordonnées des villes, avant de tracer le cercle dont le rayon correspond à cette distance.\nCalcul de la distance standard\n\nsdvil15 &lt;- sqrt(sum((coordsvil15[,2] - ptmoy_vil15[1])^2 \n                    + (coordsvil15[,3] - ptmoy_vil15[2])^2) /nrow(coordsvil15))\n\nCréer la géométrie du cercle (à l’aide de la fonction st_buffer() de sf)\n\nsdvil15_buffer &lt;- st_buffer(ptmoy_vil15, sdvil15)\n\nCarte du point moyen et de la distance standard\n\nmf_map(del, col = \"bisque\", border=\"white\")\nmf_map(vil2015, pch = 20, cex = .6, col = \"brown4\", add=TRUE) \nmf_map(ptmoy_vil15, pch = 20, cex = 1.5, col = \"brown4\", lwd = 3,add=TRUE)\nmf_map(sdvil15_buffer, col = NA, lwd = 2, border = \"brown4\", add=TRUE) \n\nmf_title(\"Point moyen et dispersion du semis, 2015\")\nmf_scale(pos = \"bottomright\",lwd = 1,cex = 0.6,scale_units=\"km\")\nmf_credits(\"Sources : Africapolis 2020, INS & Syfacte/Riate\")"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#lellipse-de-dispersion",
    "href": "SPA1_ResumeSemis.html#lellipse-de-dispersion",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "2.2 L’ellipse de dispersion",
    "text": "2.2 L’ellipse de dispersion\nPour traduire l’orientation privilégiée du semis de manière plus souple, on peut préférer à la distance-type le calcul d’une ellipse de dispersion. Une manière d’en déterminer l’axe principal d’étirement, ou encore axe de variance maximal, est par exemple illustrée dans Feuillet, Cossart, and Commenges (2019), p.85 :\n\nConstruction des diagrammes de distribution suivant les coordonnées en X et en Y\n\nCalcul de la moyenne observée pour positionner le point moyen (centre de l’ellipse)\n\nCalcul des écart-types respectifs des coordonnées X et Y, pour identifier l’axe d’étirement principal du semis, situé au croisement des valeurs moyennes de X et Y + 1 écart-type d’une part, des valeurs moyennes de X et Y - 1 écart-type d’autre part\n\n\nDans R…\nOn peut dessiner les contours de l’ellipse de dispersion à l’aide de la fonction dataEllipse() du package car (Companion to Applied Regression).\n\n# Carte 2015 des villes\nmf_map(del, col = \"bisque\", border=\"white\")\nmf_map(vil2015, pch = 20, cex = .6, col = \"brown4\", add=TRUE) \nmf_map(ptmoy_vil15, pch = 20, cex = 1.5, col = \"brown4\", lwd = 3,add=TRUE)\nmf_title(\"Point moyen et ellipse de dispersion du semis, 2015\")\n\n# Tracé de l'ellipse en 2015\n# Faire d'abord la transformation des coordonnées en data.frame, pour pouvoir utiliser la fonction \"dataEllipse\" du package Car\n\nvil_pt_df_2015 &lt;- cbind(st_drop_geometry(vil2015), \n                   st_coordinates(vil2015))\n\ndataEllipse(x = vil_pt_df_2015$X, \n            y = vil_pt_df_2015$Y, \n            center.pch = FALSE, plot.points=FALSE,col = \"brown4\",\n            levels = .66,xpd=T, # xpd=T permet d'écrire dans les marges\n            add = TRUE)\n\nmf_scale(pos = \"bottomright\",lwd = 1,cex = 0.6,scale_units=\"km\")\nmf_credits(\"Sources : Africapolis 2020, INS & Syfacte/Riate\")"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#analyse-temporelle",
    "href": "SPA1_ResumeSemis.html#analyse-temporelle",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "Analyse temporelle",
    "text": "Analyse temporelle\nPour suivre dans le temps l’évolution de la répartition des villes et des populations urbaines, les grandes tendances de leur localisation, vous pouvez calculer les points médian et moyen à différentes dates.\n\nComment ce semis urbain s’est-il diffusé dans le temps, depuis 1950 ?\n\n\n\n\n\n\nÀ vous de jouer\n\n\n\nQue montre le déplacement du point moyen depuis 1950 ? Comment les directions et les rythmes de diffusion de l’urbanisation ont-ils évolué depuis 1950 ?\n\n\n\n\n\n\n\n\nCode R pour cartographier le déplacement du point moyen depuis 1950\n\n\n\n\n\nCalcul des points moyens de 1950 à 2015\n\n# 1950\ncoordsvil50 &lt;- data.frame(Nom = vil1950$Nom, X = st_coordinates(vil1950)[,1], Y = st_coordinates(vil1950)[, 2], stringsAsFactors = FALSE)\nptmoy_vil50 &lt;- st_point(c(mean(coordsvil50[, 2]), mean(coordsvil50[, 3])))\n\n# 1970\ncoordsvil70 &lt;- data.frame(Nom = vil1970$Nom, X = st_coordinates(vil1970)[,1], Y = st_coordinates(vil1970)[, 2], stringsAsFactors = FALSE)\nptmoy_vil70 &lt;- st_point(c(mean(coordsvil70[, 2]), mean(coordsvil70[, 3])))\n\n# 1990\ncoordsvil90 &lt;- data.frame(Nom = vil1990$Nom, X = st_coordinates(vil1990)[,1], Y = st_coordinates(vil1990)[, 2], stringsAsFactors = FALSE)\nptmoy_vil90 &lt;- st_point(c(mean(coordsvil90[, 2]), mean(coordsvil90[, 3])))\n\n# 2015\ncoordsvil15 &lt;- data.frame(Nom = vil2015$Nom, X = st_coordinates(vil2015)[,1], Y = st_coordinates(vil2015)[, 2], stringsAsFactors = FALSE)\nptmoy_vil15 &lt;- st_point(c(mean(coordsvil15[, 2]), mean(coordsvil15[, 3])))\n\nCréation du tableau des coordonnées des pts moyens pour les 4 dates et transformation en fichier sf\n\nptmoy &lt;- data.frame(Date = c(\"1950\",\"1970\",\"1990\",\"2015\"),\n                    X = c(ptmoy_vil50[1],ptmoy_vil70[1],ptmoy_vil90[1],ptmoy_vil15[1]),\n                    Y = c(ptmoy_vil50[2],ptmoy_vil70[2],ptmoy_vil90[2],ptmoy_vil15[2]))\n\n# Transformation du df en fichier de points\nptmoy &lt;- st_as_sf(x=ptmoy,\n                  coords = c(\"X\",\"Y\"),\n                  crs = 3035)\n\nAvec Mapview\n\nmapview(ptmoy)\n\n\n\n\n\n\nEt quand on prend on compte la population des villes ?\n\n\n\n\n\n\nÀ vous de jouer\n\n\n\nComment expliquer les différences observées dans le déplacement du point moyen entre 1950 et 2010, selon que le point est pondéré ou non par la population ?\n\n\n\n\n\n\n\n\nCode R pour l’analyse de la diffusion du semis urbain pondéré\n\n\n\n\n\nCalcul des points moyens pondérés pour les dates antérieures à 2015\n\n# 1950\ncoordsvilpop50 &lt;- left_join(coordsvil50, vil1950, by = \"Nom\", keep = FALSE) %&gt;%\n  select(Nom, X, Y, Pop1950)\ncoordsvilpop50 &lt;- coordsvilpop50 %&gt;%\n  mutate(Xp = X * Pop1950, Yp = Y * Pop1950)\nxctrp50 &lt;- sum(coordsvilpop50$Xp)/sum(coordsvilpop50$Pop1950)\nyctrp50 &lt;- sum(coordsvilpop50$Yp)/sum(coordsvilpop50$Pop1950)\nptmoyp_1950 &lt;- st_point(c(xctrp50, yctrp50))\n\n# 1970\ncoordsvilpop70 &lt;- left_join(coordsvil70, vil1970, by = \"Nom\", keep = FALSE) %&gt;%\n  select(Nom, X, Y, Pop1970)\ncoordsvilpop70 &lt;- coordsvilpop70 %&gt;%\n  mutate(Xp = X * Pop1970, Yp = Y * Pop1970)\nxctrp70 &lt;- sum(coordsvilpop70$Xp)/sum(coordsvilpop70$Pop1970)\nyctrp70 &lt;- sum(coordsvilpop70$Yp)/sum(coordsvilpop70$Pop1970)\nptmoyp_1970 &lt;- st_point(c(xctrp70, yctrp70))\n\n# 1990\ncoordsvilpop90 &lt;- left_join(coordsvil90, vil1990, by = \"Nom\", keep = FALSE) %&gt;%\n  select(Nom, X, Y, Pop1990)\ncoordsvilpop90 &lt;- coordsvilpop90 %&gt;%\n  mutate(Xp = X * Pop1990, Yp = Y * Pop1990)\nxctrp90 &lt;- sum(coordsvilpop90$Xp)/sum(coordsvilpop90$Pop1990)\nyctrp90 &lt;- sum(coordsvilpop90$Yp)/sum(coordsvilpop90$Pop1990)\nptmoyp_1990 &lt;- st_point(c(xctrp90, yctrp90))\n\nTableau des coordonnées des pts moyens pondérés pour les 4 dates et transformation en fichier sf Projection du point\n\nptmoyp &lt;- data.frame(Date = c(\"1950\",\"1970\",\"1990\",\"2015\"),\n                    X = c(ptmoyp_1950[1],ptmoyp_1970[1],ptmoyp_1990[1],ptmoyp_vil15[1]),\n                    Y = c(ptmoyp_1950[2],ptmoyp_1970[2],ptmoyp_1990[2],ptmoyp_vil15[2]))\n\nptmoyp &lt;- st_as_sf(x=ptmoyp,\n                  coords = c(\"X\",\"Y\"),\n                  crs = 3035)\n\nCarte 1950-1970-1990-2015 / Symboles colorés en fonction de la date\n\npar(mfrow = c(1,2))\n\nmf_map(del, col = \"bisque\", border=\"white\")\nmf_map(x = ptmoy,                 ## fichier sf\n       var = \"Date\",              ## variables\n       type = \"typo\",             ## le type de carte\n       cex = 1,\n       pch = 15,\n       pal = c(\"rosybrown1\",\"lightsalmon\",\"brown2\",\"brown4\"),\n       leg_pos = \"topright\",\n       leg_title = \"Point moyen\",\n       add = TRUE\n)\nmf_scale(pos=\"bottomright\",lwd=1.5,cex=0.6,unit=\"km\")\nmf_credits(\"Sources : Africapolis, GADM\")\nmf_title(\"Diffusion du point moyen, 1950-2010\")\n\nmf_map(del, col = \"bisque\", border=\"white\")\nmf_map(x = ptmoyp,             ## fichier sf\n       var = \"Date\",           ## variable à représenter\n       type = \"typo\",          ## le type de carte\n       cex = 1.5,\n       pch = 16,\n       pal = c(\"rosybrown1\",\"lightsalmon\",\"brown2\",\"brown4\"),\n       leg_pos = \"topright\",\n       leg_title = \"Point moyen\\npondéré\",\n       add = TRUE\n)\nmf_scale(pos=\"bottomright\",lwd=1.5,cex=0.6,scale_units=\"km\")\nmf_credits(\"Sources : Africapolis, INS & Syfacte/Riate\")\nmf_title(\"Diffusion du point moyen pondéré, 1950-2015\")\n\n\n\n\n\npar(mfrow = c(1,2))\n\nmf_map(del, col = \"bisque\", border=\"white\")\nmf_map(x = ptmoy,                 ## fichier sf\n       var = \"Date\",              ## variables\n       type = \"typo\",             ## le type de carte\n       cex = 1,\n       pch = 15,\n       pal = c(\"rosybrown1\",\"lightsalmon\",\"brown2\",\"brown4\"),\n       leg_pos = \"topright\",\n       leg_title = \"Point moyen\",\n       add = TRUE\n)\nmf_map(x = ptmoyp,             ## fichier sf\n       var = \"Date\",           ## variable à représenter\n       type = \"typo\",          ## le type de carte\n       cex = 1.5,\n       pch = 16,\n       pal = c(\"rosybrown1\",\"lightsalmon\",\"brown2\",\"brown4\"),\n       leg_pos = \"topright\",\n       leg_title = \"Point moyen\\npondéré\",\n       add = TRUE\n)\nmf_scale(pos=\"bottomright\",lwd=1.5,cex=0.6,unit=\"km\")\nmf_credits(\"Sources : Africapolis, INS & Syfacte/Riate\")\nmf_title(\"Diffusion du point moyen pondéré et non pondéré, 1950-2015\")\n\n\n\n\n\nmapview(ptmoyp)"
  },
  {
    "objectID": "SPA1_ResumeSemis.html#analyser-la-forme-dun-semis-de-points-concentrationdispersion",
    "href": "SPA1_ResumeSemis.html#analyser-la-forme-dun-semis-de-points-concentrationdispersion",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "Analyser la forme d’un semis de points (concentration/dispersion)",
    "text": "Analyser la forme d’un semis de points (concentration/dispersion)\nCes résumés d’un semis de points aident à mesurer la dispersion plus ou moins importante des points autour d’un centre, mais elles restent dépendantes de la référence à la valeur centrale et proportionnelles à la taille des zones d’étude (la distance-type sera d’autant plus grande que la zone étudiée est vaste). D’autres méthodes proposent des indicateurs de dispersion relative qui permettent de caractériser la forme plus ou moins concentrée ou dispersée d’une distribution, indépendamment d’une valeur centrale et de la taille de la zone d’étude. C’est le cas par exemple de la méthode des distances au plus proche voisin, dont un exemple d’application est présenté dans ce module de l’école d’été du CIST au Bénin (2023)."
  },
  {
    "objectID": "SPA1_ResumeSemis.html#championnat-de-1ère-division-1955-2015",
    "href": "SPA1_ResumeSemis.html#championnat-de-1ère-division-1955-2015",
    "title": "[SPA1] Resumé d’un semis de points",
    "section": "Championnat de 1ère division 1955-2015",
    "text": "Championnat de 1ère division 1955-2015\nLes données originales (informations transmises par C. Grasland)\nLe premier fichier décrit de façon détaillée les résultats du championnat de première division année par année. La variable Rang indique le classement et la variable CodeClub l’équipe. Les coordonnées X et Y donnent la longitude et la latitude du club. Les autres colonnes indiquent le nombre de points obtenu avec le nombre de matchs joués gagnés, perdus ou nuls. On trouve enfin les buts marqués (BP) et les buts encaissés (BC). Le deuxième fichier contient les noms des clubs et les coordonnées X et Y de leur implantation.\n\n# Championnat de 1ere division 1955-2015\nchamp1 &lt;- read.table(\"data/SPA1/champ1.csv\", \n                     header=T,\n                     sep = \";\")\nhead(champ1,14)\n\n   DIV Annee Rang CodeClub      X      Y PTS  J  G N  P BP BC\n1  DI   1955    1     CSHL 10.346 36.728  58 22 15 6  1 56 15\n2  DI   1955    2      ESS 10.624 35.829  55 22 15 3  4 54 28\n3  DI   1955    3       CA 10.189 36.804  50 22 12 4  6 43 21\n4  DI   1955    4      EST 10.187 36.814  50 22 11 6  5 38 21\n5  DI   1955    5      CAB  9.866 37.279  48 22 11 4  7 36 22\n6  DI   1955    6     USMF 10.898 35.620  43 22  8 5  9 41 27\n7  DI   1955    7       ST 10.127 36.816  43 22  9 3 10 43 41\n8  DI   1955    8      CSS 10.753 34.726  40 22  5 8  9 25 35\n9  DI   1955    9      SRS 10.770 34.752  39 22  7 3 12 34 43\n10 DI   1955   10      COT 10.153 36.799  37 22  6 3 13 25 48\n11 DI   1955   11     PFCB  9.858 37.273  37 22  5 5 12 35 71\n12 DI   1955   12       PS 10.632 35.823  28 22  2 2 18 19 77\n13 DI   1956    1       ST 10.127 36.816  58 22 16 4  2 54 24\n14 DI   1956    2      EST 10.187 36.814  55 22 13 7  2 49 18\n\n# La liste des clubs de D1 et de D2\nclubs &lt;- read.table(\"data/SPA1/clubs.csv\", \n                     header=T,\n                     sep = \";\")\nkable(head(clubs,10))\n\n\n\n\n\n\n\n\n\n\n\n\nCodeClub\nNomClub\nCodeDel\nNomDel\nX\nY\n\n\n\n\nAG\nAvenirGrombalia\nTS115D\nGrombalia\n36.594\n10.505\n\n\nAH\nAlHilelSport(Zahra)\nTS1136\nZahra\n36.742\n10.315\n\n\nAMCHL\nAMelClubHamemLif\nTS1133\nHamemLif\n36.728\n10.346\n\n\nAMS\nAssociationMegrineSportif\nTS1138\nMegrine\n36.772\n10.239\n\n\nAPS\nAvenirPopulairedeSoliman\nTS115A\nSoliman\n36.694\n10.484\n\n\nASA\nAssociationSportifAriana\nTS1120\nLArianaVille\n36.854\n10.191\n\n\nASD\nAssociationSportifdeDjerba\nTS3125\nDjerbaHoumetSouk\n33.871\n10.858\n\n\nASDJ\nAssociationSportifdeDjerba\nTS3125\nDjerbaHoumetSouk\n33.871\n10.858\n\n\nASG\nAvenirSportifdeGabes\nTS3110\nGabesMedina\n33.848\n10.099\n\n\nASGH\nAssociationSportivedeGhardimaou\nTS1226\nGhardimaou\n36.446\n8.443\n\n\n\n\n\nLes données transformées en fichier sf pour l’exercice\n\nchamp1 &lt;- st_read(\"data/SPA1/champ1.gpkg\")\n\nReading layer `champ1' from data source \n  `/Users/claudegrasland1/worldregio/geounivr2024/data/SPA1/champ1.gpkg' \n  using driver `GPKG'\nSimple feature collection with 834 features and 11 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 8.402 ymin: 33.153 xmax: 11.207 ymax: 37.279\nGeodetic CRS:  WGS 84\n\n\n\nPré-traitements (création d’une nouvelle variable Période, identification des clubs de ligue 1 à chaque période)\nAgrégation temporelle\nNous reprenons les cinq périodes identifiées par Ali Langar pour suivre les grandes phases de la diffusion des clubs :\n\n1955-1969 : Années qui précèdent et qui suivent l’indépendance\n1970-1986 : Retour à l’économie de marché, sous Bourguiba\n1987-2002 : Libéralisation économique sous Ben Ali (I)\n2003-2011 : Libéralisation économique sous Ben Ali (II)\n2012-2015 : Période qui suit la révolution de Jasmin\n\nCes périodes sont associées à des hypothèses qui tiennent compte des évolutions politiques et économiques : par exemple, on pourrait s’attendre à un mouvement de concentration pendant la libéralisation économique sous Ben Ali, du fait des nouvelles options d’aménagement du territoire au profit des métropoles et du littoral, ou bien à l’inverse, à une rupture profonde avec la révolution de Jasmin qui initierait un mouvement de rééquilibrage vers le sud.\nCréation d’une nouvelle variable $Periode pour associer les résultats de chaque club à une période donnée\n\nchamp1$Periode &lt;- ifelse(champ1$Annee&lt;=1969,\"1955-1969\", \n                     ifelse(champ1$Annee&gt;1969 & champ1$Annee&lt;=1986,\"1970-1986\",\n                     ifelse(champ1$Annee&gt;1986 & champ1$Annee&lt;=2002,\"1987-2002\",\n                     ifelse(champ1$Annee&gt;2002 & champ1$Annee&lt;=2011,\"2003-2011\",\"2012-2015\"))))\n\nQuels sont les clubs présents au moins une année, pendant chaque période ? On crée 5 nouveaux fichiers à partir du fichier initial champ1 : de Club1 (1955-1969)… à Club5 (2012-2015)\n\nPeriode1 &lt;- champ1[champ1$Periode==\"1955-1969\",]\nClubs1 &lt;- Periode1 %&gt;% group_by(CodeClub) %&gt;% summarize(nbannees = n())\nClubs1 &lt;- Clubs1 %&gt;% select(CodeClub,nbannees,geom)\n\nPeriode2 &lt;- champ1[champ1$Periode==\"1970-1986\",]\nClubs2 &lt;- Periode2 %&gt;% group_by(CodeClub) %&gt;% summarize(nbannees = n())\nClubs2 &lt;- Clubs2 %&gt;% select(CodeClub,nbannees,geom)\n\nPeriode3 &lt;- champ1[champ1$Periode==\"1987-2002\",]\nClubs3 &lt;- Periode3 %&gt;% group_by(CodeClub) %&gt;% summarize(nbannees = n())\nClubs3 &lt;- Clubs3 %&gt;% select(CodeClub,nbannees,geom)\n\nPeriode4 &lt;- champ1[champ1$Periode==\"2003-2011\",]\nClubs4 &lt;- Periode4 %&gt;% group_by(CodeClub) %&gt;% summarize(nbannees = n())\nClubs4 &lt;- Clubs4 %&gt;% select(CodeClub,nbannees,geom)\n\nPeriode5 &lt;- champ1[champ1$Periode==\"2012-2015\",]\nClubs5 &lt;- Periode5 %&gt;% group_by(CodeClub) %&gt;% summarize(nbannees = n())\nClubs5 &lt;- Clubs5 %&gt;% select(CodeClub,nbannees,geom)\n\n\n\nAnalyse de la diffusion des clubs de ligue 1 entre 1955 et 2015\nObjectif : construire 5 cartes représentant pour chaque période le barycentre (point moyen) des clubs et l’ellipse de dispersion autour du point moyen.\nPar exemple, pour la période 1955-1969, cela suppose :\n\nde projeter le fichier Club1 en EPSG:3035\nd’extraire les coordonnées des équipes de Club1 au sein d’un tableau de données de format sf\nde calculer la moyenne de ces coordonnées en X et en Y\nde transformer ces coordonnées du point moyen en fichier sf pour pouvoir afficher ce point moyen en 1955-1969\nde tracer l’ellipse de déviation autour du point moyen\n\n\nComplétez le code suivant pour calculer le point moyen et l’ellipse de dispersion pour la période 1955-1969\nEtapes 1) à 4): projeter Clubs1 en crs:3035, extraire les coordonnées des clubs, calculer la moyenne de ces coordonnées.\nVous devez utiliser les quatre fonctions suivantes (pas forcément dans cet ordre) : mean, st_point,st_transform,st_coordinates\n\n# Projection du fichier puis extraction des coordonnées des clubs\n\nClubs1 &lt;- ...(Clubs1, ...)\ncoordsClubs1 &lt;- data.frame(Code = Clubs1$CodeClub, X = ... (Clubs1)[,1], Y = ... (Clubs1)[, 2], stringsAsFactors = FALSE) \n\n# Calcul de la moyenne de ces coordonnées en X et Y puis transformation en point\n\nptmoy_Clubs1 &lt;- ...(c(...(coordsClubs1[, 2]), ...(coordsClubs1[, 3]))) \n\nEtape 5) : tracer l’ellipse de déviation à l’aide de la Fonction dataEllipse du package car\n\n# Carte des Clubs1 (1955-1969)\n\nmf_map(del, col = \"bisque\", border=\"white\") # Affichage du fond des délégations\n\nmf_map(..., pch = 20, cex = .6, col = \"brown4\", ...) # Affichage de Clubs1 \nmf_map(..., pch = 20, cex = 1.5, col = \"brown4\", lwd = 3,...) # Affichage du point moyen \nmf_title(\"Point moyen et ellipse de dispersion des clubs de Ligue 1, 1955-1969\",cex=0.8)\n\n# Tracé de l'ellipse en 1955-1969 (période 1)\n# Faire d'abord la transformation des coordonnées de Club1 en data.frame, pour pouvoir utiliser la fonction \"dataEllipse\" du package Car\ndf1 &lt;- cbind(st_drop_geometry(Clubs1), st_coordinates(Clubs1))\ndataEllipse(x = df1$X, \n            y = df1$Y, \n            center.pch = FALSE, plot.points=FALSE,col = \"brown4\",\n            levels = .66,xpd=T, # xpd=T permet d'écrire dans les marges\n            add = TRUE)\n\n\n\n\n\n\n\nSolution de l’exercice & suite des traitements pour construire la carte qui superpose les points moyens et les ellipses\n\n\n\n\n\nExtraction des coordonnées des clubs pour chaque période\n\n# Extraction des coordonnées des clubs\nClubs1 &lt;- st_transform(Clubs1, crs=3035)\ncoordsClubs1 &lt;- data.frame(Code = Clubs1$CodeClub, X = st_coordinates(Clubs1)[,1], Y = st_coordinates(Clubs1)[, 2], stringsAsFactors = FALSE)\n\n# Calcul de la moyenne de ces coordonnées en X et Y puis transformation en point\nptmoy_Clubs1 &lt;- st_point(c(mean(coordsClubs1[, 2]), mean(coordsClubs1[, 3]))) # pour récupérer directement la valeur de Xm et Ym\n\n\n# Extraction des coordonnées des clubs\nClubs2 &lt;- st_transform(Clubs2, crs=3035)\ncoordsClubs2 &lt;- data.frame(Code = Clubs2$CodeClub, X = st_coordinates(Clubs2)[,1], Y = st_coordinates(Clubs2)[, 2], stringsAsFactors = FALSE)\n\n# Calcul de la moyenne de ces coordonnées en X et Y puis transformation en point\nptmoy_Clubs2 &lt;- st_point(c(mean(coordsClubs2[, 2]), mean(coordsClubs2[, 3]))) # pour récupérer directement la valeur de Xm et Ym \n\n\n# Extraction des coordonnées des clubs\nClubs3 &lt;- st_transform(Clubs3, crs=3035)\ncoordsClubs3 &lt;- data.frame(Code = Clubs3$CodeClub, X = st_coordinates(Clubs3)[,1], Y = st_coordinates(Clubs3)[, 2], stringsAsFactors = FALSE)\n\n# Calcul de la moyenne de ces coordonnées en X et Y puis transformation en point\nptmoy_Clubs3 &lt;- st_point(c(mean(coordsClubs3[, 2]), mean(coordsClubs3[, 3]))) # pour récupérer directement la valeur de Xm et Ym \n\n\n# Extraction des coordonnées des clubs\nClubs4 &lt;- st_transform(Clubs4, crs=3035)\ncoordsClubs4 &lt;- data.frame(Code = Clubs4$CodeClub, X = st_coordinates(Clubs4)[,1], Y = st_coordinates(Clubs4)[, 2], stringsAsFactors = FALSE)\n\n# Calcul de la moyenne de ces coordonnées en X et Y puis transformation en point\nptmoy_Clubs4 &lt;- st_point(c(mean(coordsClubs4[, 2]), mean(coordsClubs4[, 3]))) # pour récupérer directement la valeur de Xm et Ym \n\n\n# Extraction des coordonnées des clubs\nClubs5 &lt;- st_transform(Clubs5, crs=3035)\ncoordsClubs5 &lt;- data.frame(Code = Clubs5$CodeClub, X = st_coordinates(Clubs5)[,1], Y = st_coordinates(Clubs5)[, 2], stringsAsFactors = FALSE)\n\n# Calcul de la moyenne de ces coordonnées en X et Y puis transformation en point\nptmoy_Clubs5 &lt;- st_point(c(mean(coordsClubs5[, 2]), mean(coordsClubs5[, 3]))) # pour récupérer directement la valeur de Xm et Ym \n\nCréation d’un tableau des coordonnées des pts moyens pour les 5 périodes et transformation en fichier sf\n\nptmoy &lt;- data.frame(Periode = c(\"1955-1969\",\"1970-1986\",\"1987-2002\",\"2003-2011\",\"2012-2015\"),\n                    X = c(ptmoy_Clubs1[1],ptmoy_Clubs2[1],ptmoy_Clubs3[1],ptmoy_Clubs4[1],ptmoy_Clubs5[1]),\n                    Y = c(ptmoy_Clubs1[2],ptmoy_Clubs2[2],ptmoy_Clubs3[2],ptmoy_Clubs4[2],ptmoy_Clubs5[2]))\n\nptmoy_Clubs &lt;- st_as_sf(x=ptmoy,\n                  coords = c(\"X\",\"Y\"),\n                  crs = 3035)\n\nCarte de 1955 à 2015\n\nmf_map(del, col = \"bisque\", border=\"white\")\nmf_map(x = ptmoy_Clubs,           ## fichier sf\n       var = \"Periode\",           ## variables\n       type = \"typo\",             ## le type de carte\n       cex = 1.5,\n       pch = 20,\n       pal = c(\"rosybrown1\",\"lightsalmon\",\"brown2\",\"brown3\",\"brown4\"),\n       leg_pos = \"topright\",\n       leg_title = \"Point moyen\",\n       add = TRUE\n)\nmf_map(Clubs5, pch = 20, cex = .8, col = \"grey60\", add=TRUE) # Affichage de Clubs5 \n\n# Tracer les ellipses de déviation à l'aide de la Fonction `dataEllipse` du package `car`\n# Ex détaillé pour le tracé de l'ellipse en 1955-1969 (période 1)\n# Faire d'abord la transformation des coordonnées de Club1 en data.frame, pour pouvoir utiliser la fonction \"dataEllipse\" du package Car\ndf1 &lt;- cbind(st_drop_geometry(Clubs1), st_coordinates(Clubs1))\ndataEllipse(x = df1$X, \n            y = df1$Y, \n            center.pch = FALSE, plot.points=FALSE,col = \"rosybrown1\",\n            levels = .66,xpd=T, # xpd=T permet d'écrire dans les marges\n            add = TRUE)\n\n# Tracé de l'ellipse en 1970-1986 (période 2)\ndf2 &lt;- cbind(st_drop_geometry(Clubs2), st_coordinates(Clubs2))\ndataEllipse(x = df2$X, \n            y = df2$Y, \n            center.pch = FALSE, plot.points=FALSE,col = \"lightsalmon\",\n            levels = .66,xpd=T,\n            add = TRUE)\n\n# Tracé de l'ellipse en 1987-2003 (période 3)\ndf3 &lt;- cbind(st_drop_geometry(Clubs3), st_coordinates(Clubs3))\ndataEllipse(x = df3$X, \n            y = df3$Y, \n            center.pch = FALSE, plot.points=FALSE,col = \"brown2\",\n            levels = .66,xpd=T, \n            add = TRUE)\n\n# Tracé de l'ellipse en 2003-2011 (période 4)\ndf4 &lt;- cbind(st_drop_geometry(Clubs4), st_coordinates(Clubs4))\ndataEllipse(x = df4$X, \n            y = df4$Y, \n            center.pch = FALSE, plot.points=FALSE,col = \"brown3\",\n            levels = .66,xpd=T, \n            add = TRUE)\n\n# Tracé de l'ellipse en 2012-2015 (période 5)\ndf5 &lt;- cbind(st_drop_geometry(Clubs5), st_coordinates(Clubs5))\ndataEllipse(x = df5$X, \n            y = df5$Y, \n            center.pch = FALSE, plot.points=FALSE,col = \"brown4\",\n            levels = .66,xpd=T, \n            add = TRUE)\n\nmf_scale(pos=\"bottomright\",lwd=1.5,cex=0.6,unit=\"km\")\nmf_credits(\"Sources : A. Langar 2018, INS\")\nmf_title(\"Diffusion des clubs de Ligue 1, 1955-2015 : pts moyens/ellipses dév.\", cex=0.7)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nÀ propos de ce document\n\n\n\nCe support a été créé pour la semaine de formation franco-tunisienne GEO UNIV’R Tunisie 2024 - “Enseigner la statistique, la cartographie et l’analyse spatiale avec R qui se tient à Sousse en mai 2024.\n\n\n\n\nRéférences\nFeuillet, T., Cossart, É., Commenges, H. (2019). Manuel de géographie quantitative : Concepts, outils, méthodes. Armand Colin. Chapitre 4 : Décrire la localisation des objets géographiques.\nGrasland,C. (2000), Cours d’analyse spatiale, Université Paris 7, en ligne\nPumain, D., Saint-Julien, T. (2010). Analyse spatiale : Les localisations. Armand Colin. Chapitre 2 : Lieux et distribution de lieux.\nTaylor P.J. (1977). Quantitative Methods in Geography: an introduction to Spatial Analysis, Waveland Press, 386 p.\n\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Paris\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] kableExtra_1.4.0 osmextract_0.5.2 car_3.1-3        carData_3.0-5   \n[5] mapview_2.11.2   mapsf_0.12.0     sf_1.0-19        dplyr_1.1.4     \n\nloaded via a namespace (and not attached):\n [1] xfun_0.49               raster_3.6-30           htmlwidgets_1.6.4      \n [4] lattice_0.22-6          leaflet.providers_2.0.0 vctrs_0.6.5            \n [7] tools_4.4.1             crosstalk_1.2.1         generics_0.1.3         \n[10] stats4_4.4.1            tibble_3.2.1            proxy_0.4-27           \n[13] pkgconfig_2.0.3         KernSmooth_2.23-24      satellite_1.0.5        \n[16] uuid_1.2-1              leaflet_2.2.2           lifecycle_1.0.4        \n[19] farver_2.1.2            compiler_4.4.1          stringr_1.5.1          \n[22] munsell_0.5.1           terra_1.8-29            codetools_0.2-20       \n[25] maplegend_0.1.0         htmltools_0.5.8.1       class_7.3-22           \n[28] yaml_2.3.10             Formula_1.2-5           jquerylib_0.1.4        \n[31] pillar_1.10.1           classInt_0.4-10         wk_0.9.4               \n[34] abind_1.4-8             brew_1.0-10             tidyselect_1.2.1       \n[37] digest_0.6.37           stringi_1.8.4           fastmap_1.2.0          \n[40] grid_4.4.1              colorspace_2.1-1        cli_3.6.4              \n[43] magrittr_2.0.3          base64enc_0.1-3         leafem_0.2.3           \n[46] e1071_1.7-16            withr_3.0.2             scales_1.3.0           \n[49] sp_2.1-4                rmarkdown_2.29          png_0.1-8              \n[52] evaluate_1.0.1          knitr_1.49              viridisLite_0.4.2      \n[55] s2_1.1.7                rlang_1.1.5             Rcpp_1.0.13-1          \n[58] leafpop_0.1.0           glue_1.8.0              DBI_1.2.3              \n[61] xml2_1.3.6              svglite_2.1.3           rstudioapi_0.17.1      \n[64] jsonlite_1.9.1          R6_2.6.1                systemfonts_1.1.0      \n[67] units_0.8-5"
  },
  {
    "objectID": "SPA3_PointsSurfaces.html#polygones-de-thiessen-ou-de-voronoï",
    "href": "SPA3_PointsSurfaces.html#polygones-de-thiessen-ou-de-voronoï",
    "title": "[SPA3] Des points aux surfaces",
    "section": "• Polygones de Thiessen ou de Voronoï",
    "text": "• Polygones de Thiessen ou de Voronoï\nAssez simple à mettre en œuvre, la méthode des polygones de Thiessen/Voronoï estime la valeur d’un point, à partir de celles de ses voisins et de leur distance, en utilisant la méthode du plus proche voisin : la valeur de chaque cellule de la surface est égale à la valeur de la donnée située le plus près. La taille et la forme des polygones ne dépendera donc que de la distribution des points d’échantillonnage.\nElle transforme le phénomène continu en un modèle spatialement discret (Caloz and Collet (2011)) et ne présuppose pas d’étude statistique au préalable (notamment d’autocorrélation spatiale).\nVous verrez peut-être prochainement, dans [SPA3] Modéliser des aires d’influence, la fonction sf::st_voronoi(), pour faire des polygones de Thiessen/Voronoï. Ici, nous proposons une autre manière, avec le package terra.\n\n\nCréation des polygones à partir des points, puis découpage selon le contour de la Tunisie :\n\n# création polygones de Voronoï/Thiessen\npoly_voronoi &lt;- voronoi(clim_spatv)\nplot(poly_voronoi)\npoints(clim_spatv, col = \"seagreen\")\n# fusion des régions et format SpatVector\ncontour_tunisie &lt;- vect(st_union(reg))  \n\n# découpage des polygones selon le contour \npoly_voronoi &lt;- crop(poly_voronoi, contour_tunisie)\nplot(poly_voronoi)\npoints(clim_spatv, col = \"seagreen\")\n\n\n\n\n\n\nCréation des polygones\n\n\n\n\n\n\n\nDécoupage selon la Tunisie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode R mapsf pour la création de la carte\n\n\n\n\n\n\n# mapsf ne lit pas (encore ?) les objets SpatVect, alors transformation \npoly_voronoi_sf &lt;- st_as_sf(poly_voronoi) \n\nmf_map(x = poly_voronoi_sf,   ## fichier de départ\n       var = \"P.mm\",          ## variable Précipitations\n       type = \"choro\",        ## le type de carte, ici choroplèthe\n       pal = \"Blues\",         ## la palette\n       breaks =  c(0, 150, 300, 450, 600, 750),  ## discrétisation manuelle\n       leg_title = \"Total annuel (en mm)\",  ## le titre de la légende\n       leg_pos = 'topleft',\n       leg_val_rnd = 0,\n)\nmf_title(\"Précipitations - polygones de Voronoï\")\nmf_credits(\"Source : Fichier envoyé par Salem Dahech, 2024\")\nmf_scale(pos = 'bottomright')\nmf_map(clim_sf, col = \"seagreen\", cex = 2, add = TRUE) # ajout des points des stations"
  },
  {
    "objectID": "SPA3_PointsSurfaces.html#inverse-de-la-distance-pondérée-idw",
    "href": "SPA3_PointsSurfaces.html#inverse-de-la-distance-pondérée-idw",
    "title": "[SPA3] Des points aux surfaces",
    "section": "• Inverse de la distance pondérée (IDW)",
    "text": "• Inverse de la distance pondérée (IDW)\nLa méthode IDW (inverse distance weighting), assez classique également, repose sur le calcul de moyennes mobiles pondérées par l’inverse de la distance élevée à une puissance. À partir d’une grille régulière ou d’un raster, on réalise pour chaque cellule :\n\nSélection des n plus proches voisins ou selon un voisinage d’une certaine portée,\nCalcul de la moyenne de leurs attributs en pondérant par l’inverse de la distance élevée à une puissance (souvent 2).\n\nOn peut donc ajuster la méthode en choisissant les voisins retenus (c’est-à-dire le « rayon d’influence ») et aussi la puissance (lorsque celle-ci tend vers 1, la décroissance de l’influence d’un point tend vers une fonction linéaire ; plus elle est élevée, plus la décroissance augmente rapidement ; égale à 0, elle correspond à la triangulation de Delaunay et à une absence de l’effet de la distance).\nSous R, nous allons utiliser la fonction générique de géostatistique gtat() du package gstat qui permet de choisir une méthode d’interpolation (ici en précisant nmax et idp, on indiquera IDW, le nombre de points et la puissance). On le fait sur un tableau de données avec des colonnes “x” et “y” (attention : le non respect du libellé des colonnes peut conduire à des galères…).\n\n\n\n# retour à un dataframe avec 2 colonnes x et y\nclim_df &lt;- data.frame(geom(clim_spatv)[, c(\"x\", \"y\")], as.data.frame(clim_spatv))\n\n# construction d'un modèle \nmodel_gs &lt;- gstat(data = clim_df,     \n                  locations=~x+y, \n                  id = \"P.mm\", \n                  formula = P.mm ~ 1, \n# 1~ pour ne pas prendre de co-variables ici (comme l'altitude, etc.) \n                  nmax=7, \n                  set=list(idp = 2))\n\n# application du modèle à l'ensemble de l'emprise spatiale\nidw &lt;- interpolate(clim_r_1km, model_gs, debug.level=0)\n# l'option debug.level=0 permet de pas afficher ici les messages, i.e. le modèle retenu \"[inverse distance weighted interpolation]\"\n\n# découpage du résultat selon le contour \nidw_tun &lt;- mask(idw, reg)\n\n# cartographie\n# du raster\nmf_raster(idw_tun$P.mm.pred,\n          pal = \"Blues\", \n          type = \"interval\",\n          breaks =  seq(0, 750, 10),  \n)\n# ajout des stations\nmf_map(clim_sf, col = \"seagreen\", cex = 2, add = TRUE)\n# ajout des graticules (latitudes et longitudes)\nmf_graticule(reg, lwd=0.5, cex = .6)\n# ajout d'un contour\nmf_map(st_union(reg), border = \"grey40\", col=NA, add=TRUE)\n# ajout de la source\nmf_credits(\"Source : Fichier envoyé par Salem Dahech, 2024\")\n# ajout de l'échelle\nmf_scale(pos = 'bottomright')\n# ajout du N\nmf_arrow()\n# ajout du titre\nmf_title(\"IDW (puissance : 2)\")\n\n\n\n\nCarte des précipitations selon la méthode IDW\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutre procédure un peu plus rapide qui utilise le package terra\n\n\n\n\n\n\nidw_terra &lt;- interpIDW(clim_r_1km, clim_spatv, field = \"P.mm\", radius=500000, power=2, maxPoints=7)\nidw_terra_tun &lt;- mask(idw_terra, reg)\n\nmf_raster(idw_terra_tun,\n          pal = \"Blues\", \n          type = \"interval\",\n          breaks =  seq(0, 750, 10),  \n          leg_pos = NA\n)\nmf_map(clim_sf, col = \"seagreen\", cex = 2, add = TRUE)\nmf_title(\"IDW, p=2, 7 pts, p=500km\")\n# ajout des graticules (latitudes et longitudes)\nmf_graticule(reg, lwd=0.5, cex = .6)\n# ajout d'un contour\nmf_map(st_union(reg), border = \"grey40\", col=NA, add=TRUE)\n# ajout de la source\nmf_credits(\"Source : Fichier envoyé par Salem Dahech, 2024\")\n# ajout du N\nmf_arrow()\n# ajout de l'échelle\nmf_scale(pos = 'bottomright')\n\n\n\n\n\n\n\nEn faisant varier les paramètres de la méthode :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nLes nuances sur ces 3 cartes avec des paramètres différents sont assez subtiles, à cette échelle et avec la palette choisie. En choisissant exprès une palette divergente, on peut remarquer une importance plus « diluée » des valeurs des stations pour la puissance 1 à l’inverse de p = 4."
  },
  {
    "objectID": "SPA3_PointsSurfaces.html#surfaces-de-tendance",
    "href": "SPA3_PointsSurfaces.html#surfaces-de-tendance",
    "title": "[SPA3] Des points aux surfaces",
    "section": "• Surfaces de tendance",
    "text": "• Surfaces de tendance\nL’objectif de cette méthode est d’approcher la surface, déterminée à partir des points de mesure, par une surface polynomiale pouvant être de plusieurs ordres. Le choix d’un ordre 1, soit une « surface de tendance du premier degré », rend compte d’un gradient spatial linéaire (de type Z = a + bX + cY), par ex un gradient SW-NE. Plus on augmente l’ordre, plus on prend en compte les effets plus locaux, mais on s’écarte alors du pouvoir explicatif de la variabilité spatiale à large échelle et il peut s’avérer difficile d’interpréter le résultat de la modélisation.\n\n\nSous R, toujours avec la fonction générique gstat() et en précisant le degré ou l’ordre de la surface de tendance (degree =) :\n\nmodel_gs1 &lt;- gstat(data = clim_df,     \n                  locations=~x+y, \n                  id = \"P.mm\", \n                  formula = P.mm ~ 1, \n                  degree = 1)\nsurftend_1 &lt;- interpolate(clim_r_1km, model_gs1, debug.level=0)\nsurftend_1_tun &lt;- mask(surftend_1, reg)\nplot(surftend_1_tun$P.mm.pred)\n\nLes totaux annuels de précipitations diminuent du nord au sud de la Tunisie, jusqu’à atteindre des valeurs négatives, ce qui est impossible ! Cela est notamment lié à la quasi-absence de stations dans le sud de la Tunisie et à un effet qu’on appelle « effet de bord ». Plus généralement, cela montre bien la prudence à avoir, en général, sur les résultats des interpolations (spatiales ou non).\n\n\n\n\n\n\n\n\n\n\nEn faisant varier l’ordre et en choisissant une discrétisation identique (excluant les valeurs inférieures à 0) :\n\n# Surface de tendance d'ordre 2\nmodel_gs2 &lt;- gstat(data = clim_df,     \n                  locations=~x+y, \n                  id = \"P.mm\", \n                  formula = P.mm ~ 1, \n                  degree = 2)\nsurftend_2 &lt;- interpolate(clim_r_1km, model_gs2, debug.level=0)\nsurftend_2_tun &lt;- mask(surftend_2, reg)\n\n# Surface de tendance d'ordre 3\nmodel_gs3 &lt;- gstat(data = clim_df,     \n                  locations=~x+y, \n                  id = \"P.mm\", \n                  formula = P.mm ~ 1, \n                  degree = 3)\nsurftend_3 &lt;- interpolate(clim_r_1km, model_gs3, debug.level=0)\nsurftend_3_tun &lt;- mask(surftend_3, reg)\n\nsurftend_1_tun$P.mm.pred[surftend_1_tun$P.mm.pred &lt; 0,] &lt;- NA\nsurftend_2_tun$P.mm.pred[surftend_2_tun$P.mm.pred &lt; 0,] &lt;- NA\nsurftend_3_tun$P.mm.pred[surftend_3_tun$P.mm.pred &lt; 0,] &lt;- NA\n\nmf_map(st_union(reg), col=\"grey90\")\nmf_raster(surftend_1_tun$P.mm.pred,\n          pal = \"Blues\", \n          type = \"interval\",\n          breaks =  seq(0, 750, 10),  \n          leg_pos = NA,\n          add=TRUE\n)\nmf_map(st_union(reg), border = \"grey40\", col=NA, add=TRUE)\nmf_title(\"Surf Tend ordre = 1\")\nmf_graticule(reg, lwd=0.5, cex = .6)\nmf_credits(\"Source : Fichier envoyé par Salem Dahech, 2024\")\nmf_arrow()\nmf_map(st_union(reg), col=\"grey90\")\nmf_raster(surftend_2_tun$P.mm.pred,\n          pal = \"Blues\", \n          type = \"interval\",\n          breaks =  seq(0, 750, 10),  \n          leg_pos = NA,\n          add=TRUE\n)\nmf_map(st_union(reg), border = \"grey40\", col=NA, add=TRUE)\nmf_title(\"Surf Tend ordre = 2\")\nmf_graticule(reg, lwd=0.5, cex = .6)\nmf_map(st_union(reg), border = \"grey40\", col=NA, add=TRUE)\nmf_map(st_union(reg), col=\"grey90\")\nmf_raster(surftend_3_tun$P.mm.pred,\n          pal = \"Blues\", \n          type = \"interval\",\n          breaks =  seq(0, 750, 10),  \n          leg_pos = NA,\n          add=TRUE\n)\nmf_map(st_union(reg), border = \"grey40\", col=NA, add=TRUE)\nmf_title(\"Surf Tend ordre = 3\")\nmf_graticule(reg, lwd=0.5, cex = .6)\nmf_map(st_union(reg), border = \"grey40\", col=NA, add=TRUE)\nmf_scale(pos = 'bottomright')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuelques remarques\n\n\n\n\n\nD’un point de vue pédagogique, nous avons voulu distinguer sur les cartes les valeurs négatives. Mais nous aurions pu décider de les mettre à 0 mm/an.\nLes faibles différences entre les 3 ordres ne sont pas liées qu’à la palette utilisée ! Elles montrent ici l’importance du gradient N-S.\nLes surfaces de tendance sont des modèles statistiques (comme la régression), il est donc possible de calculer leur pouvoir explicatif et d’analyser les écarts au modèle, i.e. les résidus.\nLes surfaces de tendance sont pertinentes lorsqu’on observe un gradient dans les données, c’est beaucoup moins le cas avec de nombreuses variations locales. En climatologie, elles sont parfois utilisées pour dégager les grandes structures climatiques (variation zonale = en fonction de la latitude ; continentalité ; gradient altitudinal), pour ensuite spatialiser plus finement les variations spatiales.\n\n\n\n\n\n\n\n\n\nA vous de jouer\n\n\n\nPour les plus rapides et/ou pour s’entraîner, réalisez une ou plusieurs cartes d’interpolation des températures minimales et maximales."
  },
  {
    "objectID": "SPA3_PointsSurfaces.html#de-lanalyse-variographique-à-linterpolation-par-krigeage",
    "href": "SPA3_PointsSurfaces.html#de-lanalyse-variographique-à-linterpolation-par-krigeage",
    "title": "[SPA3] Des points aux surfaces",
    "section": "• De l’analyse variographique à l’interpolation par krigeage",
    "text": "• De l’analyse variographique à l’interpolation par krigeage\nUne autre famille de méthodes ne reposent pas sur une approche déterministe comme précédemment, ce sont les méthodes autour du krigeage, développées par Matheron (1970). Plusieurs auteurs préfèrent d’ailleurs réserver le terme de « méthodes géostatistiques » pour celles-ci.\nElles reposent sur 2 étapes :\n• la caractérisation de la structure spatiale ou analyse variographique\n• puis l’estimation spatiale ou krigeage.\nÀ nouveau, plusieurs packages sous R permettent de réaliser ces méthodes. On citera en particulier le package gstat, terra et automap. Ce dernier permet, comme son nom peut l’évoquer, d’automatiser l’ensemble des étapes.\nNous montrons ici les étapes à partir des données de précipitations, même si le nombre de stations est trop faible. De plus, la structure spatiale ici « se limite » à un gradient, ce qui limite l’intérêt du krigeage.\n\nAnalyse variographique\nLa première étape repose sur la construction d’un semi-variogramme empirique, permettant d’estimer comment la « dépendance » spatiale varie avec la distance.\nLa fonction gstat::variogram() calcule les valeurs du semi-variogramme :\n\n# Semi-variogramme expérimental / empirique\nVario &lt;- variogram(P.mm~1, data=clim_sf)\n# 1~ pour ne pas prendre de co-variables ici (comme l'altitude, etc.) \n      \nhead(Vario) \n\n  np     dist     gamma dir.hor dir.ver   id\n1  1 14099.73   72.7218       0       0 var1\n2  1 34717.36  513.9218       0       0 var1\n3  6 45475.92 2289.8333       0       0 var1\n4  4 58581.64 4696.1605       0       0 var1\n5  4 65200.80 3596.3750       0       0 var1\n6 11 80780.83 7573.4091       0       0 var1\n\n\nnp : nombre de paires, dist : distance, gamma : la valeur de semi-variance\n\nplot(Vario, \n     plot.numbers = TRUE) # pour ajouter le nombre de paires pour chaque point\n\n\n\n\nLe choix du pas influence l’allure du variogramme. Il doit, au moins, être inférieur à la moitié de la plus grande distance entre les points de mesure utilisés (Journel and Huijbregts (1976)). Il est possible de le préciser dans la fonction variogram() avec width =, ou d’utiliser la distance par défaut.\nLa lecture d’un variogramme :\n\nle palier et sa portée (qui montre la limite de l’influence spatiale d’un point sur ces voisins) ;\nle comportement avant le palier (variation linéraire, exponentielle…) ;\nl’importance de l’effet pépite à proximité de l’origine (qui témoigne des variations locales) ;\net enfin le comportement directionnel (anisotropie).\n\nIci, dans l’exemple des précipitations en Tunisie, on n’observe pas de palier mais une augmentation assez continue des valeurs de semivariance avec la distance, qui témoigne d’un gradient.\nL’analyse directionnelle ne donne pas de résultats plus probants. Le gradient s’observe très nettement selon la direction 0°, soit du N au S (sans surprise !), et dans une moindre mesure selon 135° (SE-NW).\nRappelons que le nombre de points ici reste faible pour ce type d’analyse.\n\n# selon les directions\nvario_directionnel &lt;- variogram(P.mm~1, data=clim_sf,\n                                alpha = c(0, 45, 90, 135)) # soit N-S, NE-SW, E-W, SE-NW\nplot(vario_directionnel)\n\n\n\n\nPour trouver ensuite l’ajustement, on peut le faire automatiquement ou contraindre un ajustement selon un certain modèle. Ici, pour l’exemple, nous montrons, sans commenter les résultats, la procédure R pour un ajustement sphérique (qui ne se justifie pas à la lecture du variogramme).\n\n## Ajustement du semi-variogramme \nVario.fit &lt;- fit.variogram(Vario, vgm(\"Sph\")) # Modèle d'ajustement (ici sphérique) \nVario.fit\n\n  model    psill   range\n1   Nug     0.00       0\n2   Sph 88884.06 1806571\n\n# Nug / psill &gt;= effet pépite\n\n\n\n\nLe krigeage\nAprès la lecture du variogramme puis la sélection d’un modèle d’ajustement, on applique l’interpolation à l’ensemble de la zone d’étude, c’est ce qu’on appelle le « krigeage ». Il fait référence à une famille de méthodes (krigeage simple, ordinaire, universel, co-krigeage…). Pour cela et comme déjà vu, auparavant, on va créer une grille…\n\n# création d'une grille (en points) \nclim.grid &lt;- st_make_grid(reg, what = \"centers\", cellsize = 1000)\n# Limit\nclim.grid &lt;- st_intersection(clim.grid, reg)\n\n# Krigeage : resultat &lt;- krige(Z_pour_data ~ 1, tabdata_depart, grille, model = modèle_étape_précédente)\nkrigeage &lt;- krige(P.mm~1, clim_sf, clim.grid, model=Vario.fit) \n\n[using ordinary kriging]\n\nplot(krigeage)\n\n\n\n\nUn krigeage produit 2 champs comme résultats : les valeurs estimées (.pred) et la qualité de l’ajustement (.var).\nLa sortie d’un krigeage via gstat est un sf de points, qu’on peut traiter, cartographier, etc :\n\nhead(krigeage)\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4313158 ymin: 1237627 xmax: 4323158 ymax: 1238627\nProjected CRS: ETRS89-extended / LAEA Europe\n  var1.pred var1.var                geometry\n1  193.5326 3565.969 POINT (4314158 1237627)\n2  197.1914 3373.864 POINT (4323158 1237627)\n3  193.5642 3638.312 POINT (4313158 1238627)\n4  194.0124 3613.839 POINT (4314158 1238627)\n5  194.4511 3589.919 POINT (4315158 1238627)\n6  194.8799 3566.655 POINT (4316158 1238627)\n\n\n\n\nAvec automap\nAttention : automap utilise des objets spatiaux sp et non sf. La fonction as_Spatial() permet de transformer le type d’objet.\n\nAutoKrigeage &lt;- autoKrige(formula = P.mm ~ 1,\n                          input_data = as_Spatial(clim_sf), \n                          new_data = as_Spatial(clim.grid))\n\n[using ordinary kriging]\n\nhead(AutoKrigeage[[1]])\n\n         coordinates var1.pred var1.var var1.stdev\n1 (4314158, 1237627)  184.7039 2332.473   48.29569\n2 (4323158, 1237627)  186.6656 2333.047   48.30163\n3 (4313158, 1238627)  185.2179 2333.599   48.30733\n4 (4314158, 1238627)  185.4446 2333.542   48.30675\n5 (4315158, 1238627)  185.6688 2333.505   48.30636\n6 (4316158, 1238627)  185.8906 2333.490   48.30621\n\nplot(AutoKrigeage)\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\nLes cartes des krigeages montrent bien le gradient N-S, à nouveau, avec une confiance dans l’estimation des valeurs qui diminuent inversement, ce qui s’explique par la localisation des stations météorologiques.\n\n\n\n\n\n\n\n\n\nA vous de jouer\n\n\n\nPour les plus rapides et/ou pour vous entraîner, vous pouvez réaliser les mêmes étapes à partir des mesures de température réalisées par Sami Charfi et Salem Dahech. Cette fois-ci, il y a beaucoup plus de points, le poids statistique est renforcé. Par contre, les mesures réalisées sur des transects limitent la validité spatiale des valeurs estimées.\nAlors, observe-t-on un îlot de chaleur urbain ?"
  },
  {
    "objectID": "SPA3_PointsSurfaces.html#lissage-par-noyaux-de-densité-kernel-density-estimation",
    "href": "SPA3_PointsSurfaces.html#lissage-par-noyaux-de-densité-kernel-density-estimation",
    "title": "[SPA3] Des points aux surfaces",
    "section": "• Lissage par noyaux de densité (Kernel Density Estimation)",
    "text": "• Lissage par noyaux de densité (Kernel Density Estimation)\nPrincipe général :\nLa méthode des noyaux de densité, dite aussi méthode KDE (Kernels Density Estimation), repose sur un principe commun à l’ensemble des cartes lissées : la prise en compte du voisinage des lieux observés. La présence d’un phénomène en un point i de l’espace étant supposée indissociable de celle de ses voisins, la densité du phénomène dans le voisinage de i peut être estimée par la quantité d’observations qui se trouvent à proximité de i, rapportée à la surface de ce voisinage. Chaque lieu est ainsi décrit non pas par l’absence/présence d’un phénomène mais par l’intensité (=la densité) du phénomène observé dans le voisinage de ce lieu.\nCette méthode permet ainsi de faire apparaître des continuités de tendance dans l’espace. A l’œil nu, ces concentrations ne sont pas toujours lisibles sur les cartes de semis de points, en raison de la fréquente surcharge d’information. La méthode de lissage par noyaux permet de transformer cette information ponctuelle discrète (absence/présence d’un phénomène) en une surface de densité qui représente l’intensité du phénomène étudié en tout point de l’espace.\nProcédure :\n\n\n\n\nCréation d’une grille d’estimation, maillant l’espace étudié\nSur le centre de chaque carreau de la grille (point d’estimation des densités), on place une « boîte » en forme de cloche au sein de laquelle on compte le nombre de points observés dans le voisinage du point d’estimation. Cette « boîte » est définie par deux paramètres : Sa portée (notée h sur le schéma) Sa forme (notée K sur le schéma). Le fait qu’il s’agisse ici d’une forme en « cloche » signifie que l’on souhaite donner un poids plus important aux observations proches du point d’estimation et un poids négligeable aux observations les plus éloignées. Il s’agit le plus souvent (comme ici) d’une fonction décroissante de la distance de type gaussien.\nPar itération, on fait glisser cette boîte d’un carreau à l’autre de la grille d’estimation = on crée autrement dit une fenêtre mobile qui balaie la zone étudiée pour attribuer à chaque carreau une valeur de densité d’un phénomène dans un voisinage de portée h.\n\n\nParfois, une dernière étape, non représentée sur le schéma, consiste à appliquer une fonction de lissage graphique à la grille, pour gommer les discontinuités liées aux limites des carreaux.\n\n\n\n\n\n\n\nLe choix de la fonction de lissage dépend donc de deux paramètres principaux :\n\nLa portée (le rayon) de la fenêtre de voisinage, sur laquelle on peut jouer pour faire ressortir des structures d’organisation plus ou moins élémentaires ou détaillées.\nLa forme de cette fenêtre, déterminée par la fonction de pondération des observations autour du point d’estimation : aux deux extrêmes, la fonction uniforme (moyenne de toutes les observations du voisinage, sans pondération) est plus simple à comprendre mais introduit des discontinuités visuelles non négligeables, tandis que la fonction gaussienne est une de celles qui traduit le mieux les continuités de tendances dans l’espace.\n\n\nDans R, avec Spatstats :\nApplication aux cafés du centre de Sousse\nConversion des données de points dans le format ppp adapté à spatstat\n\n# Récupération des coordonnées X,Y pour les cafes de Sousse\n# Puis création d'un objet points en format adapté à spatstat (.ppp)\npts &lt;- st_drop_geometry(cafes[,c(\"X\",\"Y\")])\nbbox &lt;- st_bbox(secteurs)\nbbox\n\n   xmin    ymin    xmax    ymax \n4373828 1415451 4380512 1423854 \n\np &lt;- ppp(pts[,1], pts[,2], window=owin(c(bbox$xmin,bbox$xmax), c(bbox$ymin,bbox$ymax)))\n\nCarte brute de densité par noyaux Cette carte est réalisée à partir de la fonction density.ppp de spatstat.\n\n# sigma = portée de la fenêtre (ici, 500 mètres)\n# kernel = fonction de décroissance de la distance. Par défaut, fonction gaussienne. \n# Autres fonctions courantes : \"epanechnikov\", \"quartic\", \"disc\".\n\nds &lt;- density.ppp(p, kernel=\"epanechnikov\",sigma = 500)\nrasdens &lt;- rast(ds)\n\n# Et pour convertir la légende en densité au km² ...\n# (par défaut : dans les unités de la projection, en m²)\nrasdens &lt;- rast(ds) * 1000 * 1000\nrasdens &lt;- rasdens\nplot(rasdens)\n\n\n\n\nCarte “habillée” de la densité par noyaux\n\npar(mar = c(0.5,0.5,1.2,0.5))\n\nbks &lt;- getBreaks(values(rasdens), nclass = 12, method = \"equal\")\ncols &lt;- colorRampPalette((c(\"white\",\"tomato\",\"darkorchid4\")))(length(bks)-1)\nplot(rasdens, breaks= bks, col=cols,legend=F)\n\nlegendChoro(pos = \"topleft\",cex = 0.7, title.cex = 0.7,\n            title.txt = \"Densité de cafés\\nKDE (epanechnikov\\n,sigma=500m\\n(cafés par km2))\",\n            breaks = bks-1, nodata = FALSE,values.rnd = 1, col = cols)\n\nplot(st_geometry(secteurs), border = \"grey50\",col=NA,lwd = 0.1,add=T)\nplot(st_geometry(cafes), col = \"blue\", pch = 20, cex = 0.5, add=T)\nplot(st_geometry(mer), col=\"lightblue1\",border = \"grey60\",add=T)\n\nlayoutLayer(title = \"Densité de cafés à Sousse\", scale = 1,\n            tabtitle = TRUE, frame = FALSE,\n            sources = \"OpenStreetMap 2024, INS\")\n\n\n\n\n\n\n\n\n\n\nA vous de jouer\n\n\n\nTestez différentes valeurs de portée du lissage à l’aide de l’argument sigma = de la fonction density.ppp (par exemple pour un voisinage de 300m ou 500m) et de différentes fonctions de décroissance de la distance à l’aide de l’argument kernel = de la fonction density.ppp.\n- Quelles logiques de concentration des cafés semblent émerger sur ces cartes ?\n\n\n\nPour aller plus loin…\n• Sur les noyaux de densité (KDE), voir par exemple :\n\n\nUn site de ressources sur spatstat, par les créateurs du package, A. Baddeley, R. Turner et E. Rubak, ici.\nPlusieurs exemples de cartes lissées par noyaux de densité sous R, appliquées aux bars et différents types de restaurants parisiens Giraud, 2017, ou encore aux hôpitaux pédiatriques de Singapour Tin Seong, 2019\nPour aller beaucoup plus loin : un chapitre du manuel de l’INSEE d’analyse spatiale avec R sur les cartes de densité par noyaux (chapitre 8).\n\n• Sur les lissages par potentiel\n\n\nvoir le site web du package potential réalisé par Timothée Giraud : exemples sur le lissage par potentiels des populations en Europe, le lissage par potentiels du revenu par habitant en Italie.\n\n\n\n\n\n\n\n\nA propos de ce document\n\n\n\nCe support a été créé pour la semaine de formation franco-tunisienne GEO UNIV’R Tunisie 2024 - “Enseigner la statistique, la cartographie et l’analyse spatiale avec R qui se tient à Sousse en mai 2024.\n\n\n\n\nRéférences\n\n\nCaloz, Régis, and Claude Collet. 2011. Analyse Spatiale de l’information géographique. PPUR Presses polytechniques.\n\n\nJournel, Andre G, and Charles J Huijbregts. 1976. “Mining Geostatistics.”\n\n\nMatheron, G. 1970. “La Théorie Des Variables régionalisées Et Ses Applications.” Cah Cent Morphol Math 5: 1–212.\n\n\nOpenshaw, Stan. 1979. “A Million or so Correlated Coefficients: Three Experiment on the Modifiable Areal Unit Problem.” Statistical Applications in the Spatial Sciences.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. Boca Raton: Chapman; Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nTobler, Waldo R. 1970. “A Computer Movie Simulating Urban Growth in the Detroit Region.” Economic Geography 46 (sup1): 234–40.\n\n\n\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Paris\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] cartography_3.1.4      spatstat_3.3-1         spatstat.linnet_3.2-5 \n [4] spatstat.model_3.3-4   rpart_4.1.23           spatstat.explore_3.3-4\n [7] nlme_3.1-164           spatstat.random_3.3-2  spatstat.geom_3.3-5   \n[10] spatstat.univar_3.1-1  spatstat.data_3.1-4    automap_1.1-16        \n[13] gstat_2.1-2            terra_1.8-29           mapsf_0.12.0          \n[16] sp_2.1-4               sf_1.0-19             \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6          xfun_0.49             ggplot2_3.5.1        \n [4] htmlwidgets_1.6.4     spatstat.sparse_3.1-0 lattice_0.22-6       \n [7] vctrs_0.6.5           tools_4.4.1           spatstat.utils_3.1-2 \n[10] generics_0.1.3        goftest_1.2-3         parallel_4.4.1       \n[13] tibble_3.2.1          proxy_0.4-27          spacetime_1.3-2      \n[16] xts_0.14.1            pkgconfig_2.0.3       Matrix_1.7-0         \n[19] KernSmooth_2.23-24    lifecycle_1.0.4       compiler_4.4.1       \n[22] deldir_2.0-4          FNN_1.1.4.1           munsell_0.5.1        \n[25] codetools_0.2-20      maplegend_0.1.0       stars_0.6-7          \n[28] htmltools_0.5.8.1     class_7.3-22          yaml_2.3.10          \n[31] pillar_1.10.1         classInt_0.4-10       wk_0.9.4             \n[34] abind_1.4-8           tidyselect_1.2.1      digest_0.6.37        \n[37] dplyr_1.1.4           splines_4.4.1         polyclip_1.10-7      \n[40] fastmap_1.2.0         grid_4.4.1            colorspace_2.1-1     \n[43] cli_3.6.4             magrittr_2.0.3        e1071_1.7-16         \n[46] tensor_1.5            scales_1.3.0          rmarkdown_2.29       \n[49] zoo_1.8-12            evaluate_1.0.1        knitr_1.49           \n[52] mgcv_1.9-1            s2_1.1.7              rlang_1.1.5          \n[55] Rcpp_1.0.13-1         glue_1.8.0            DBI_1.2.3            \n[58] rstudioapi_0.17.1     reshape_0.8.9         jsonlite_1.9.1       \n[61] R6_2.6.1              plyr_1.8.9            intervals_0.15.5     \n[64] units_0.8-5          \n\n\n:::"
  },
  {
    "objectID": "SPA3_PointsSurfaces.html#footnotes",
    "href": "SPA3_PointsSurfaces.html#footnotes",
    "title": "[SPA3] Des points aux surfaces",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTrès souvent utilisé par d’autres packages d’interpolation des données ou plus largement par des packages de manipulation des données spatiales, comme terra.↩︎\nEn recherchant sur un moteur de recherche, meuse + R, vous trouverez de très nombreux pas à pas, développements méthodologiques, etc. Aussi possible en mettant un autre logiciel.↩︎"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#le-shapefile",
    "href": "GEO1_carto_vecteurs.html#le-shapefile",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Le shapefile",
    "text": "Le shapefile\nLe shapefile est un format de données spatiales vectorielles propriétaire édité par l’entreprise ESRI, il se présente comme une collection de fichiers portant le même nom avec les extensions et les usages suivants :\n\n.shp : stocke le format de la forme, sa géométrie\n.dbf : données attributaires relatives aux géométries du .shp contenus dans le shapefile ;\n.shx : index de la géométrie.\n.prj : système de coordonnées au format WKT (well-known text)\n\nChaque fichier doit porter le même nom et est indispensable au bon fonctionnement du shapefile.\nD’autres fichiers annexes peuvent aussi être fournis ou générés (indexes de formes, d’attributs, métadonnées au format xml…)."
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#le-geopackage",
    "href": "GEO1_carto_vecteurs.html#le-geopackage",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Le GeoPackage",
    "text": "Le GeoPackage\nLe GeoPackage est un format de données spatiales vectorielles et raster non propriétaire et défini selon les standards de l’Open Geospatial Consortium (OGC). Il se comprend comme un fichier base de données qui peut contenir des objets vectoriels, les tuiles d’images, des données raster, des schémas de métadonnées comme ceux des normes INSPIRE.\nHormis le format ouvert et l’interopérabilité, l’avantage du géopackage est qu’il peut se requêter comme une base de données avec du SQL dans QGIs, R ou ailleurs, et qu’il peut stocker dans un même fichier plusieurs couches raster ou vecteur. Cela facilite grandement l’organisation et la gestion de projets en géomatique.\nOn peut par exemple organiser son travail autour du GeoPackage de différente façon :\n\nun géopagkage par projet\nun géopackage par echelle ou zone de travail (monde, tunisie)\nun géopagkage par type d’utilisation (géotraitements et versionnage ou cartographie)\n\nLa figure suivante illustre la différence d’organisation ou d’arborescence fichiers dans le cas d’utilisation de fichiers au format shapefile ou GéoPackage"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#anatomie-dun-objet-sf",
    "href": "GEO1_carto_vecteurs.html#anatomie-dun-objet-sf",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Anatomie d’un objet sf",
    "text": "Anatomie d’un objet sf\nUn objet sf se présente comme un tableau de données data.frame, soit comme une table attributaire, à laquelle on ajoute une colonne geom ou geometry spécifique, de classe sfc (simple feature column) contenant les géométries (simple feature geometry). Chaque ligne, chaque individu est appelé simple feature.\n\nDans l’écosystème R, le data.frame est conçu comme une structure de vecteurs. Chaque colonne correspond à un vecteur et peut donc prendre tous les types que peuvent prendre des vecteurs (character, integer, numeric, boolean etc…). On peut donc effectuer sur les objets sf les même manipulations que l’on fait sur les vecteurs et tableaux dans R.\nLa colonne contenant les géométries peut quant à elle prendre les types de géométrie traditionnels pris en charge par les GeoJSON :\n\n\n\n\n\n\n\ntype\ndescription\n\n\n\n\nPOINT\ngéométrie à zéro dimension contenant un seul point\n\n\nLINESTRING\nséquence de points reliés par des morceaux de lignes droites qui ne se coupent pas entre elles ; géométrie unidimensionnelle\n\n\nPOLYGON\nGéométrie à aire positive (bidimensionnelle) ; une séquence de points forme un anneau fermé, non auto-intersecté ; le premier anneau désigne l’anneau extérieur, zéro ou plusieurs anneaux suivants désignent des trous dans cet anneau extérieur\n\n\nMULTIPOINT\nensemble de points ; un MULTIPOINT est simple si aucun des points du MULTIPOINT n’est égal.\n\n\nMULTILINESTRING\nensemble de LINESTRING\n\n\nMULTIPOLYGON\nensemble de POLYGON\n\n\nGEOMETRYCOLLECTION\nensemble de géométries de tout type sauf GEOMETRYCOLLECTION\n\n\n\nCette colonne se prête aux géotraitements typiques d’un SIG comme le buffer, l’intersection ou l’agrégation."
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#importer-et-exporter-des-données-spatiales-vectorielles-avec-sf",
    "href": "GEO1_carto_vecteurs.html#importer-et-exporter-des-données-spatiales-vectorielles-avec-sf",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Importer et Exporter des données spatiales vectorielles avec sf",
    "text": "Importer et Exporter des données spatiales vectorielles avec sf\n\nImporter des données\nChargement de la librairie\n\nlibrary(\"sf\")\n\nLa fonction st_read() de sf permet d’importer des formats de données géographiques variés (shapefile .shp, GeoPackage .GPKG, GeoJSON .geojson …). Avant l’importation d’un fichier au format Geopackage il est préconnisé de consulter le contenu du fichier.\nPour cela on utilise la fonction st_layers()\n\nst_layers(\"data/tun/geom/tun_admin.gpkg\")\n\nDriver: GPKG \nAvailable layers:\n   layer_name geometry_type features fields                      crs_name\n1  delegation Multi Polygon      266     11 ETRS89-extended / LAEA Europe\n2 gouvernorat Multi Polygon       24      4 ETRS89-extended / LAEA Europe\n3      region Multi Polygon        6      2 ETRS89-extended / LAEA Europe\n\n\n\nCette fonction nous donne quelques résumés sur chacune des couches du GeoPackage. Le nom, le type de géométrie, le nombre d’individus, le nombre de champs, et le CRS, la projection de chaque couche.\nNous pouvons à présent importer la couche “delegation” dans l’objet “del”\n\ndel &lt;- st_read(dsn = \"data/tun/geom/tun_admin.gpkg\", \n               layer = \"delegation\")\n\nReading layer `delegation' from data source \n  `/Users/claudegrasland1/worldregio/geounivr2024/data/tun/geom/tun_admin.gpkg' \n  using driver `GPKG'\nSimple feature collection with 266 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 4089658 ymin: 807127.5 xmax: 4473286 ymax: 1584946\nProjected CRS: ETRS89-extended / LAEA Europe"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#exporter-des-données",
    "href": "GEO1_carto_vecteurs.html#exporter-des-données",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Exporter des données",
    "text": "Exporter des données\nsf peut lire plusieurs formats géospatiaux et peut donc tout autant écrire ces formats à l’aide de la fonction st_write().\nCette fonction prend trois paramètres indispensables en entrée, l’objet à écrire obj =, son chemin d’écriture dsn =, la couche à écrirelayer =.\nPour l’exercice nous allons construire un GeoPackage de projet nommé mar1Vector.gpkg, dans lequel nous allons enregistrer notre couche del.\n\nst_write(obj = del, \n         dsn = \"data/tun/mar1Vector.gpkg\", \n         layer = \"delegation\")\n\nRemarquez qu’ici le chemin d’accès prend le nom complet du fichier et son extension. Ici le nom du GeoPackage et l’extension .gpkg. Si nous avions voulu exporter un GeoJSON, nous aurions écrit dsn = delegation.geojson\nQuelques paramètres additionnels sont utiles à connaître. Par exemple pour “écraser” ou remplacer une couche déja existante on utilise l’argument delete_layer = TRUE, lorsqu’il s’agit de remplacer le fichier delete_dsn = TRUE.\n\nst_write(obj = del, \n         dsn = \"data/tun/mar1Vector.gpkg\", \n         layer = \"delegation\", \n         delete_layer = TRUE)\n\n\nD’autres paramétrages sont possibles pour les autres types d’exports, pour cela référez-vous à la vignette du package"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#lobjet-et-la-table-attributaire-le-data.frame",
    "href": "GEO1_carto_vecteurs.html#lobjet-et-la-table-attributaire-le-data.frame",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "L’objet et la table attributaire (le data.frame)",
    "text": "L’objet et la table attributaire (le data.frame)\nPuisque l’objet sf est un data.frame, on peut faire des opérations typiques telles que :\nhead() pour en visualiser un extrait :\n\nhead(del)\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 4184398 ymin: 1282883 xmax: 4380989 ymax: 1539573\nProjected CRS: ETRS89-extended / LAEA Europe\n  del_code   del_nom_fr del_code_riate del_code_ins     del_nom_ar gou_code\n1 TN.SF.AG       Agareb         TS2146        TN347          عقارب    TN.SF\n2 TN.JE.AD   Ain Drahem         TS1224        TN225      عين دراهم    TN.JE\n3 TN.SS.AK       Akouda         TS2115        TN316          اكودة    TN.SS\n4 TN.KR.AL         Alaa         TS2216        TN417         العلاء    TN.KR\n5 TN.BJ.AM       Amdoun         TS1212        TN213          عمدون    TN.BJ\n6 TN.AN.AR Ariana Ville         TS1120        TN121 أريانة المدينة    TN.AN\n   gou_nom gou_cap gou_cap_dist reg_code      reg_nom\n1     Sfax       0         30.1       CE   Centre-est\n2 Jendouba       0         38.5       NO   Nord-ouest\n3   Sousse       0         14.3       CE   Centre-est\n4 Kairouan       0         48.6       CO Centre-ouest\n5     Beja       0         18.9       NO   Nord-ouest\n6   Ariana       1          1.0       NE     Nord-est\n                            geom\n1 MULTIPOLYGON (((4375308 130...\n2 MULTIPOLYGON (((4224769 152...\n3 MULTIPOLYGON (((4373533 142...\n4 MULTIPOLYGON (((4306097 141...\n5 MULTIPOLYGON (((4243838 153...\n6 MULTIPOLYGON (((4338370 153...\n\n\nstr() pour connaitre le type ou la classe de chaque champ :\n\nstr(del)\n\nClasses 'sf' and 'data.frame':  266 obs. of  12 variables:\n $ del_code      : chr  \"TN.SF.AG\" \"TN.JE.AD\" \"TN.SS.AK\" \"TN.KR.AL\" ...\n $ del_nom_fr    : chr  \"Agareb\" \"Ain Drahem\" \"Akouda\" \"Alaa\" ...\n $ del_code_riate: chr  \"TS2146\" \"TS1224\" \"TS2115\" \"TS2216\" ...\n $ del_code_ins  : chr  \"TN347\" \"TN225\" \"TN316\" \"TN417\" ...\n $ del_nom_ar    : chr  \"عقارب\" \"عين دراهم\" \"اكودة\" \"العلاء\" ...\n $ gou_code      : chr  \"TN.SF\" \"TN.JE\" \"TN.SS\" \"TN.KR\" ...\n $ gou_nom       : chr  \"Sfax\" \"Jendouba\" \"Sousse\" \"Kairouan\" ...\n $ gou_cap       : int  0 0 0 0 0 1 0 0 0 0 ...\n $ gou_cap_dist  : num  30.1 38.5 14.3 48.6 18.9 1 36.6 15.5 17.1 28.9 ...\n $ reg_code      : chr  \"CE\" \"NO\" \"CE\" \"CO\" ...\n $ reg_nom       : chr  \"Centre-est\" \"Nord-ouest\" \"Centre-est\" \"Centre-ouest\" ...\n $ geom          :sfc_MULTIPOLYGON of length 266; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:204, 1:2] 4375308 4375308 4379546 4379546 4379546 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geom\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:11] \"del_code\" \"del_nom_fr\" \"del_code_riate\" \"del_code_ins\" ...\n\n\n\ncolnames() pour connaitre le nom chaque champ :\n\ncolnames(del)\n\n [1] \"del_code\"       \"del_nom_fr\"     \"del_code_riate\" \"del_code_ins\"  \n [5] \"del_nom_ar\"     \"gou_code\"       \"gou_nom\"        \"gou_cap\"       \n [9] \"gou_cap_dist\"   \"reg_code\"       \"reg_nom\"        \"geom\"          \n\n\n\nou summary() pour avoir un résumé statistique de chaque champ :\n\nsummary(del)\n\n   del_code          del_nom_fr        del_code_riate     del_code_ins      \n Length:266         Length:266         Length:266         Length:266        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n  del_nom_ar          gou_code           gou_nom             gou_cap       \n Length:266         Length:266         Length:266         Min.   :0.00000  \n Class :character   Class :character   Class :character   1st Qu.:0.00000  \n Mode  :character   Mode  :character   Mode  :character   Median :0.00000  \n                                                          Mean   :0.09023  \n                                                          3rd Qu.:0.00000  \n                                                          Max.   :1.00000  \n  gou_cap_dist      reg_code           reg_nom                     geom    \n Min.   :  1.00   Length:266         Length:266         MULTIPOLYGON :266  \n 1st Qu.: 14.32   Class :character   Class :character   epsg:3035    :  0  \n Median : 24.40   Mode  :character   Mode  :character   +proj=laea...:  0  \n Mean   : 28.66                                                            \n 3rd Qu.: 41.38                                                            \n Max.   :147.40"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#les-géométries",
    "href": "GEO1_carto_vecteurs.html#les-géométries",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Les géométries",
    "text": "Les géométries\nPour connaitre le type de géométries on utilise la fonction st_geometry_type(). On peut rajouter l’argument by_geometry = FALSE pour avoir le type de l’ensemble.\n\nst_geometry_type(del, by_geometry = FALSE)\n\n[1] MULTIPOLYGON\n18 Levels: GEOMETRY POINT LINESTRING POLYGON MULTIPOINT ... TRIANGLE\n\n\nOn peut aussi visualiser les géométries avec la fonction plot() native de R.\nDans ce premier cas on obtient une carte par champs de la table attributaire\n\nplot(del)\n\n\n\n\nIl existe deux façons de ne veut visualiser que les géométries\n\n\n\nla fonction st_geometry() qui renvoi uniquement aux géométrie de l’objet sf\nplot(st_geometry(del))\n\n\n\n\n\n\n\nou on sélectionne le champs contenant les géométries\nplot(del$geom)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nPour plus de détail sur la cartographie avec le package sf voir le notebook de N. Lambert conçu pour l’école thématique : Faire des cartes thématiques avec R"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#changer-de-projection",
    "href": "GEO1_carto_vecteurs.html#changer-de-projection",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Changer de projection",
    "text": "Changer de projection\nLa fonction st_transform() permet de changer la projection d’un objet sf. Il est possible de passer d’un système de coordonnées géodésique à un système de coordonnées projetées et inversement.\nPar exemple on peut reprojeter les délégations en dans le système de référence tunisien, Carthage - EPSG:2028.\n\ndel2088 &lt;- st_transform(del, crs = \"EPSG:2088\")\n\nst_crs(del2088, parameters = TRUE)$Name\n\n[1] \"Carthage / TM 11 NE\"\n\n\nOu les reprojeter en WGS84 - World Geodetic System 1984\n\ndel4326 &lt;- st_transform(del, crs = \"EPSG:4326\")\n\nst_crs(del4326, parameters = TRUE)$Name\n\n[1] \"WGS 84\"\n\n\n\n\nCode\n# Initalisation de la fenêtre graphique\npar(mfrow = c(1,3),\n    mar = c(0, 2, 5, 2),\n    xaxs='i', yaxs='i')\n\n# Afficher les délégations avec la projection initiale\n\n# On dessine les géométries dans leur projection d'origine\nplot(st_geometry(del), border = \"lightblue\", lwd = 2, col = NA,\n     graticule = TRUE)\n\n# On ajoute en titre le nom de la projection et les unités de mesure\ntitle(paste0(crsDel$Name, \"\\n\", crsDel$units_gdal))\n\n\n# Carthage - EPSG:2088\nplot(st_geometry(del2088), border = \"lightblue\", lwd = 2, col = NA,\n     graticule = TRUE)\n\ntitle(paste0(st_crs(del2088, parameters = TRUE)$Name, \"\\n\",\n             st_crs(del2088, parameters = TRUE)$units_gdal)\n     )\n\n\n# WGS84 EPSG:4326\nplot(st_geometry(del4326), border = \"lightblue\", lwd = 2, col = NA,\n     graticule = TRUE)\n\ntitle(paste0(st_crs(del4326, parameters = TRUE)$Name, \"\\n\",\n             st_crs(del4326, parameters = TRUE)$units_gdal)\n     )\n\n\n\n\n\nPour conserver la projection adaptée à la tunisie on reprojete del en EPSG:2088\n\ndel &lt;- st_transform(del, crs = \"EPSG:2088\")\n\nst_crs(del, parameters = TRUE)$Name\n\n[1] \"Carthage / TM 11 NE\""
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#sélectionner-par-attributs",
    "href": "GEO1_carto_vecteurs.html#sélectionner-par-attributs",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Sélectionner par attributs",
    "text": "Sélectionner par attributs\nComme les data.frame on peut sélectionner des lignes et des colonnes des objets sf en utilisant les crochets :\nmonSF[lignes , colonnes]\n\nSelectionner des lignes\nOn peut donc afficher les 5 premières lignes de l’objet del grace à leur index\n\ndel[1:5,]\n\nSimple feature collection with 5 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 275294.7 ymin: 3827226 xmax: 467583.4 ymax: 4087746\nProjected CRS: Carthage / TM 11 NE\n  del_code del_nom_fr del_code_riate del_code_ins del_nom_ar gou_code  gou_nom\n1 TN.SF.AG     Agareb         TS2146        TN347      عقارب    TN.SF     Sfax\n2 TN.JE.AD Ain Drahem         TS1224        TN225  عين دراهم    TN.JE Jendouba\n3 TN.SS.AK     Akouda         TS2115        TN316      اكودة    TN.SS   Sousse\n4 TN.KR.AL       Alaa         TS2216        TN417     العلاء    TN.KR Kairouan\n5 TN.BJ.AM     Amdoun         TS1212        TN213      عمدون    TN.BJ     Beja\n  gou_cap gou_cap_dist reg_code      reg_nom                           geom\n1       0         30.1       CE   Centre-est MULTIPOLYGON (((462201.4 38...\n2       0         38.5       NO   Nord-ouest MULTIPOLYGON (((315372.8 40...\n3       0         14.3       CE   Centre-est MULTIPOLYGON (((461740 3974...\n4       0         48.6       CO Centre-ouest MULTIPOLYGON (((394811.9 39...\n5       0         18.9       NO   Nord-ouest MULTIPOLYGON (((334323 4081...\n\n\nOn peut aussi les sélectionner en fonction d’une valeur de champ. Par exemple :\n\ndel[del$del_nom_fr == \"Sousse Medina\", ]\n\nSimple feature collection with 1 feature and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 463418.8 ymin: 3961466 xmax: 469492.5 ymax: 3969566\nProjected CRS: Carthage / TM 11 NE\n    del_code    del_nom_fr del_code_riate del_code_ins   del_nom_ar gou_code\n242 TN.SS.SM Sousse Medina         TS2110        TN311 سوسة المدينة    TN.SS\n    gou_nom gou_cap gou_cap_dist reg_code    reg_nom\n242  Sousse       1            1       CE Centre-est\n                              geom\n242 MULTIPOLYGON (((464400.5 39...\n\n\n\n\nSelectionner des colonnes\nOn peut sélectionner les colonnes par leur index, par exemple pour les dernières colonnes :\n\ndel[, ncol(del)-5:ncol(del)]\n\nSimple feature collection with 266 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 178843.6 ymin: 3345646 xmax: 556188.8 ymax: 4132739\nProjected CRS: Carthage / TM 11 NE\nFirst 10 features:\n     gou_nom gou_code     del_nom_ar del_code_ins del_code_riate\n1       Sfax    TN.SF          عقارب        TN347         TS2146\n2   Jendouba    TN.JE      عين دراهم        TN225         TS1224\n3     Sousse    TN.SS          اكودة        TN316         TS2115\n4   Kairouan    TN.KR         العلاء        TN417         TS2216\n5       Beja    TN.BJ          عمدون        TN213         TS1212\n6     Ariana    TN.AN أريانة المدينة        TN121         TS1120\n7  Kasserine    TN.KS         العيون        TN428         TS2227\n8      Tunis    TN.TU        باب بحر        TN113         TS1112\n9      Tunis    TN.TU      باب سويقة        TN114         TS1113\n10  Jendouba    TN.JE    بلطة بوعوان        TN229         TS1228\n         del_nom_fr del_code                           geom\n1            Agareb TN.SF.AG MULTIPOLYGON (((462201.4 38...\n2        Ain Drahem TN.JE.AD MULTIPOLYGON (((315372.8 40...\n3            Akouda TN.SS.AK MULTIPOLYGON (((461740 3974...\n4              Alaa TN.KR.AL MULTIPOLYGON (((394811.9 39...\n5            Amdoun TN.BJ.AM MULTIPOLYGON (((334323 4081...\n6      Ariana Ville TN.AN.AR MULTIPOLYGON (((428017.4 40...\n7             Ayoun TN.KS.AY MULTIPOLYGON (((319476.8 39...\n8          Bab Bhar TN.TU.BB MULTIPOLYGON (((427125.6 40...\n9        Bab Souika TN.TU.BS MULTIPOLYGON (((425857.3 40...\n10 Balta Bou Aouane TN.JE.BB MULTIPOLYGON (((323552 4060...\n\n\nOn peut aussi les selectionner par leur nom\n\ndel[, c(\"del_nom_fr\", \"gou_nom\", \"reg_nom\")]\n\nSimple feature collection with 266 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 178843.6 ymin: 3345646 xmax: 556188.8 ymax: 4132739\nProjected CRS: Carthage / TM 11 NE\nFirst 10 features:\n         del_nom_fr   gou_nom      reg_nom                           geom\n1            Agareb      Sfax   Centre-est MULTIPOLYGON (((462201.4 38...\n2        Ain Drahem  Jendouba   Nord-ouest MULTIPOLYGON (((315372.8 40...\n3            Akouda    Sousse   Centre-est MULTIPOLYGON (((461740 3974...\n4              Alaa  Kairouan Centre-ouest MULTIPOLYGON (((394811.9 39...\n5            Amdoun      Beja   Nord-ouest MULTIPOLYGON (((334323 4081...\n6      Ariana Ville    Ariana     Nord-est MULTIPOLYGON (((428017.4 40...\n7             Ayoun Kasserine Centre-ouest MULTIPOLYGON (((319476.8 39...\n8          Bab Bhar     Tunis     Nord-est MULTIPOLYGON (((427125.6 40...\n9        Bab Souika     Tunis     Nord-est MULTIPOLYGON (((425857.3 40...\n10 Balta Bou Aouane  Jendouba   Nord-ouest MULTIPOLYGON (((323552 4060...\n\n\n\n\nCombiner les selections\nEnfin on peut combiner les selections\n\ndelSousse &lt;- del[del$gou_nom %in% \"Sousse\", c(\"del_nom_fr\", \"gou_nom\", \"reg_nom\")]\n\ndelSousse\n\nSimple feature collection with 16 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 422897.2 ymin: 3933116 xmax: 469492.5 ymax: 4028665\nProjected CRS: Carthage / TM 11 NE\nFirst 10 features:\n       del_nom_fr gou_nom    reg_nom                           geom\n3          Akouda  Sousse Centre-est MULTIPOLYGON (((461740 3974...\n36       Bouficha  Sousse Centre-est MULTIPOLYGON (((458390.3 40...\n67        Enfidha  Sousse Centre-est MULTIPOLYGON (((452021.2 40...\n100 Hammam Sousse  Sousse Centre-est MULTIPOLYGON (((461739.9 39...\n107        Hergla  Sousse Centre-est MULTIPOLYGON (((452737.5 39...\n124  Kalaa Kebira  Sousse Centre-est MULTIPOLYGON (((454231.3 39...\n125 Kalaâ Seghira  Sousse Centre-est MULTIPOLYGON (((459976.1 39...\n138        Kondar  Sousse Centre-est MULTIPOLYGON (((439303 3970...\n181        Msaken  Sousse Centre-est MULTIPOLYGON (((457987.4 39...\n221   Sid Bou Ali  Sousse Centre-est MULTIPOLYGON (((455032.2 39...\n\n\nEt on peut afficher cette sélection\n\n# Parametre de l'affichage\npar(mar = c(0, 0, 4, 0),  xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\nplot(st_geometry(delSousse), col = \"#5B89A3\", border = \"white\", lwd = 2)\ntitle(paste(unique(delSousse$gou_nom)))"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#jointure-attributaire",
    "href": "GEO1_carto_vecteurs.html#jointure-attributaire",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Jointure attributaire",
    "text": "Jointure attributaire\nAvec la fonction merge() on peut joindre les données d’un autre data.frame à un objet sf et inversement via un champ de jointure commun.\nOn importe d’autres données du projet\n\n# Importer les fichiers locaux\ndel_df &lt;- read.csv(\"data/tun/don_del.csv\", sep = \";\", dec = \",\")\n\nOn identifie le champ de jointure\n\ndel[1:2,]\n\nSimple feature collection with 2 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 275294.7 ymin: 3827226 xmax: 467583.4 ymax: 4087746\nProjected CRS: Carthage / TM 11 NE\n  del_code del_nom_fr del_code_riate del_code_ins del_nom_ar gou_code  gou_nom\n1 TN.SF.AG     Agareb         TS2146        TN347      عقارب    TN.SF     Sfax\n2 TN.JE.AD Ain Drahem         TS1224        TN225  عين دراهم    TN.JE Jendouba\n  gou_cap gou_cap_dist reg_code    reg_nom                           geom\n1       0         30.1       CE Centre-est MULTIPOLYGON (((462201.4 38...\n2       0         38.5       NO Nord-ouest MULTIPOLYGON (((315372.8 40...\n\n\n\ndel_df[1:2,]\n\n  del_code      del_nom_fr     del_nom_ar gou_code gou_nom gou_cap gou_cap_dist\n1 TN.AN.AR    Ariana Ville أريانة المدينة       AN  Ariana       1          1.0\n2 TN.AN.ET Cité Ettathamen     حي التضامن       AN  Ariana       0          8.8\n  reg_code  reg_nom popto_2004 popco_2004 immig_2004 emigr_2004 mobil_2004\n1       NE Nord-est      97687      97687      16961      15426      32387\n2       NE Nord-est      78311      78311       5651       5245      10896\n  menag_2004 ordin_2004 porta_2004 telef_2004 popto_2014 popco_2014 immig_2014\n1      27468       9751      22524      18596     114486     114486      15637\n2      11950        430       4505       3824      84312      84312       5028\n  emigr_2014 mobil2014 menag_2014 ordin_2014 porta_2014 telef_2014 popto_2010\n1      20448     36085      32498      25474      32308      19942     109500\n2       6752     11780      22087       6836      21715       3496      82922\n  surfa_2010 idr_2011\n1     18.612    0.638\n2      3.376    0.386\n\n\nIci les deux colonnes identiques ont aussi le même nom. On choisi d’utiliser les codes pour la jointure :\n\ndelMerge &lt;- merge(x = del,\n                  y = del_df, \n                  by.x = \"del_code\",\n                  by.y = \"del_code\",\n                  all.x = TRUE)\n\nAttention, le sens de la jointure est important. Ici l’objet “x” est l’objet auquel on joint le second. L’objet final prend le type de l’objet x. Ici nous avons créé un nouvel objet delMerge qui résulte de la jointure de del_def à del. del_mergeprend donc le type de del. C’est un objetsf.\nLa ligne all.x signifie que l’on conserve tous les individus du tableau “x” meme si la correspondance est manquante dans le tableau “y”.\n\n# Les deux objets ont bien été joints\nhead(delMerge, 3)\n\nSimple feature collection with 3 features and 40 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 411876.4 ymin: 4075789 xmax: 429940.1 ymax: 4109337\nProjected CRS: Carthage / TM 11 NE\n  del_code       del_nom_fr.x del_code_riate del_code_ins   del_nom_ar.x\n1 TN.AN.AR       Ariana Ville         TS1120        TN121 أريانة المدينة\n2 TN.AN.ET    Cité Ettathamen         TS1125        TN126     حي التضامن\n3 TN.AN.KA kalaât El Andalous         TS1123        TN124   قلعة الاندلس\n  gou_code.x gou_nom.x gou_cap.x gou_cap_dist.x reg_code.x reg_nom.x\n1      TN.AN    Ariana         1            1.0         NE  Nord-est\n2      TN.AN    Ariana         0            8.8         NE  Nord-est\n3      TN.AN    Ariana         0           19.8         NE  Nord-est\n        del_nom_fr.y   del_nom_ar.y gou_code.y gou_nom.y gou_cap.y\n1       Ariana Ville أريانة المدينة         AN    Ariana         1\n2    Cité Ettathamen     حي التضامن         AN    Ariana         0\n3 kalaât El Andalous   قلعة الاندلس         AN    Ariana         0\n  gou_cap_dist.y reg_code.y reg_nom.y popto_2004 popco_2004 immig_2004\n1            1.0         NE  Nord-est      97687      97687      16961\n2            8.8         NE  Nord-est      78311      78311       5651\n3           19.8         NE  Nord-est      23045      15313        728\n  emigr_2004 mobil_2004 menag_2004 ordin_2004 porta_2004 telef_2004 popto_2014\n1      15426      32387      27468       9751      22524      18596     114486\n2       5245      10896      11950        430       4505       3824      84312\n3        528       1256       4709        188       1865        829      26796\n  popco_2014 immig_2014 emigr_2014 mobil2014 menag_2014 ordin_2014 porta_2014\n1     114486      15637      20448     36085      32498      25474      32308\n2      84312       5028       6752     11780      22087       6836      21715\n3      18211       1104        752      1856       6554       1701       6305\n  telef_2014 popto_2010 surfa_2010 idr_2011                           geom\n1      19942     109500     18.612    0.638 MULTIPOLYGON (((428017.4 40...\n2       3496      82922      3.376    0.386 MULTIPOLYGON (((420275.4 40...\n3        428      24367    188.206    0.383 MULTIPOLYGON (((423864.5 41..."
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#sélections-spatiales",
    "href": "GEO1_carto_vecteurs.html#sélections-spatiales",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Sélections spatiales",
    "text": "Sélections spatiales\nLes sélections spatiales s’exécutent avec la fonction st_filter() et selon les prédicats géométriques suivants :\n\nst_intersects()\nst_disjoint()\nst_touches()\nst_crosses()\nst_within()\nst_contains()\nst_contains_properly()\nst_overlaps()\nst_equals()\nst_covers()\nst_covered_by()\nst_equals_exact()\nst_is_within_distance()\n\n\n\n\n\n\n\nTip\n\n\n\nVoir la vignette sf\n\n\nOn importe les géométries extraites de OSM dans le module sur la Manipulation des données\n\n\n\n\n\n\nTip\n\n\n\nPour plus de détail sur l’extraction de données OSM voir le notebook de R. Ysebaert conçu pour l’école thématique : Acquisition de données géographiques et visualisations de base\n\n\n\n# Consulter le contenu du géopackage \"tun_osm\"\nst_layers(\"data/tun/geom/tun_osm.gpkg\")\n\nDriver: GPKG \nAvailable layers:\n  layer_name geometry_type features fields crs_name\n1      deleg Multi Polygon      266      7   WGS 84\n2       sect Multi Polygon     2104      7   WGS 84\n3        poi         Point    11571      4   WGS 84\n\n# Charger les données ponctuelles\npoi &lt;- st_read(\"data/tun/geom/tun_osm.gpkg\", \n               layer = \"poi\")\n\nReading layer `poi' from data source \n  `/Users/claudegrasland1/worldregio/geounivr2024/data/tun/geom/tun_osm.gpkg' \n  using driver `GPKG'\nSimple feature collection with 11571 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 5.364165 ymin: 31.00284 xmax: 14.74145 ymax: 44.40715\nGeodetic CRS:  WGS 84\n\n# Extrait des données chargées\nhead(poi)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 5.364165 ymin: 33.23918 xmax: 10.86563 ymax: 43.31226\nGeodetic CRS:  WGS 84\n     osm_id          amenity             name_ar                     name_fr\n1 255880618   ferry_terminal   محطة آرنك البحرية                        &lt;NA&gt;\n2 262728007          parking                &lt;NA&gt;                        &lt;NA&gt;\n3 283583078         pharmacy   الصيدلية المركزية          Pharmacie Centrale\n4 283658474   ferry_terminal                &lt;NA&gt;                        &lt;NA&gt;\n5 290891538             bank بنك قطر الوطني تونس Qatar National Bank Tunisia\n6 297765095 place_of_worship             الغريبة      Synagogue de la Ghriba\n                       geom\n1 POINT (5.364165 43.31226)\n2 POINT (10.86563 33.23918)\n3 POINT (10.18092 36.83346)\n4 POINT (10.30467 36.80743)\n5  POINT (10.5971 35.83918)\n6 POINT (10.85939 33.81392)\n\n\nPour que la sélection spatiale fonctionne il faut s’assurer que les deux objets possèdent le meme système de coordonnées de référence\n\n# Nom du SCR de \"del\"\nst_crs(del, parameters = TRUE)$srid\n\n[1] \"EPSG:2088\"\n\n# Nom du SCR de \"poi\"\nst_crs(poi, parameters = TRUE)$srid\n\n[1] \"EPSG:4326\"\n\n\nIci ils ne concordent pas donc :\n\n# Re projection en \npoi &lt;- st_transform(poi, crs = \"EPSG:2088\")\n\n# Verification du SCR\nst_crs(poi, parameters = TRUE)$srid\n\n[1] \"EPSG:2088\"\n\n\nOn peut maintenant réaliser notre sélection spatiale. Ici on va sélectionner les points qui se trouvent dans l’objet delSousse que l’on a construit plus haut.\n\npoiSousse &lt;- st_filter(x = poi, \n                       y = delSousse,\n                       .predicate = st_within)\n\nOn visualise le résultat\n\n\nCode\n# Parametre de l'affichage\npar(mar = c(0, 0, 4, 0),  xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\n# Initialisation de la carte à l'emprise de Sousse\nplot(st_geometry(delSousse), col = NA, border = NA)\n\n# Fond de carte des délégations\nplot(st_geometry(del), col = \"gray80\", border = \"white\", lwd = 1, add = TRUE)\n\n# Délégations de Soussz\nplot(st_geometry(delSousse), col = \"#5B89A3\", border = \"white\", lwd = 2, add = TRUE)\n\n# Points remarquables de Souss\nplot(st_geometry(poiSousse), col = \"red\", border = \"white\", pch = 19, cex = .3, add = TRUE)\n\n# Titre\ntitle(\"Points remarquables \\ndu Gouvernorat de Sousse\")"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#sec-centro",
    "href": "GEO1_carto_vecteurs.html#sec-centro",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Extraction de centroides",
    "text": "Extraction de centroides\nLa fonction st_centroid() permet d’extraire les centroides des polygones.\nIci on extrait les centroides des délégations de Sousse :\n\ndelSousse_c &lt;- st_centroid(delSousse)\n\n\n# Parametre de l'affichage\npar(mar = c(0, 0, 0, 0),  xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\n# Délégations de Sousse\nplot(st_geometry(delSousse), col = \"#5B89A3\", border = \"white\")\n\n# Centroides des délégations de Sousse\nplot(st_geometry(delSousse_c), add = TRUE, pch = 20, col = \"pink\")"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#agrégation-de-polygones",
    "href": "GEO1_carto_vecteurs.html#agrégation-de-polygones",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Agrégation de polygones",
    "text": "Agrégation de polygones\n\nAgrégation spatiale\nLa fonction st_union() permet d’agréger des polygones entre eux. Par exemple pour reconstituer le gouvernorat de Sousse\n\ngouSousse &lt;- st_union(delSousse)\n\n\n\nCode\n# Parametre de l'affichage\npar(mar = c(0, 0, 0, 0),  xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\n# Initialisation de la carte à l'emprise de Sousse\nplot(st_geometry(delSousse), col = NA, border = NA)\n\n# Fond de carte des délégations\nplot(st_geometry(del), col = \"gray80\", border = \"white\", lwd = 1, add = TRUE)\n\n# Délégations de Sousse\nplot(st_geometry(delSousse), col = \"#5B89A3\", border = \"white\", lwd = 1, add = TRUE)\n\n# Gouvernorat de Sousse\nplot(st_geometry(gouSousse), border = \"darkblue\", lwd = 3, add = TRUE)\n\n\n\n\n\n\n\nAgrégation spatiale et attributaire\nOn peut aussi agréger les polygones et demander un résumé statistique pour un ou plusieurs champ décrivant ces polygones. Plusieurs méthodes permettent de réaliser cet objectif.\nLa première méthode mobilise la fonction aggregate() de sf. Cette fonction permet d’agréger les polygones et de demander le même résumé statistique pour plusieurs champs.\nDans cet exemple nous repartons de l’objet delMerge issu de la fusion entre les géométries des délégations et le tableau additionnel. L’objectif est de construire un objet gou représentant les gouvernorats et leur population. Pour y arriver, nous fusionnons toutes les délégations via le champ gou_nom.x et calculons la somme de la population pour chacun.\n\ngou &lt;- aggregate(\n  x = delMerge[c(\"popto_2014\", \"immig_2014\")], \n  by = list(gou_nom = delMerge$gou_nom.x), \n  FUN = sum\n)\n\n\n\nCode\n# Parametre de l'affichage\npar(mar = c(0, 0, 0, 0),  xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\n# Fond de carte des délégations\nplot(st_geometry(del), col = \"gray80\", border = \"white\", lwd = 1)\n\n# Gouvernorats\nplot(st_geometry(gou), border = \"#5B89A3\", lwd = 2, add = TRUE)\n\n\n\n\n\nLes fonctions group_by() et summarise() du package dplyr permettent d’agréger les polygones en demandant des résumés statistiques différents selon les champs.\n\nlibrary(dplyr)\n\ngou &lt;- delMerge |&gt; \n  group_by(gou_nom.x) |&gt; \n  summarise(pop = sum(popto_2014),\n            immig_mean = mean(immig_2014))\n\n\ngou[1:3, ]\n\nSimple feature collection with 3 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 313571.7 ymin: 4026799 xmax: 445046.3 ymax: 4113741\nProjected CRS: Carthage / TM 11 NE\n# A tibble: 3 × 4\n  gou_nom.x    pop immig_mean                                               geom\n  &lt;chr&gt;      &lt;int&gt;      &lt;dbl&gt;                                      &lt;POLYGON [m]&gt;\n1 Ariana    576088     11297. ((419782.2 4077626, 419782.2 4077626, 419782.2 40…\n2 Beja      303032      1049. ((350635.1 4027850, 350635.1 4027850, 350635.1 40…\n3 Ben Arous 631842      6088  ((442640 4056428, 442640 4056428, 442640 4056428,…"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#construction-dune-zone-tampon-buffer",
    "href": "GEO1_carto_vecteurs.html#construction-dune-zone-tampon-buffer",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Construction d’une zone tampon (buffer)",
    "text": "Construction d’une zone tampon (buffer)\nPour construire la zone tampon il est préférable de connaître le SCR et l’unité de mesure de l’objet sf, par exemple avec cette fonction.\n\nst_crs(delSousse_c)$units\n\n[1] \"m\"\n\n\nLes mesures sont exprimées en metres, on peut à présent utiliser la fonction st_buffer() pour construire la zone tampon.\nIci on peut construire une zone tampon autour du centroide de la délégation de Sidi Bou Ali\n\n# Sélection du centroide de Sidi Bou Ali \nsidiBou_c &lt;- delSousse_c[delSousse_c$del_nom_fr %in% \"Sid Bou Ali\", ]\n\nEt on construit la zone tampon de 3000 m soit 5km\n\nsidiBou_t &lt;- st_buffer(sidiBou_c, dist = 5000)\n\n\n\nCode\n# Parametre de l'affichage\npar(mar = c(0, 0, 0, 0),  xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\n# Initialisation de la carte à l'emprise de Sousse\nplot(st_geometry(delSousse), col = NA, border = NA)\n\n# Fond de carte des délégations\nplot(st_geometry(del), col = \"gray80\", border = \"white\", lwd = 1, add = TRUE)\n\n# Délégations de Sousse\nplot(st_geometry(delSousse), col = \"#5B89A3\", border = \"white\", lwd = 1, add = TRUE)\n\n# Gouvernorat de Sousse\nplot(st_geometry(gouSousse), border = \"darkblue\", lwd = 3, add = TRUE)\n\n# Zone tampon de 5km autour du centroide de Sidi Bou Ali\nplot(st_geometry(sidiBou_t), border = \"pink\", col = \"#fac0cb50\", lwd = 2, add = TRUE)\n\n# Centroide de Sidi Bou Ali\nplot(st_geometry(sidiBou_c), col = \"pink\", pch = 20, cex = 2, add = TRUE)"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#sec-inter",
    "href": "GEO1_carto_vecteurs.html#sec-inter",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Intersection",
    "text": "Intersection\nLa fonction st_intersection() permet de découper une couche par une autre.\nOn peut ici par exemple, découper la couche poi des points remarquables, par le centroide de la délégation de Sidi Bou Ali.\n\npoi_sidiBou &lt;- st_intersection(x = sidiBou_t, y = poiSousse)\n\n\n\nCode\n# Parametre de l'affichage\npar(mar = c(0, 0, 0, 0),  xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\n# Initialisation de la carte à l'emprise de Sousse\nplot(st_geometry(delSousse), col = NA, border = NA)\n\n# Fond de carte des délégations\nplot(st_geometry(del), col = \"gray80\", border = \"white\", lwd = 1, add = TRUE)\n\n# Délégations de Sousse\nplot(st_geometry(delSousse), col = \"#5B89A3\", border = \"white\", lwd = 1, add = TRUE)\n\n# Gouvernorat de Sousse\nplot(st_geometry(gouSousse), border = \"darkblue\", lwd = 3, add = TRUE)\n\n# Zone tampon de 5km autour du centroide de Sidi Bou Ali\nplot(st_geometry(sidiBou_t), border = \"pink\", col = \"#fac0cb50\", lwd = 2, add = TRUE)\n\n# Centroide de Sidi Bou Ali\nplot(st_geometry(sidiBou_c), col = \"pink\", pch = 20, cex = 2, add = TRUE)\n\nplot(st_geometry(poi_sidiBou), col = \"red\", border = \"white\", pch = 19, cex = .5, add = TRUE)"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#compter-les-points",
    "href": "GEO1_carto_vecteurs.html#compter-les-points",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Compter les points",
    "text": "Compter les points\nLa fonction st_intersects() permet d’intersecter deux couches sans les découper, et de compter les éléments d’une couche (y) contenue dans une autre (x).\nL’argument sparse = TRUE nous permet de lister pour chaque élément de x les objets de y.\n\ninter &lt;- st_intersects(x = sidiBou_t, y = poi_sidiBou)\n\ninter\n\nSparse geometry binary predicate list of length 1, where the predicate\nwas `intersects'\n 1: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\n\n\nLe 1: signifie qu’il y a un objet, une 1 liste. Les chiffres suivants sont les identifiants de chacun des points.\nPour vérifier que le nombre d’intersection corresponde bien au nombre d’objets intersectés de x, ici il s’agit de sidiBou_t on fait :\n\nlength(inter) == nrow(sidiBou_t)\n\n[1] TRUE\n\n\nPour compter le nombre de points intersectés par sidiBou_t on utilise la fonction lengths() qui renvoie la longueurs de chaque liste de l’intersection.\n\nlengths(inter)\n\n[1] 11\n\n\nOn peut ajouter cette information à la table attributaire de sidiBou_t en créant un nouveau champ nb_poi\n\nsidiBou_t$nb_poi &lt;- lengths(inter)\n\nSur la base de cet exemple on peut compter les points dans les gouvernorats créé dans la Section 7.2.2\n\ninterGou &lt;- st_intersects(x = gou, y = poi)\n\ninterGou\n\nSparse geometry binary predicate list of length 24, where the predicate\nwas `intersects'\nfirst 10 elements:\n 1: 68, 125, 149, 160, 173, 174, 177, 186, 193, 195, ...\n 2: 24, 260, 1206, 1322, 1323, 1708, 1710, 1711, 1712, 1713, ...\n 3: 69, 70, 71, 72, 73, 74, 75, 96, 97, 262, ...\n 4: 276, 277, 278, 289, 329, 330, 1297, 1597, 1728, 1729, ...\n 5: 94, 746, 761, 762, 763, 784, 785, 787, 809, 810, ...\n 6: 695, 1215, 1216, 1217, 1218, 1249, 1746, 1747, 1748, 1780, ...\n 7: 23, 549, 550, 1544, 1545, 1546, 1547, 1548, 1550, 1551, ...\n 8: 19, 261, 364, 505, 506, 764, 765, 766, 767, 768, ...\n 9: 1739, 2175, 2985, 2986, 2987, 2988, 3001, 3002, 3003, 3004, ...\n 10: 29, 145, 1208, 1219, 1220, 1221, 1222, 1223, 1224, 1225, ...\n\n# Le nombre d'intersections est-il égal aux objets de gou\nlength(interGou) == nrow(gou)\n\n[1] TRUE\n\n# combien y a t il de points par intersection\nlengths(interGou)\n\n [1]  292  117  705  183  276  225  143  239  277  165   85  277   56  361  508\n[16] 1406 1336  262  100  767  316   90 2505   91\n\n# Ajout du nombre de points intersectés à l'objet gou\ngou$nb_poi &lt;- lengths(interGou)\n\nEt on peut cartographier ce résultat avec le package mapSf\n\nlibrary(mapsf)\n\n# intitialisation du fond de carte\nmf_map(x = gou, border = \"white\", lwd = 0.5)\n\n# cartographie du nombre de points en cercles proportionnels\nmf_map(x = gou,\n       var = \"nb_poi\",\n       type = \"prop\",\n       border = \"white\",\n       col = \"#FF000080\",\n       leg_title = \"Nombre de points remarquables\",\n       inches   = 0.4, leg_pos  = \"topright\")\n\n# Habillage\nmf_layout(title = \"Equipements dans les gouvernorats\", arrow = TRUE, scale = TRUE, credits = \"GeoUnivR 2024 - Tunisie\")\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nPour plus de détail sur la cartographie avec le package mapsf voir le notebook de N. Lambert conçu pour l’école thématique : Faire des cartes thématiques avec R"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#changer-de-type-de-géométrie",
    "href": "GEO1_carto_vecteurs.html#changer-de-type-de-géométrie",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Changer de type de géométrie",
    "text": "Changer de type de géométrie\nIl est possible de convertir une géométrie en un autre type, par exemple convertir des géométries de type POLYGON à LINESTRING, avec la fonction st_cast() de sf.\nPour connaitre le type de géométries\n\nst_geometry_type(del, by_geometry = FALSE)\n\n[1] MULTIPOLYGON\n18 Levels: GEOMETRY POINT LINESTRING POLYGON MULTIPOINT ... TRIANGLE\n\n\nIci on converti ces MULTIPOLYGON en MULTILINESTRING\n\ndel_line &lt;- st_cast(del, to = \"MULTILINESTRING\")"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#unités-de-mesures",
    "href": "GEO1_carto_vecteurs.html#unités-de-mesures",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Unités de mesures",
    "text": "Unités de mesures\nOn peut connaitre l’unité de mesure de la projection avec la fonction st_crs()\n\n\n\n\n\n\nDétail de st_crs(del)\n\n\n\n\n\n\nst_crs(del)\n\nCoordinate Reference System:\n  User input: EPSG:2088 \n  wkt:\nPROJCRS[\"Carthage / TM 11 NE\",\n    BASEGEOGCRS[\"Carthage\",\n        DATUM[\"Carthage\",\n            ELLIPSOID[\"Clarke 1880 (IGN)\",6378249.2,293.466021293627,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4223]],\n    CONVERSION[\"TM 11 NE\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",11,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Oil and gas exploration and production.\"],\n        AREA[\"Tunisia - offshore.\"],\n        BBOX[33.22,7.81,38.41,13.67]],\n    ID[\"EPSG\",2088]]\n\n\n\n\n\nUne méthode plus directe consiste à aller chercher précisément cette information dans ce que renvoie cette fonction :\n\nst_crs(del, parameters = TRUE)$units_gdal\n\n[1] \"metre\""
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#calculs",
    "href": "GEO1_carto_vecteurs.html#calculs",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Calculs",
    "text": "Calculs\n\nCalcul de superficie\nPour calculer la superficie on utilise la fonction st_area(). Elle renvoie une valeur dans l’unité de mesure de l’objet sf. Ici en metres carrés.\n\n# Superficie des 5 premier-es délégations\nst_area(del[1:5, ])\n\nUnits: [m^2]\n[1] 715991519 462714091  44463342 805121622 238700382\n\n\nOn peut enregistrer cette information dans l’objet\n\ndel$area &lt;- st_area(del)\n\n\n\nCalcul de longueur\nLe calcul de longueur ne s’applique qu’aux types LINESTRING et MULTILINESTRING.\n\nst_length(del_line[1:5, ])\n\nUnits: [m]\n[1] 123930.04 130232.45  34469.44 159296.09  80536.48\n\ndel_line$perimetre &lt;- st_length(del_line)\n\n\n\nCalcul de distance\nOn peut calculer la distance entre deux points avec la fonction st_distance().\nDans le cas d’objets géographiques de type POLYGONS, le calcul de distance s’effectue automatiquement entre leurs centroides.\nLe résultat du calcul est une matrice de distance entre tous les points.\n\nst_distance(del[1:5, ])\n\nUnits: [m]\n          [,1]     [,2]      [,3]      [,4]     [,5]\n[1,]      0.00 244010.5 109399.42  91764.93 229873.3\n[2,] 244010.51      0.0 167738.93 116685.25      0.0\n[3,] 109399.42 167738.9      0.00  62508.93 150025.5\n[4,]  91764.93 116685.2  62508.93      0.00 106360.3\n[5,] 229873.27      0.0 150025.46 106360.32      0.0\n\n\nIci l’unité de mesure de la distance est le metre. On peut modifier cette unité grace au package units et de la fonction set_units(). Il ne s’agit pas ici de modifier l’unité de tout l’objet sf mais seulement des objets créés lors des calculs.\nPar exemple en reprenant notre calcul de distances en metres dans un nouvel objet :\n\ndistances &lt;- st_distance(del[1:5, ])\n\nOn peut les convertir en kilometres (km)\n\n# Chargement du package\nlibrary(units)\n\n# Modification de l'unité\nset_units(x = distances, value = km)\n\nUnits: [km]\n          [,1]     [,2]      [,3]      [,4]     [,5]\n[1,]   0.00000 244.0105 109.39942  91.76493 229.8733\n[2,] 244.01051   0.0000 167.73893 116.68525   0.0000\n[3,] 109.39942 167.7389   0.00000  62.50893 150.0255\n[4,]  91.76493 116.6852  62.50893   0.00000 106.3603\n[5,] 229.87327   0.0000 150.02546 106.36032   0.0000\n\n\nPour que le résultat soit conservé :\n\ndistances &lt;- set_units(x = distances, value = km)"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#simplifier-les-géométries",
    "href": "GEO1_carto_vecteurs.html#simplifier-les-géométries",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Simplifier les géométries",
    "text": "Simplifier les géométries\nLa fonction st_simplify() de sfpermet de généraliser des géométries.\n\ndel_simp_sf &lt;- st_simplify(del, dTolerance = 5000, preserveTopology = TRUE)\n\nCett fonction n’est pas la plus éfficiace, on peut préférer utiliser la fonction ms_simplify() du package rmapshaper permet de généraliser ou simplifier les géométries en préservant la topologie.\n\nlibrary(rmapshaper)\n\n# simple généralisation des géométries\ndel_simp_rmap &lt;- ms_simplify(del)\n\nOn peut choisir la proportion de sommets à garder avec l’argument keep = ..., et forcer la conservation des formes avec keep_shapes = TRUE\n\n# Forte généralisation des géométries\ndel_simp_rmap2 &lt;- ms_simplify(del, keep = 0.001, keep_shapes = TRUE)\n\nVoici une comparaison de généralisation avec différents paramètres et avec la fonction st_simplify() de sf\n\npar(mfrow = c(1,4),\n    mar = c(0, 1, 3, 1),\n    xaxs='i', yaxs='i', \n    bg = \"#F1F3F5\")\n\nplot(del$geom, col = \"#5B89A3\", border = \"white\")\ntitle(\"Géométries \\ninitiales\")\n\nplot(del_simp_sf$geom, col = \"#5B89A3\", border = \"white\")\ntitle(\"Simplification avec sf\")\n\nplot(del_simp_rmap$geom, col = \"#5B89A3\", border = \"white\")\ntitle(\"Simplification avec \\nrMapshaper\")\n\nplot(del_simp_rmap2$geom, col = \"#5B89A3\", border = \"white\")\ntitle(\"Forte simplification \\navec rMapshaper\")"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#agréger-des-polygones-en-fonction-dune-variable",
    "href": "GEO1_carto_vecteurs.html#agréger-des-polygones-en-fonction-dune-variable",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Agréger des polygones en fonction d’une variable",
    "text": "Agréger des polygones en fonction d’une variable"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#digitalisation",
    "href": "GEO1_carto_vecteurs.html#digitalisation",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Digitalisation",
    "text": "Digitalisation\nLa digitalisation est une étape utile de la manipulation de données spatiales mais n’est pas reproductible.\nCertains packages de R permettent de réaliser ces opérations mais ne sont pas les plus adaptés car certains de Digitalisation : proposer des choses et préciser que ce n’est pas reproductible et quil peut y avoir des problèmes de topologie et suilhy des outils plus adaptés à ça. Qgis"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#construction-dune-grille-régulière",
    "href": "GEO1_carto_vecteurs.html#construction-dune-grille-régulière",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Construction d’une grille régulière",
    "text": "Construction d’une grille régulière\nLa fonction st_male_grid() permet la création d’une grille régulière sur l’emprise d’un objet géographique donné.\nCette fonction renvoi un objet de type sfc constitué de listes de cellules. Pour le manipuler facilement on le converti en objet sf avec la fonction st_sf() et en ajoutant un champ d’identifiants.\n\n# Création de la grille\ngrid &lt;- st_make_grid(gou, cellsize = 35000)\n\n# Ajout d'un identifiant unique et passage en sf \ngrid &lt;- st_sf(ID = 1:length(grid), geom = grid)\n\nhead(grid)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 178843.6 ymin: 3345646 xmax: 388843.6 ymax: 3380646\nProjected CRS: Carthage / TM 11 NE\n  ID                           geom\n1  1 POLYGON ((178843.6 3345646,...\n2  2 POLYGON ((213843.6 3345646,...\n3  3 POLYGON ((248843.6 3345646,...\n4  4 POLYGON ((283843.6 3345646,...\n5  5 POLYGON ((318843.6 3345646,...\n6  6 POLYGON ((353843.6 3345646,...\n\n\n\npar(mar = c(0, 0, 0, 0), xaxs='i', yaxs='i', bg = \"#F1F3F5\")\nplot(st_geometry(gou), col = \"#5B89A3\", border = \"white\", lwd = 1)\nplot(st_geometry(grid), col = NA, border = \"black\", lwd = 1, add = TRUE)\n\n\n\n\nIl est possible de créer des grilles hexagonales avec l’argument square = FALSE\n\ngrid_hex &lt;- st_make_grid(gou, cellsize = 35000, square = FALSE)\n\n# Ajout d'un identifiant unique et passage en sf \ngrid_hex &lt;- st_sf(ID = 1:length(grid_hex), geom = grid_hex)\n\n# Cartographie\npar(mar = c(0, 0, 0, 0), xaxs='i', yaxs='i', bg = \"#F1F3F5\")\nplot(st_geometry(gou), col = \"#5B89A3\", border = \"white\", lwd = 1)\nplot(st_geometry(grid_hex), col = NA, border = \"black\", lwd = 1, add = TRUE)\n\n\n\n\nOu de récuperer le centroide de ces polygones avec l’argument what = centers ou les angles avec what = corners\n\npar(mar = c(0, 0, 0, 0), xaxs='i', yaxs='i', bg = \"#F1F3F5\")\n\nplot(st_geometry(gou), col = \"#5B89A3\", border = \"white\", lwd = 1)\n\n# Les centres\nplot(st_make_grid(gou, cellsize = 35000, what = \"centers\"), col = \"red\", pch = 20, add = TRUE)\n\n# Les angles\nplot(st_make_grid(gou, cellsize = 35000, what = \"corners\"), col = \"pink\", pch = 3, add = TRUE)\n\n\n\n\n\nIntersecter la grille avec les points\nComme présenté dans la Section 7.4 on peut intersecter des points dans des polygones et les compter.\n\n# Intersection\ninter &lt;- st_intersects(grid, poi, sparse = TRUE) \n\n# vérifier l'intersection\nlength(inter) == nrow(grid)\n\n[1] TRUE\n\n# Jointure des résultats dans la grille\ngrid$nb_poi &lt;- lengths(inter)\n\nhead(grid)\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 178843.6 ymin: 3345646 xmax: 388843.6 ymax: 3380646\nProjected CRS: Carthage / TM 11 NE\n  ID                           geom nb_poi\n1  1 POLYGON ((178843.6 3345646,...      0\n2  2 POLYGON ((213843.6 3345646,...      0\n3  3 POLYGON ((248843.6 3345646,...      0\n4  4 POLYGON ((283843.6 3345646,...      0\n5  5 POLYGON ((318843.6 3345646,...      0\n6  6 POLYGON ((353843.6 3345646,...      0\n\n\nOn peut affiner cette grille en ne sélectionnant que les carreaux qui intersectent le fond de carte…\n\ngrid_f &lt;- st_filter(grid, gou, .predicate = st_intersects)\n\n…et cartographier le résultat avec mapsf\n\n# intitialisation du fond de carte\nmf_map(x = grid_f, border = \"white\", lwd = 0.5)\n\n# cartographie du nombre de points en cercles proportionnels\nmf_map(x = grid_f,\n       var = \"nb_poi\",\n       type = \"prop\",\n       border = \"white\",\n       col = \"#FF000080\",\n       leg_title = \"Nombre de points remarquables\",\n       inches   = 0.4, leg_pos  = \"topright\")"
  },
  {
    "objectID": "GEO1_carto_vecteurs.html#conversion-vecteur-raster",
    "href": "GEO1_carto_vecteurs.html#conversion-vecteur-raster",
    "title": "[GEO1] Manipuler les vecteurs avec R et le package sf",
    "section": "Conversion vecteur –> raster",
    "text": "Conversion vecteur –&gt; raster\nLe package terra permet la manipulation de données raster mais aussi de données vecteur pour certains traitements.\nOn peut convertir un objet vectoriel sf vers un objet vectoriel terra de format spatVector avec la fonction vect() de terra\n\nlibrary(terra)\n\ngrid_spatVect &lt;- vect(grid)\nclass(grid_spatVect)\n\n[1] \"SpatVector\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nOn peut aussi convertir un objet vectoriel sf vers un objet raster terra de format spatRast pour cela voir le module de raster\n\n\n\n\n\n\n\nA propos de ce document\n\n\n\nCe support a été créé pour la semaine de formation franco-tunisienne GEO UNIV’R Tunisie 2024 - “Enseigner la statistique, la cartographie et l’analyse spatiale avec R qui se tient à Sousse en mai 2024.\n\n\n\nRéférences\n\n\nGiraud, Timothée, and Hugues Pecout. 2024. Géomatique avec R. https://doi.org/https://doi.org/10.5281/zenodo.5906212.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in r. Chapman; Hall/CRC.\n\n\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Paris\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] terra_1.8-29     rmapshaper_0.5.0 units_0.8-5      mapsf_0.12.0    \n[5] dplyr_1.1.4      sf_1.0-19       \n\nloaded via a namespace (and not attached):\n [1] jsonlite_1.9.1     compiler_4.4.1     tidyselect_1.2.1   Rcpp_1.0.13-1     \n [5] yaml_2.3.10        fastmap_1.2.0      lattice_0.22-6     R6_2.6.1          \n [9] generics_0.1.3     curl_6.2.1         classInt_0.4-10    s2_1.1.7          \n[13] knitr_1.49         htmlwidgets_1.6.4  maplegend_0.1.0    tibble_3.2.1      \n[17] DBI_1.2.3          pillar_1.10.1      rlang_1.1.5        sp_2.1-4          \n[21] utf8_1.2.4         V8_6.0.0           xfun_0.49          cli_3.6.4         \n[25] magrittr_2.0.3     class_7.3-22       wk_0.9.4           digest_0.6.37     \n[29] grid_4.4.1         rstudioapi_0.17.1  geojsonsf_2.0.3    lifecycle_1.0.4   \n[33] vctrs_0.6.5        KernSmooth_2.23-24 proxy_0.4-27       evaluate_1.0.1    \n[37] glue_1.8.0         codetools_0.2-20   e1071_1.7-16       rmarkdown_2.29    \n[41] tools_4.4.1        pkgconfig_2.0.3    htmltools_0.5.8.1"
  },
  {
    "objectID": "INT2_Enseigne_R.html",
    "href": "INT2_Enseigne_R.html",
    "title": "[INT2] : Enseigner avec R",
    "section": "",
    "text": "On se propoe de passer en revue l’ensemble du programme de la semaine à travers un exercice pédagogique associant statistique, cartographie, analyse spatiale, modélisation … Cet exercice correspond typiquement au travail qu’on pourrait donner à des étudiants de licence 2 ou 3 ayant suivi des cours de statistique, cartographie et SIG.\nOn limite volontairement au minimum le nombre de packages R utilisés, en se limitant ici à deux : readxl et sf. Ceux-ci sont utilisés pour importer/exporter les données statistiques et les données géographiques.\nOn propose de réaliser une analyse de la distribution du taux d’équipement en ordinateur dans les délégations d’un gouvernorat en 2004 et 2014. Le programme est rédigé de telle sorte qu’on puisse facilement passer d’un gouvernorat à l’autre.\n\n\nCode\n# Importe les données\nlibrary(readxl)\ndata&lt;-read_xls(path = \"data/RP_Tunisie/data/don_del.xls\",\n              sheet = \"data\")\n\nchoix_gou &lt;- \"Sfax\"\n\n\nA chaque étape, on peut comparer les résultats obtenus en se servant de programmes R et ceux obtenus en se servant des logiciels utilisant la souris comme Excel, Xlstat, Magrit, QGIS, ArCGIS, Philcarto , …"
  },
  {
    "objectID": "INT2_Enseigne_R.html#introduction",
    "href": "INT2_Enseigne_R.html#introduction",
    "title": "[INT2] : Enseigner avec R",
    "section": "",
    "text": "On se propoe de passer en revue l’ensemble du programme de la semaine à travers un exercice pédagogique associant statistique, cartographie, analyse spatiale, modélisation … Cet exercice correspond typiquement au travail qu’on pourrait donner à des étudiants de licence 2 ou 3 ayant suivi des cours de statistique, cartographie et SIG.\nOn limite volontairement au minimum le nombre de packages R utilisés, en se limitant ici à deux : readxl et sf. Ceux-ci sont utilisés pour importer/exporter les données statistiques et les données géographiques.\nOn propose de réaliser une analyse de la distribution du taux d’équipement en ordinateur dans les délégations d’un gouvernorat en 2004 et 2014. Le programme est rédigé de telle sorte qu’on puisse facilement passer d’un gouvernorat à l’autre.\n\n\nCode\n# Importe les données\nlibrary(readxl)\ndata&lt;-read_xls(path = \"data/RP_Tunisie/data/don_del.xls\",\n              sheet = \"data\")\n\nchoix_gou &lt;- \"Sfax\"\n\n\nA chaque étape, on peut comparer les résultats obtenus en se servant de programmes R et ceux obtenus en se servant des logiciels utilisant la souris comme Excel, Xlstat, Magrit, QGIS, ArCGIS, Philcarto , …"
  },
  {
    "objectID": "INT2_Enseigne_R.html#donnees-statistiques",
    "href": "INT2_Enseigne_R.html#donnees-statistiques",
    "title": "[INT2] : Enseigner avec R",
    "section": "(1) DONNEES STATISTIQUES",
    "text": "(1) DONNEES STATISTIQUES\n\n\n\n\n\n\nTélécharger le jeu de données\n\n\n\n\nRP_Tunisie\n\n\n\n\nAcquisition\n\nConsigne : Après avoir chargé le tableau excel tun_del_2004.xls, sélectionnez les délégations du gouvernorat de Sfax et construisez un tableau décrivant le nombre ménages et leur équipement en ordinateur en 2004 et 2014\nRésultat :\n\n\n\nCode\n# Importe les données\nlibrary(readxl)\ndata&lt;-read_xls(path = \"data/RP_Tunisie/data/don_del.xls\",\n              sheet = \"data\")\n\n# Sélectionne les lignes\ndon &lt;- data[data$gou_nom==choix_gou,]\n\n# simplifie le code\ndon$code&lt;-substr(don$del_code,7,8)\n\n# Calcule le taux d'équipement\ndon$equip_2004 &lt;- 100*don$ordin_2004/don$menag_2004\ndon$equip_2014 &lt;- 100*don$ordin_2014/don$menag_2014\n\n# Sélectionne les colonnes\ndon &lt;- don[,c(\"code\",\"del_nom_fr\",\"del_nom_ar\",\"gou_cap\",\"menag_2004\",\"menag_2014\", \"ordin_2004\", \"ordin_2014\")]\n\n# renomme\nnames(don)&lt;-c(\"code\",\"nomfr\",\"nomar\",\"cap\", \"men04\",\"men14\",\"equ04\",\"equ14\")\n\n# Affiche\nlibrary(knitr)\nkable(don, digits=0,\n      main = \"Tableau 1 : Ménages et équipements\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode\nnomfr\nnomar\ncap\nmen04\nmen14\nequ04\nequ14\n\n\n\n\nSM\nSfax Medina\nصفاقس المدينة\n1\n28794\n29107\n3772\n14494\n\n\nSO\nSfax Ouest\nصفاقس الغربية\n0\n26653\n30371\n3385\n14841\n\n\nSZ\nSakiet Ezzit\nساقية الزيت\n0\n17541\n23096\n2193\n10978\n\n\nSD\nSakiet Eddair\nساقية الدائر\n0\n23633\n30277\n2056\n12418\n\n\nSS\nSfax Sud\nصفاقس الجنوبية\n0\n24215\n31866\n2664\n14057\n\n\nTI\nTina\nطينة\n0\n10239\n15577\n307\n4576\n\n\nAG\nAgareb\nعقارب\n0\n7689\n9743\n177\n1543\n\n\nDJ\nJebeniana\nجبنيانة\n0\n9502\n11823\n171\n1948\n\n\nAM\nEL Amra\nالعامرة\n0\n6181\n7501\n80\n966\n\n\nHA\nHencha\nالحنشة\n0\n8831\n11385\n97\n1087\n\n\nMC\nMenzel Chaker\nمنزل شاكر\n0\n7084\n8387\n35\n477\n\n\nGH\nEl Ghraiba\nالغريبة\n0\n3029\n3390\n21\n269\n\n\nBA\nBir Ali Ben khlifa\nبئر علي بن خليفة\n0\n9598\n11230\n58\n994\n\n\nSK\nSkhira\nالصخيرة\n0\n5137\n6807\n72\n936\n\n\nMA\nMahres\nالمحرس\n0\n6506\n8311\n247\n2245\n\n\nKE\nKerkenah\nقرقنة\n0\n3933\n3869\n102\n1314\n\n\n\n\n\n\n\nTransformation\n\nConsigne : Ajoutez deux colonnes décrivant le taux d’équipement en % des ménages en 2004 et 2014\n\n\n\nCode\ndon$pct04&lt;-100*don$equ04/don$men04\ndon$pct14&lt;-100*don$equ14/don$men14\nkable(don, \n      main = \"Tableau 2 : taux d'équipement\",\n      digits=c(0,0,0,0,0,0,0,0,1,1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode\nnomfr\nnomar\ncap\nmen04\nmen14\nequ04\nequ14\npct04\npct14\n\n\n\n\nSM\nSfax Medina\nصفاقس المدينة\n1\n28794\n29107\n3772\n14494\n13.1\n49.8\n\n\nSO\nSfax Ouest\nصفاقس الغربية\n0\n26653\n30371\n3385\n14841\n12.7\n48.9\n\n\nSZ\nSakiet Ezzit\nساقية الزيت\n0\n17541\n23096\n2193\n10978\n12.5\n47.5\n\n\nSD\nSakiet Eddair\nساقية الدائر\n0\n23633\n30277\n2056\n12418\n8.7\n41.0\n\n\nSS\nSfax Sud\nصفاقس الجنوبية\n0\n24215\n31866\n2664\n14057\n11.0\n44.1\n\n\nTI\nTina\nطينة\n0\n10239\n15577\n307\n4576\n3.0\n29.4\n\n\nAG\nAgareb\nعقارب\n0\n7689\n9743\n177\n1543\n2.3\n15.8\n\n\nDJ\nJebeniana\nجبنيانة\n0\n9502\n11823\n171\n1948\n1.8\n16.5\n\n\nAM\nEL Amra\nالعامرة\n0\n6181\n7501\n80\n966\n1.3\n12.9\n\n\nHA\nHencha\nالحنشة\n0\n8831\n11385\n97\n1087\n1.1\n9.5\n\n\nMC\nMenzel Chaker\nمنزل شاكر\n0\n7084\n8387\n35\n477\n0.5\n5.7\n\n\nGH\nEl Ghraiba\nالغريبة\n0\n3029\n3390\n21\n269\n0.7\n7.9\n\n\nBA\nBir Ali Ben khlifa\nبئر علي بن خليفة\n0\n9598\n11230\n58\n994\n0.6\n8.9\n\n\nSK\nSkhira\nالصخيرة\n0\n5137\n6807\n72\n936\n1.4\n13.8\n\n\nMA\nMahres\nالمحرس\n0\n6506\n8311\n247\n2245\n3.8\n27.0\n\n\nKE\nKerkenah\nقرقنة\n0\n3933\n3869\n102\n1314\n2.6\n34.0"
  },
  {
    "objectID": "INT2_Enseigne_R.html#statistique-univariee",
    "href": "INT2_Enseigne_R.html#statistique-univariee",
    "title": "[INT2] : Enseigner avec R",
    "section": "(2) STATISTIQUE UNIVARIEE",
    "text": "(2) STATISTIQUE UNIVARIEE\n\nParamètres principaux\n\nConsigne : Etudiez l’évolution du taux d’équipement des ménages en ordinateur par délégation en 2004 et 2014 en vous servant de paramètres principaux (valeurs centrales, paramètres de dispersion). Puis établissez deux histogrammes permettant de visualiser l’évolution.\n\n\n\nCode\n# sélectionne les variables\nsel &lt;- don[,c(\"pct04\",\"pct14\")]\n\n# Tableau standard\nquant&lt;-apply(sel,2,quantile)\nmoy&lt;-apply(sel,2,mean)\nect&lt;-apply(sel,2,sd)\ncv&lt;-100*ect/moy\ntab&lt;-rbind(quant,moy,ect,cv)\nrow.names(tab) &lt;-c(\"Minimum\",\"Q1\",\"Médiane\",\"Q3\",\"Maximum\",\"Moyenne\",\"Ecart-type\", \"C.V. (%)\")\n\nkable(tab, caption=\"Paramètres principaux\", digits =1,\n      col.names = c(\"Situation en 2004\",\"Situation en 2014\"),\n      )\n\n\n\nParamètres principaux\n\n\n\nSituation en 2004\nSituation en 2014\n\n\n\n\nMinimum\n0.5\n5.7\n\n\nQ1\n1.2\n12.0\n\n\nMédiane\n2.4\n21.7\n\n\nQ3\n9.3\n41.8\n\n\nMaximum\n13.1\n49.8\n\n\nMoyenne\n4.8\n25.8\n\n\nEcart-type\n4.9\n16.3\n\n\nC.V. (%)\n101.6\n63.3\n\n\n\n\n\n\n\nHistogrammes\n\nConsigne : Etablissez deux histogrammes permettant de visualiser la forme de la distribution du taux d’équipement et son évolution entre 2004 et 2014.\n\n\n\nCode\npar(mfrow=c(2,1))\n\nmintot &lt;-min(c(sel$pct04, sel$pct14))\nmaxtot &lt;-max(c(sel$pct04, sel$pct14))\n\n# Histogramme\nhist(sel$pct04,\n     breaks=quantile(sel$pct04),\n     xlim=c(mintot,maxtot),\n     col=\"gray80\",\n     main= \"Situation en 2004\",\n     xlab = \"Taux d'équipement (%)\",\n     ylab = \"Fréquence moyenne\")\nrug(sel$pct04, col=\"black\", lwd=2)\nlines(density(sel$pct04), lty=3,lwd=2)\n\nhist(sel$pct14,\n    breaks=quantile(sel$pct14),\n     xlim=c(mintot,maxtot),\n     col=\"gray80\",\n     main= \"Situation en 2014\",\n     xlab = \"Taux d'équipement (%)\",\n     ylab = \"Fréquence moyenne\")\nrug(sel$pct14, col=\"black\", lwd=2)\nlines(density(sel$pct14), lty=3,lwd=2)"
  },
  {
    "objectID": "INT2_Enseigne_R.html#donnees-geometriques",
    "href": "INT2_Enseigne_R.html#donnees-geometriques",
    "title": "[INT2] : Enseigner avec R",
    "section": "(3) DONNEES GEOMETRIQUES",
    "text": "(3) DONNEES GEOMETRIQUES\n\nAcquision\n\nConsigne : Après avoir chargé le shapefile Tunisie2014_del.shp, extraire les délégations correspondant à votre gouvernorat et afficher le fonds de carte avec le code des unités.\n\n\n\nCode\n# Chargement du package spatial features\nlibrary(sf)\n\n# Importation du fonds de carte complet\nmap&lt;-st_read(\"data/RP_Tunisie/geom/map_del.geojson\", quiet=T)\n\n# Selection d'un gouvernorat\nmap &lt;- map[map$gou_nom == choix_gou,]\n\n# simplifie le code\nmap$code &lt;- substr(map$del_code,7,8)\n\n# ne conserve que le code,la capitale et la géométrie\nmap &lt;- map[,c(\"code\",\"gou_cap\",\"geometry\")]\n\n\n# Affichage du fonds de carte\npar(mar=c(0,0,3,0))\nplot(map$geometry, \n     col=\"gray90\",\n     main = \"Code des unités spatiales de la zone d'étude\")\n\n# Ajout du code des unités spatiales\ncoo&lt;-st_coordinates(st_centroid(map))\ntext(coo, map$code, cex=0.5,col=\"black\",)\n\n\n\n\n\n\n\nTransformation\n\nConsigne : ajoutez une colonne correspondant à la distance en km au chef-lieu de gouvernorat et faites en une cartographie en prenant comme bornes de classes 0, 5, 10, 20, 40, 80, 160 km.\n\n\n\nCode\ncap&lt;-map[map$gou_cap==1,]\nmap$dist&lt;-as.numeric(st_distance(st_centroid(map),st_centroid(cap)))/1000\nplot(map[\"dist\"], main=\"Distance au chef-lieu (en km)\",\n     breaks=c(0,5, 10,20,40,80, 160),\n     pal=c(\"gray10\", \"gray30\",\"gray50\",\"gray70\",\"gray90\", \"gray100\"),)"
  },
  {
    "objectID": "INT2_Enseigne_R.html#cartographie-thematique",
    "href": "INT2_Enseigne_R.html#cartographie-thematique",
    "title": "[INT2] : Enseigner avec R",
    "section": "(4) CARTOGRAPHIE THEMATIQUE",
    "text": "(4) CARTOGRAPHIE THEMATIQUE\n\nCartes de stock\n\nConsigne : Réalisez deux cartes de stock décrivant le nombre de ménages équipés en ordinateur en 2004 et 2014. Vous utiliserez la même échelle de taille pour rendre les deux cartes comparables.\n\n\n\nCode\nlibrary(mapsf)\nmap&lt;-map[,c(\"code\",\"geometry\")]\nmap_don &lt;- merge(map, don, by=\"code\")\nmaxequ&lt;-max(don$equ04,don$equ14)\n\npar(mfrow=c(1,2))\nmf_map(map_don$geometry, col=\"white\")\nmf_map(map_don, type=\"prop\", var=\"equ04\",\n       val_max = maxequ, inches=0.1, col=\"gray20\", \n       leg_title = \"Nb. de ménages équipés\",)\nmf_layout(title=\"2004\",frame = T, credits = \"Source : INS Tunisie\")\n\nmf_map(map_don$geometry, col=\"white\")\nmf_map(map_don, type=\"prop\", var=\"equ14\",\n       val_max = maxequ, inches=0.1, col=\"gray20\",\n       leg_title = \"Nb. de ménages équipés\")\nmf_layout(title=\"2014\",frame = T, credits = \"Source : INS Tunisie\")\n\n\n\n\n\n\n\nCartes de ratio (choroplèthes)\n\nConsigne : Réalisez deux cartes de taux décrivant le nombre de ménages équipés en ordinateur en 2004 et 2014. Pour les rendre comparables vous utiliserez dans chaque carte une partition en quintiles (5 classes d’effectifs égaux)\n\n\n\nCode\nlibrary(mapsf)\nmap_don &lt;- merge(map, don, by=\"code\")\nmaxequ&lt;-max(don$equ04,don$equ14)\n\npar(mfrow=c(1,2))\nmf_map(map_don, type=\"choro\", var=\"pct04\",\n       breaks = \"quantile\",nbreaks = 5, pal =\"Grays\",\n       leg_title = \"% ménages équipés\",leg_val_rnd = 1)\nmf_layout(title=\"2004\",frame = T, credits = \"Source : INS Tunisie\")\n\nmf_map(map_don, type=\"choro\", var=\"pct14\",\n       breaks = \"quantile\",nbreaks = 5, pal =\"Grays\",\n       leg_title = \"% ménages équipés\",leg_val_rnd = 1)\nmf_layout(title=\"2014\",frame = T, credits = \"Source : INS Tunisie\")"
  },
  {
    "objectID": "INT2_Enseigne_R.html#statistiques-bivariees",
    "href": "INT2_Enseigne_R.html#statistiques-bivariees",
    "title": "[INT2] : Enseigner avec R",
    "section": "(5) STATISTIQUES BIVARIEES",
    "text": "(5) STATISTIQUES BIVARIEES\n\nNuage de points\n\nConsigne : Tracez un nuage de point montrant l’évolution de l’indicateur entre les deux dates.\n\n\n\nCode\n# prépration de l'analyse\ncode&lt;-don$code\nnomfr&lt;-don$nomfr\nnomar&lt;-don$nomar\nX&lt;-don$pct04\nY&lt;-don$pct14\ntab&lt;-data.frame(code,nomfr, nomar,X,Y)\n\n# Diagramme\nplot(tab$X,tab$Y, \n     pch=20,\n     cex=0.8,\n     col=\"red\",\n     main = \"Evolution du taux d'équipement\",\n     xlab=\"tx. equipement. 2004\",\n     ylab =\"tx. equipement 2014\")\ntext(tab$X,tab$Y,tab$code, \n     pos=2,\n     cex=0.5,\n     col=\"blue\")\n\n\n\n\n\n\n\nAnalyse de la corrélation\n\nConsigne : calculez les coefficients de corrélation de Pearson et Spearman et testez leur sgnificativité.\n\n\n\nCode\ncor.test(X,Y, method=\"pearson\")\n\n\n\n    Pearson's product-moment correlation\n\ndata:  X and Y\nt = 10.264, df = 14, p-value = 6.756e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8306927 0.9791923\nsample estimates:\n      cor \n0.9395226 \n\n\nCode\ncor.test(X,Y, method=\"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  X and Y\nS = 12, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9823529 \n\n\n\n\nDroite de régression\n\nConsigne : calculez l’equation de la droite de régression et tracez- là sur le graphique.\n\n\n\nCode\nmodreg &lt;- lm(Y~X)\nsummary(modreg)\n\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5455 -2.6977 -1.7530  0.8751 15.1464 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  10.6836     2.0643   5.175 0.000141 ***\nX             3.1357     0.3055  10.264 6.76e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.79 on 14 degrees of freedom\nMultiple R-squared:  0.8827,    Adjusted R-squared:  0.8743 \nF-statistic: 105.4 on 1 and 14 DF,  p-value: 6.756e-08\n\n\nCode\nplot(tab$X,tab$Y, \n     pch=20,\n     cex=0.8,\n     col=\"red\",\n     main = \"Droite de régression\",\n     xlab=\"tx. equipement. 2004\",\n     ylab =\"tx. equipement 2014\")\n\nabline(modreg,col=\"blue\",lwd=1)\n\n\n\n\n\n\n\nAnalyse des résidus\n\nConsigne : Calculez les valeurs théoriques prévus par le modèle de régression et les résidus. Affichez le tableau correspondant après l’avoir trié par ordre de résidus croissants.\n\n\n\nCode\ntab$Y_est &lt;- modreg$fitted.values\ntab$Y_res &lt;- modreg$residuals\ntab&lt;-tab[order(tab$Y_res),]\nkable(tab, digits=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode\nnomfr\nnomar\nX\nY\nY_est\nY_res\n\n\n\n\n11\nMC\nMenzel Chaker\nمنزل شاكر\n0.5\n5.7\n12.2\n-6.5\n\n\n12\nGH\nEl Ghraiba\nالغريبة\n0.7\n7.9\n12.9\n-4.9\n\n\n10\nHA\nHencha\nالحنشة\n1.1\n9.5\n14.1\n-4.6\n\n\n13\nBA\nBir Ali Ben khlifa\nبئر علي بن خليفة\n0.6\n8.9\n12.6\n-3.7\n\n\n3\nSZ\nSakiet Ezzit\nساقية الزيت\n12.5\n47.5\n49.9\n-2.4\n\n\n7\nAG\nAgareb\nعقارب\n2.3\n15.8\n17.9\n-2.1\n\n\n1\nSM\nSfax Medina\nصفاقس المدينة\n13.1\n49.8\n51.8\n-2.0\n\n\n9\nAM\nEL Amra\nالعامرة\n1.3\n12.9\n14.7\n-1.9\n\n\n2\nSO\nSfax Ouest\nصفاقس الغربية\n12.7\n48.9\n50.5\n-1.6\n\n\n14\nSK\nSkhira\nالصخيرة\n1.4\n13.8\n15.1\n-1.3\n\n\n5\nSS\nSfax Sud\nصفاقس الجنوبية\n11.0\n44.1\n45.2\n-1.1\n\n\n8\nDJ\nJebeniana\nجبنيانة\n1.8\n16.5\n16.3\n0.1\n\n\n4\nSD\nSakiet Eddair\nساقية الدائر\n8.7\n41.0\n38.0\n3.1\n\n\n15\nMA\nMahres\nالمحرس\n3.8\n27.0\n22.6\n4.4\n\n\n6\nTI\nTina\nطينة\n3.0\n29.4\n20.1\n9.3\n\n\n16\nKE\nKerkenah\nقرقنة\n2.6\n34.0\n18.8\n15.1\n\n\n\n\n\n\n\nCartographie des résidus\n\nConsigne : Cartographiez les résidus après les avoir standardisés.\n\n\n\nCode\nlibrary(mapsf)\n\n# Standardisation des résidus\ntab$Y_res_std&lt;-tab$Y_res/sd(tab$Y_res)\n\n# Jointure avec la carte\nmap&lt;-map[,c(\"code\",\"geometry\")]\nmap_reg &lt;- merge(map, tab, by=\"code\")\n\n# Choix de la palette et des classes\nlibrary(RColorBrewer)\nmypal&lt;-brewer.pal(n = 6, name = \"RdYlBu\")\nmybreaks = c(-10, -2,-1,0,1,2,10)\n\nmf_map(map_reg, type=\"choro\", var=\"Y_res_std\",\n       pal = mypal, breaks=mybreaks,\n       leg_title = \"Résidus standardisés\",leg_val_rnd = 1)\nmf_layout(title=\"Ecarts à la tendance 2004-2014\",frame = T, credits = \"Source : INS Tunisie\")"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html",
    "href": "STA2C_biv_quanti_quanti.html",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "",
    "text": "Nous allons charger ici un fichier de données climatiques sur la Tunisie\n\n\n\n\n\n\nTélécharger le jeux de données\n\n\n\n\nTUN-CLIMAT\n\n\n\n\n\n\n# Importe les données\nlibrary(readxl)\ndon&lt;-read_xlsx(path = \"data/TUN-CLIMAT/tun_climat.xlsx\",\n              sheet = \"data\")\nkable(don, caption = \"Tableau de données\")\n\n\nTableau de données\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode\nnom\nreg_code\nreg_nom\nlat\nlon\nalt\ntmin\ntmax\ntmoy\nprec\nvent\nrosee\n\n\n\n\nBJ\nBeja\nNO\nNord-ouest\n36.73333\n9.183333\n159.00\n11.45894\n24.62033\n18.55692\n590.000\n6.436291\n10.881502\n\n\nBZ\nBizerte\nNE\nNord-est\n37.24545\n9.791453\n6.09\n13.36735\n23.96475\n18.73467\n639.000\n13.080826\n13.507263\n\n\nGB\nGabes\nSE\nSud-est\n33.87692\n10.103333\n7.92\n15.62121\n25.44585\n20.64563\n192.000\n11.564158\n12.396331\n\n\nGF\nGafsa\nSO\nSud-ouest\n34.42202\n8.822503\n323.08\n13.73596\n26.88865\n20.42736\n163.000\n12.759514\n7.894512\n\n\nJE\nJendouba\nNO\nNord-ouest\n36.48333\n8.800000\n144.00\n12.03502\n25.75739\n19.17381\n458.000\n8.187385\n11.549468\n\n\nKR\nKairouan\nCO\nCentre-ouest\n35.66667\n10.100000\n68.00\n15.05704\n27.37991\n20.88537\n303.000\n5.826256\n10.894726\n\n\nKS\nKasserine\nCO\nCentre-ouest\n35.16667\n8.833333\n707.00\n11.47720\n24.13852\n18.46683\n340.000\n12.853035\n8.366253\n\n\nKB\nKebili\nSO\nSud-ouest\n33.70000\n8.966667\n46.00\n15.34825\n28.66706\n22.71979\n89.000\n14.061362\n10.373775\n\n\nKF\nLe Kef\nNO\nNord-ouest\n36.13333\n8.700000\n518.00\n10.30506\n23.19958\n17.24170\n528.000\n8.246948\n8.059934\n\n\nMH\nMahdia\nCE\nCentre-est\n35.50000\n11.066667\n12.00\n16.50674\n23.29379\n20.16491\n290.000\n10.854368\n14.624500\n\n\nME\nMedenine\nSE\nSud-est\n33.35000\n10.483333\n117.00\n16.17117\n27.56439\n22.57362\n159.000\n8.743863\n11.404804\n\n\nMS\nMonastir\nCE\nCentre-est\n35.66667\n10.750000\n2.00\n15.64783\n24.26410\n19.76152\n322.062\n13.888661\n13.587094\n\n\nNB\nNabeul\nNE\nNord-est\n36.46667\n10.700000\n78.00\n15.70167\n23.43309\n19.81197\n450.000\n12.190401\n14.033335\n\n\nSF\nSfax\nCE\nCentre-est\n34.71795\n10.690972\n25.90\n14.88812\n25.24082\n20.05744\n221.000\n11.408961\n12.427977\n\n\nSZ\nSidi Bou Zid\nCO\nCentre-ouest\n35.00000\n9.483333\n355.00\n13.03144\n26.20685\n20.25616\n280.000\n8.283933\n9.461638\n\n\nSL\nSiliana\nNO\nNord-ouest\n36.06667\n9.366667\n445.00\n11.36109\n24.50220\n19.02255\n389.000\n9.242761\n9.455365\n\n\nSS\nSousse\nCE\nCentre-est\n35.70000\n10.600000\n5.00\n15.70000\n24.40000\n19.90000\n310.000\n12.500000\n13.600000\n\n\nTA\nTataouine\nSE\nSud-est\n32.91667\n10.450000\n215.00\n15.90320\n27.20100\n21.41218\n110.000\n10.298155\n9.182343\n\n\nTO\nTozeur\nSO\nSud-ouest\n33.93972\n8.110556\n87.47\n16.83189\n28.64269\n22.63410\n97.000\n14.732460\n8.697420\n\n\nTU\nTunis\nNE\nNord-est\n36.85103\n10.227217\n6.70\n14.26899\n24.61744\n19.14238\n453.000\n13.405618\n12.626422\n\n\nZA\nZaghouan\nNE\nNord-est\n36.43333\n10.083333\n156.00\n12.43361\n25.06573\n18.57657\n501.000\n10.331711\n11.907365\n\n\n\n\n\n\n\n\nOn charge ensuite le fichier des métadonnées:\n\n# Importe les métadonnées\nmeta&lt;-read_xlsx(path = \"data/TUN-CLIMAT/tun_climat.xlsx\",\n              sheet = \"meta\")\nkable(meta, caption = \"Tableau de métadonnées\")\n\n\nTableau de métadonnées\n\n\nvariable\ndef\n\n\n\n\ncode\ncode de la station\n\n\nnom\nnom de la station\n\n\nreg_code\ncode de la région\n\n\nreg_nom\nnom de la region\n\n\ngouv_nom\nnom du gouvernorat\n\n\nlat\nLatitude\n\n\nlon\nLongitude\n\n\nalt\nAltitude (en mètres)\n\n\ntmin\nMoyenne de Tmin\n\n\ntmax\nMoyenne de Tmax\n\n\ntmoy\nMoyenne de Tmoy\n\n\nprec\nMoyenne de précipitations totales\n\n\nvent\nMoyenne de vent km/h\n\n\nrose\nMoyenne de point de rosée\n\n\n\n\n\n\n\n\nOn suppose qu’on ne s’intéresse qu’aux variables latitude (lat) et précipitations (prec) que l’on va renommer espectivement X (variable explicative) et Y (variable à expliquer)\n\ndon&lt;-don[,c(\"code\",\"nom\",\"lat\",\"tmoy\")]\ncolnames(don)&lt;-c(\"code\",\"nom\",\"X\",\"Y\")\nkable(head(don))\n\n\n\n\ncode\nnom\nX\nY\n\n\n\n\nBJ\nBeja\n36.73333\n18.55692\n\n\nBZ\nBizerte\n37.24545\n18.73467\n\n\nGB\nGabes\n33.87692\n20.64563\n\n\nGF\nGafsa\n34.42202\n20.42736\n\n\nJE\nJendouba\n36.48333\n19.17381\n\n\nKR\nKairouan\n35.66667\n20.88537\n\n\n\n\n\n\n\n\nPour pouvoir produire des graphiques en français ou en arabes, on stocke dans des variables le titre, la source et le nom des deux indicateurs.\n\n# Pour la version française\ntitre &lt;- \"Température et latitude en Tunisie\"\nnomX &lt;- \"Latitude\"\nnomY &lt;- \"Température moyenne\""
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#importation-des-données",
    "href": "STA2C_biv_quanti_quanti.html#importation-des-données",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "",
    "text": "# Importe les données\nlibrary(readxl)\ndon&lt;-read_xlsx(path = \"data/TUN-CLIMAT/tun_climat.xlsx\",\n              sheet = \"data\")\nkable(don, caption = \"Tableau de données\")\n\n\nTableau de données\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode\nnom\nreg_code\nreg_nom\nlat\nlon\nalt\ntmin\ntmax\ntmoy\nprec\nvent\nrosee\n\n\n\n\nBJ\nBeja\nNO\nNord-ouest\n36.73333\n9.183333\n159.00\n11.45894\n24.62033\n18.55692\n590.000\n6.436291\n10.881502\n\n\nBZ\nBizerte\nNE\nNord-est\n37.24545\n9.791453\n6.09\n13.36735\n23.96475\n18.73467\n639.000\n13.080826\n13.507263\n\n\nGB\nGabes\nSE\nSud-est\n33.87692\n10.103333\n7.92\n15.62121\n25.44585\n20.64563\n192.000\n11.564158\n12.396331\n\n\nGF\nGafsa\nSO\nSud-ouest\n34.42202\n8.822503\n323.08\n13.73596\n26.88865\n20.42736\n163.000\n12.759514\n7.894512\n\n\nJE\nJendouba\nNO\nNord-ouest\n36.48333\n8.800000\n144.00\n12.03502\n25.75739\n19.17381\n458.000\n8.187385\n11.549468\n\n\nKR\nKairouan\nCO\nCentre-ouest\n35.66667\n10.100000\n68.00\n15.05704\n27.37991\n20.88537\n303.000\n5.826256\n10.894726\n\n\nKS\nKasserine\nCO\nCentre-ouest\n35.16667\n8.833333\n707.00\n11.47720\n24.13852\n18.46683\n340.000\n12.853035\n8.366253\n\n\nKB\nKebili\nSO\nSud-ouest\n33.70000\n8.966667\n46.00\n15.34825\n28.66706\n22.71979\n89.000\n14.061362\n10.373775\n\n\nKF\nLe Kef\nNO\nNord-ouest\n36.13333\n8.700000\n518.00\n10.30506\n23.19958\n17.24170\n528.000\n8.246948\n8.059934\n\n\nMH\nMahdia\nCE\nCentre-est\n35.50000\n11.066667\n12.00\n16.50674\n23.29379\n20.16491\n290.000\n10.854368\n14.624500\n\n\nME\nMedenine\nSE\nSud-est\n33.35000\n10.483333\n117.00\n16.17117\n27.56439\n22.57362\n159.000\n8.743863\n11.404804\n\n\nMS\nMonastir\nCE\nCentre-est\n35.66667\n10.750000\n2.00\n15.64783\n24.26410\n19.76152\n322.062\n13.888661\n13.587094\n\n\nNB\nNabeul\nNE\nNord-est\n36.46667\n10.700000\n78.00\n15.70167\n23.43309\n19.81197\n450.000\n12.190401\n14.033335\n\n\nSF\nSfax\nCE\nCentre-est\n34.71795\n10.690972\n25.90\n14.88812\n25.24082\n20.05744\n221.000\n11.408961\n12.427977\n\n\nSZ\nSidi Bou Zid\nCO\nCentre-ouest\n35.00000\n9.483333\n355.00\n13.03144\n26.20685\n20.25616\n280.000\n8.283933\n9.461638\n\n\nSL\nSiliana\nNO\nNord-ouest\n36.06667\n9.366667\n445.00\n11.36109\n24.50220\n19.02255\n389.000\n9.242761\n9.455365\n\n\nSS\nSousse\nCE\nCentre-est\n35.70000\n10.600000\n5.00\n15.70000\n24.40000\n19.90000\n310.000\n12.500000\n13.600000\n\n\nTA\nTataouine\nSE\nSud-est\n32.91667\n10.450000\n215.00\n15.90320\n27.20100\n21.41218\n110.000\n10.298155\n9.182343\n\n\nTO\nTozeur\nSO\nSud-ouest\n33.93972\n8.110556\n87.47\n16.83189\n28.64269\n22.63410\n97.000\n14.732460\n8.697420\n\n\nTU\nTunis\nNE\nNord-est\n36.85103\n10.227217\n6.70\n14.26899\n24.61744\n19.14238\n453.000\n13.405618\n12.626422\n\n\nZA\nZaghouan\nNE\nNord-est\n36.43333\n10.083333\n156.00\n12.43361\n25.06573\n18.57657\n501.000\n10.331711\n11.907365"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#liste-des-variables",
    "href": "STA2C_biv_quanti_quanti.html#liste-des-variables",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "",
    "text": "On charge ensuite le fichier des métadonnées:\n\n# Importe les métadonnées\nmeta&lt;-read_xlsx(path = \"data/TUN-CLIMAT/tun_climat.xlsx\",\n              sheet = \"meta\")\nkable(meta, caption = \"Tableau de métadonnées\")\n\n\nTableau de métadonnées\n\n\nvariable\ndef\n\n\n\n\ncode\ncode de la station\n\n\nnom\nnom de la station\n\n\nreg_code\ncode de la région\n\n\nreg_nom\nnom de la region\n\n\ngouv_nom\nnom du gouvernorat\n\n\nlat\nLatitude\n\n\nlon\nLongitude\n\n\nalt\nAltitude (en mètres)\n\n\ntmin\nMoyenne de Tmin\n\n\ntmax\nMoyenne de Tmax\n\n\ntmoy\nMoyenne de Tmoy\n\n\nprec\nMoyenne de précipitations totales\n\n\nvent\nMoyenne de vent km/h\n\n\nrose\nMoyenne de point de rosée"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#choix-des-deux-variables-à-analyser",
    "href": "STA2C_biv_quanti_quanti.html#choix-des-deux-variables-à-analyser",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "",
    "text": "On suppose qu’on ne s’intéresse qu’aux variables latitude (lat) et précipitations (prec) que l’on va renommer espectivement X (variable explicative) et Y (variable à expliquer)\n\ndon&lt;-don[,c(\"code\",\"nom\",\"lat\",\"tmoy\")]\ncolnames(don)&lt;-c(\"code\",\"nom\",\"X\",\"Y\")\nkable(head(don))\n\n\n\n\ncode\nnom\nX\nY\n\n\n\n\nBJ\nBeja\n36.73333\n18.55692\n\n\nBZ\nBizerte\n37.24545\n18.73467\n\n\nGB\nGabes\n33.87692\n20.64563\n\n\nGF\nGafsa\n34.42202\n20.42736\n\n\nJE\nJendouba\n36.48333\n19.17381\n\n\nKR\nKairouan\n35.66667\n20.88537"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#on-est-malin",
    "href": "STA2C_biv_quanti_quanti.html#on-est-malin",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "",
    "text": "Pour pouvoir produire des graphiques en français ou en arabes, on stocke dans des variables le titre, la source et le nom des deux indicateurs.\n\n# Pour la version française\ntitre &lt;- \"Température et latitude en Tunisie\"\nnomX &lt;- \"Latitude\"\nnomY &lt;- \"Température moyenne\""
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#visualisation-avec-plotxy",
    "href": "STA2C_biv_quanti_quanti.html#visualisation-avec-plotxy",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "2.1 Visualisation avec plot(X,Y)",
    "text": "2.1 Visualisation avec plot(X,Y)\nLa manière la plus simple d’analyser la relation entre X et Y est d’utiliser un simple plot\n\nplot(don$X,don$Y)"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#visualisation-avec-plotxy-1",
    "href": "STA2C_biv_quanti_quanti.html#visualisation-avec-plotxy-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "2.1 Visualisation avec plot(X,Y)",
    "text": "2.1 Visualisation avec plot(X,Y)\nLa fonction plot() comporte de nombreux paramètres permettant d’améliorer le graphique et de l’habiller. Voici un exemple d’habillage\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\n\nplot(don$X,don$Y,\n     main = titre,   # titre\n     cex.main = 1,      # police du titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = nomX,    # nom de l'axe X\n     xlim = c(32.7,37.5),   # intervalle de l'axe X\n     ylab = nomY,    # nom de l'axe Y\n    ylim = c(17,24),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#identification-des-points-avec-text",
    "href": "STA2C_biv_quanti_quanti.html#identification-des-points-avec-text",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "2.2 Identification des points avec text(…)",
    "text": "2.2 Identification des points avec text(…)\nOn peut ajouter au graphique généré par plot(X,Y) une couche de labels avec text(X,Y,Code). On précise la position avec pos =, la taille de police avex cex = et la couleur avec col =.\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\n\nplot(don$X,don$Y,\n     main = titre,   # titre\n     cex.main = 1,      # police du titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = nomX,    # nom de l'axe X\n     xlim = c(32.7,37.5),   # intervalle de l'axe X\n     ylab = nomY,    # nom de l'axe Y\n    ylim = c(17,24),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\ntext(x = don$X,\n     y = don$Y,\n     label = don$code,\n     cex = 0.7,\n     pos=3,\n     col = \"blue\")"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#ajout-de-lignes-horizontales-ou-verticales-avec-abline",
    "href": "STA2C_biv_quanti_quanti.html#ajout-de-lignes-horizontales-ou-verticales-avec-abline",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "2.3 Ajout de lignes horizontales ou verticales avec abline(…)",
    "text": "2.3 Ajout de lignes horizontales ou verticales avec abline(…)\nOn peut rajouter à un graphique des lignes horizontales ou verticales avec abline en précisant leur position avec h= ou v=, leur épaisseur avec lwd = , leur style avec lty= et leur couleur avec col=\n\n\n\n\n\n\nCommentaire\n\n\n\n\n\n\nplot(don$X,don$Y,\n     main = titre,   # titre\n     cex.main = 1,      # police du titre\n     cex.sub = 0.6,     # police du sous-titre\n     xlab = nomX,    # nom de l'axe X\n     xlim = c(32.7,37.5),   # intervalle de l'axe X\n     ylab = nomY,    # nom de l'axe Y\n    ylim = c(17,24),    # intervalle de l'axe Y\n     cex.axis = 0.8,    # police des gradations d'axes\n     cex.lab = 0.8,     # police des noms d'axes\n     cex = 0.6,         # taille des symboles\n     col = \"blue\")       # couleur des symboles\n\n\n# Ajout d'une ligne horizontale  correspondant à la moyenne de Y\nabline(h=mean(don$Y),col=\"red\",lwd = 1, lty = 2)\n# Ajout d'une ligne verticlae  correspondant à la moyenne de X\nabline(v=mean(don$X),col=\"red\",lwd = 1, lty = 2)\n\ntext(x = don$X,\n     y = don$Y,\n     label = don$code,\n     cex = 0.7,\n     pos=3,\n     col = \"blue\")\n\n\n\n\n\n\n\n\n\nLa fonction abline() peut servir aussi à tracer la droite de régression Y=aX+b produite par la fonction lm() sur laquelle nous reviendrons plus tard."
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#au-delà-de-r-base",
    "href": "STA2C_biv_quanti_quanti.html#au-delà-de-r-base",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "2.4 Au delà de R-Base …",
    "text": "2.4 Au delà de R-Base …\nIl existe des packages spécialisés permettant de faire des graphiques plus sophistiqués. Mais on les apprendra ultérieuement. Juste un exemple :\n\nlibrary(car)\nscatterplot(don$X,don$Y)"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-linéairemonotonecomplexe",
    "href": "STA2C_biv_quanti_quanti.html#relation-linéairemonotonecomplexe",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.1 relation linéaire/monotone/complexe",
    "text": "3.1 relation linéaire/monotone/complexe\n\nil existe une relation linéaire entre deux variables quantitatives X et Y si l’on peut prédire leurs valeurs respectives par les fonctions Y = a1.X + b1 et X = a2.X = b2\nil existe une relation monotone entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X far une fonction Y=f(X) qui est strictement croissante ou strictement décroissante.\nil existe une relation complexe entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X par une fonction Y=f(X) qui comporte au moins un point minimum ou maximum de changement de pente (annulation de la dérivée première)"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-linéairemonotonecomplexe-1",
    "href": "STA2C_biv_quanti_quanti.html#relation-linéairemonotonecomplexe-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.1 relation linéaire/monotone/complexe",
    "text": "3.1 relation linéaire/monotone/complexe"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-positivenégativenulle",
    "href": "STA2C_biv_quanti_quanti.html#relation-positivenégativenulle",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.2 relation positive/négative/nulle",
    "text": "3.2 relation positive/négative/nulle\n\nUne relation linéaire ou monotone est positive si à un accroissement de X correspond un accroissement de Y\nUne relation linéaire ou monotone est négative si à un accroissement de X correspond une diminution de Y\nune relation est nulle si une variation de X n’entraine pas de variation de Y"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-positivenégativenulle-1",
    "href": "STA2C_biv_quanti_quanti.html#relation-positivenégativenulle-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.2 relation positive/négative/nulle",
    "text": "3.2 relation positive/négative/nulle"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-fortefaiblenulle",
    "href": "STA2C_biv_quanti_quanti.html#relation-fortefaiblenulle",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.3 : relation forte/faible/nulle",
    "text": "3.3 : relation forte/faible/nulle\n\nUne relation linéaire est forte si une valeur de X permet de prédire la valeur de Y avec une faible marge d’erreur.\nUne relation linéaire ou monotone est faible si une valeur de X permet de prédire la valeur de Y avec une forte marge d’erreur.\nune relation linéaire est nulle si une valeur de X ne permet aucunement de prédire la valeur de Y"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-fortefaiblenulle-1",
    "href": "STA2C_biv_quanti_quanti.html#relation-fortefaiblenulle-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.3 : relation forte/faible/nulle",
    "text": "3.3 : relation forte/faible/nulle"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-significativenon-siginificative",
    "href": "STA2C_biv_quanti_quanti.html#relation-significativenon-siginificative",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.4 : relation significative/non siginificative",
    "text": "3.4 : relation significative/non siginificative\n\nUne relation linéaire est significative si l’effectif permettant de la mettre en évidence est suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard.\nUne relation linéaire ou monotone est non significative si l’effectif permettant de la mettre en évidence n’est pas suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard.\nOn considère traditionnellement qu’une relation est significative s’il y a moins de 5% de chances qu’elle soit l’effet du hasard (p-value &lt; 0.05)."
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#relation-significativenon-siginificative-1",
    "href": "STA2C_biv_quanti_quanti.html#relation-significativenon-siginificative-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.4 : relation significative/non siginificative",
    "text": "3.4 : relation significative/non siginificative"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#sens-de-la-relation",
    "href": "STA2C_biv_quanti_quanti.html#sens-de-la-relation",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.1 Sens de la relation",
    "text": "4.1 Sens de la relation\n\nLa fonction cor() permet de mesurer le coefficient de corrélation de deux variable X et Y.\nElle permet de détecter les relations linéaires en choisissant le paramètre (par défaut) method = pearson\n\nElle permet de détecter les relations non linéaires en choisissant le paramètre method = spearman qui mesure l’existence d’une relation monotone entre les rangs de X et Y"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#sens-de-la-relation-1",
    "href": "STA2C_biv_quanti_quanti.html#sens-de-la-relation-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.1 Sens de la relation",
    "text": "4.1 Sens de la relation\n\nLa syntaxe de la fonction cor() est très simple et permet de calculer trois types de corrélation. La méthode par défaut est pearson c’est-à-dire le coefficient de corrélation linéaire\n\n\ncor(don$X,don$Y)\n\n[1] -0.7966527\n\ncor(don$X,don$Y, method = \"spearman\")\n\n[1] -0.7779221"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#forme-de-la-relation",
    "href": "STA2C_biv_quanti_quanti.html#forme-de-la-relation",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.2 forme de la relation",
    "text": "4.2 forme de la relation"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#forme-de-la-relation-1",
    "href": "STA2C_biv_quanti_quanti.html#forme-de-la-relation-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.2 forme de la relation",
    "text": "4.2 forme de la relation"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#intensité-de-la-relation",
    "href": "STA2C_biv_quanti_quanti.html#intensité-de-la-relation",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.3 Intensité de la relation",
    "text": "4.3 Intensité de la relation\nPour calculer l’intensité d’une relation, on calcule le carré du coefficient de corrélation appelé coefficient de détermination et noté r2 et souvent exprimé en %. Il permet de connaître le pouvoir explicatif du modèle de régression Y = aX+b\n\nr2 &lt;- 100*cor(don$X,don$Y)**2\nr2\n\n[1] 63.46554"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#intensité-de-la-relation-1",
    "href": "STA2C_biv_quanti_quanti.html#intensité-de-la-relation-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.3 Intensité de la relation",
    "text": "4.3 Intensité de la relation"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#significativité-de-la-relation",
    "href": "STA2C_biv_quanti_quanti.html#significativité-de-la-relation",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.4. significativité de la relation",
    "text": "4.4. significativité de la relation\n\nla fonction cor() permet de savoir si une relation est forte ou faible, positive ou négative, linéaire ou non linéaire. Mais cor() ne permet pas de savoir si une relation est significative ou pas.\nEn effet une relation peut être forte mais non significative si elle a été calculée sur un échantillon trop petit.\nil faut donc effectuer un test pour obtenir une probabilité de rejet de l’hypothèse H0 d’absence de relation entre X et Y.\np-value &gt; 0.10 : relation non significative\n0.10 &gt; p-value &gt; 0.05 : relation presque significative\np-value &lt; 0.05 : relation significative\np-value &lt; 0.01 : relation très significative"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#significativité-de-la-relation-1",
    "href": "STA2C_biv_quanti_quanti.html#significativité-de-la-relation-1",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.4 significativité de la relation",
    "text": "3.4 significativité de la relation\n\nA gauche : une relation forte mais non significative\nA droite : une relation faible mais très significative"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#significativité-de-la-relation-2",
    "href": "STA2C_biv_quanti_quanti.html#significativité-de-la-relation-2",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "4.4. significativité de la relation",
    "text": "4.4. significativité de la relation\n\nC’est la fonction cor.test() qui permet de tester la significativité d’une relation en fournissant un intervalle de confiance du coefficient de corrélation et une probabilité de rejet de H0 appelée p-value.\n\n\ncor.test(don$Y,don$X)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$Y and don$X\nt = -5.7451, df = 19, p-value = 1.549e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9140080 -0.5562694\nsample estimates:\n       cor \n-0.7966527"
  },
  {
    "objectID": "STA2C_biv_quanti_quanti.html#conclusion",
    "href": "STA2C_biv_quanti_quanti.html#conclusion",
    "title": "[STA2C] : Statistique bivariée : X et Y quantitatives",
    "section": "3.5 Conclusion",
    "text": "3.5 Conclusion\nAlors qu’en est-il pour la relation température moyenne / altitude ?\n\n\n\n\n\nCette relation est :\n\nnégative : \\(r_{X,Y} &lt; 0\\)\nlinéaire : \\(r_{X,Y} \\approx \\rho_{X,Y}\\)\nforte : \\(r^2 = 79\\%\\)\ntrès signifcative : \\(p_{value} &lt; 0.001\\)"
  }
]